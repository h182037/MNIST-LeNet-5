{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.utils as np_utils\n",
    "from keras.models import Sequential\n",
    "from keras import models, layers\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import keras\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# resources:\n",
    "# https://engmrk.com/lenet-5-a-classic-cnn-architecture/\n",
    "# https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dd2ab82048>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array(x_train[0], dtype='uint8')\n",
    "pixels = image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize value to [0, 1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Transform lables to one-hot encoding\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Reshape the dataset into 4D array\n",
    "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer, activation_1, activation_2, activation_3, activation_4, kernel_size, pool_size, dropout_1, dropout_2):\n",
    "    model = Sequential()\n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(6, kernel_size=kernel_size, strides=(1, 1), activation=activation_1, input_shape=(28,28,1), padding=\"same\"))\n",
    "\n",
    "    # First pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(1, 1), padding='valid'))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation=activation_2, padding='valid'))\n",
    "    \n",
    "    # Second pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "    \n",
    "    # Connected convolutional layer\n",
    "    model.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation=activation_3, padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dropout(dropout_1)) \n",
    "    # Connected layer\n",
    "    model.add(layers.Dense(84, activation=activation_4))\n",
    "    model.add(Dropout(dropout_2)) \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # build/compile\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.5045 - acc: 0.8432\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.3738 - acc: 0.8863\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 52s 2ms/step - loss: 0.3427 - acc: 0.8964\n",
      "30000/30000 [==============================] - 12s 405us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 0.4868 - acc: 0.8489\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 59s 2ms/step - loss: 0.3705 - acc: 0.8875\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 0.3467 - acc: 0.8921: 1s - loss\n",
      "30000/30000 [==============================] - 12s 405us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 29s 979us/step - loss: 0.4108 - acc: 0.8751\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 27s 909us/step - loss: 0.3092 - acc: 0.9068\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 908us/step - loss: 0.2672 - acc: 0.9187\n",
      "30000/30000 [==============================] - 8s 272us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 858us/step - loss: 0.4187 - acc: 0.8737\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 0.3205 - acc: 0.9025\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 885us/step - loss: 0.2715 - acc: 0.9182\n",
      "30000/30000 [==============================] - 9s 301us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 873us/step - loss: 0.4065 - acc: 0.8780\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.2869 - acc: 0.9141\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 24s 789us/step - loss: 0.2482 - acc: 0.9256\n",
      "30000/30000 [==============================] - 8s 260us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 806us/step - loss: 0.3881 - acc: 0.8834\n",
      "Epoch 2/3\n",
      " 5100/30000 [====>.........................] - ETA: 22s - loss: 0.2713 - acc: 0.9125"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [10, 50, 100, 120, 200],\n",
    "              'optimizer': ['SGD'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['tanh'],\n",
    "              'activation_3' : ['tanh'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 7 candidates, totalling 14 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 24s 806us/step - loss: 0.9969 - acc: 0.6903\n",
      "30000/30000 [==============================] - 8s 269us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 23s 783us/step - loss: 1.1067 - acc: 0.6770\n",
      "30000/30000 [==============================] - 8s 260us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 25s 846us/step - loss: 0.2018 - acc: 0.9381\n",
      "30000/30000 [==============================] - 8s 256us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 26s 850us/step - loss: 0.2128 - acc: 0.9337\n",
      "30000/30000 [==============================] - 8s 258us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 23s 773us/step - loss: 0.2070 - acc: 0.9359\n",
      "30000/30000 [==============================] - 7s 249us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.1687 - acc: 0.9467\n",
      "30000/30000 [==============================] - 8s 253us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 28s 923us/step - loss: 0.2416 - acc: 0.92590s - loss: 0.2453 - ac\n",
      "30000/30000 [==============================] - 8s 262us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 27s 892us/step - loss: 0.2596 - acc: 0.9203\n",
      "30000/30000 [==============================] - 8s 263us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 26s 861us/step - loss: 0.2214 - acc: 0.9310\n",
      "30000/30000 [==============================] - 9s 292us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 27s 890us/step - loss: 0.2395 - acc: 0.9266\n",
      "30000/30000 [==============================] - 8s 276us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 27s 911us/step - loss: 0.1769 - acc: 0.9462\n",
      "30000/30000 [==============================] - 8s 262us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 0.2037 - acc: 0.9343\n",
      "30000/30000 [==============================] - 8s 259us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 26s 875us/step - loss: 0.2505 - acc: 0.9214\n",
      "30000/30000 [==============================] - 9s 308us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 26s 857us/step - loss: 0.2639 - acc: 0.9206\n",
      "30000/30000 [==============================] - 9s 306us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 50s 828us/step - loss: 0.1244 - acc: 0.9601\n",
      "Best: 0.979183 using {'batch_size': 64, 'epochs': 1, 'optimizer': 'Nadam'}\n",
      "10000/10000 [==============================] - 3s 264us/step\n",
      "Test loss 2.3055, accuracy 7.64%\n"
     ]
    }
   ],
   "source": [
    "#optimizer\n",
    "seed = 42\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [10, 50, 100, 120, 200],\n",
    "              'optimizer': [['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam', 'Adamax']],\n",
    "              'activation:_1' : ['relu'],\n",
    "              'activation:_2' : ['relu'],\n",
    "              'activation:_3' : ['relu'],\n",
    "              'activation:_4' : ['relu'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "#BEST BATCH SIZE 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 7 candidates, totalling 14 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 29s 956us/step - loss: 0.1757 - acc: 0.9448\n",
      "30000/30000 [==============================] - 9s 317us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 29s 957us/step - loss: 0.1887 - acc: 0.9412\n",
      "30000/30000 [==============================] - 9s 302us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 28s 942us/step - loss: 0.1783 - acc: 0.9455\n",
      "30000/30000 [==============================] - 10s 319us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 28s 944us/step - loss: 0.1790 - acc: 0.9443\n",
      "30000/30000 [==============================] - 9s 311us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 27s 901us/step - loss: 0.1865 - acc: 0.9410\n",
      "30000/30000 [==============================] - 9s 312us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 0.1571 - acc: 0.9515\n",
      "30000/30000 [==============================] - 9s 312us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 28s 924us/step - loss: 0.3828 - acc: 0.8729\n",
      "30000/30000 [==============================] - 10s 320us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.4273 - acc: 0.8601\n",
      "30000/30000 [==============================] - 9s 315us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 28s 945us/step - loss: 0.1626 - acc: 0.9480\n",
      "30000/30000 [==============================] - 10s 335us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1737 - acc: 0.9463\n",
      "30000/30000 [==============================] - 10s 339us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.2845 - acc: 0.9084\n",
      "30000/30000 [==============================] - 13s 430us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 39s 1ms/step - loss: 0.3550 - acc: 0.8837\n",
      "30000/30000 [==============================] - 13s 427us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1734 - acc: 0.9464\n",
      "30000/30000 [==============================] - 10s 345us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 30s 984us/step - loss: 0.1786 - acc: 0.9438\n",
      "30000/30000 [==============================] - 10s 335us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  9.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 55s 916us/step - loss: 0.1173 - acc: 0.9641\n",
      "Best: 0.978817 using {'activation': 'linear', 'batch_size': 64, 'epochs': 1}\n",
      "10000/10000 [==============================] - 3s 349us/step\n",
      "Test loss 2.3055, accuracy 7.64%\n"
     ]
    }
   ],
   "source": [
    "#activations\n",
    "seed = 42\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [10, 50, 100, 120, 200],\n",
    "              'optimizer': [['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam', 'Adamax']],\n",
    "              'activation:_1' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation:_2' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation:_3' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation:_4' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "#BEST BATCH SIZE 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 968us/step - loss: 0.1643 - acc: 0.9502\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 770us/step - loss: 0.0504 - acc: 0.9844\n",
      "30000/30000 [==============================] - 10s 337us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1680 - acc: 0.9471\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 842us/step - loss: 0.0484 - acc: 0.9853\n",
      "30000/30000 [==============================] - 10s 349us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.6306 - acc: 0.7754\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 953us/step - loss: 0.0845 - acc: 0.9736\n",
      "30000/30000 [==============================] - 11s 366us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3832 - acc: 0.8673\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 893us/step - loss: 0.0697 - acc: 0.9785\n",
      "30000/30000 [==============================] - 11s 369us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.1785 - acc: 0.9449\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 864us/step - loss: 0.0700 - acc: 0.9786\n",
      "30000/30000 [==============================] - 12s 385us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.1865 - acc: 0.9437\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 867us/step - loss: 0.0673 - acc: 0.9796\n",
      "30000/30000 [==============================] - 11s 372us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 984us/step - loss: 0.1747 - acc: 0.94540s - loss: 0.1751 - acc: 0.9\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 784us/step - loss: 0.0696 - acc: 0.9787\n",
      "30000/30000 [==============================] - 11s 350us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1855 - acc: 0.9434: 0s - loss: 0.1861 - acc: 0.9\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 795us/step - loss: 0.0700 - acc: 0.9791\n",
      "30000/30000 [==============================] - 11s 355us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  9.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.1162 - acc: 0.9641\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 47s 784us/step - loss: 0.0404 - acc: 0.9880\n",
      "Best: 0.979783 using {'activation': 'relu', 'batch_size': 64, 'epochs': 2}\n",
      "10000/10000 [==============================] - 3s 330us/step\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.1601 - acc: 0.9510 - val_loss: 0.0467 - val_acc: 0.9857\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 49s 824us/step - loss: 0.0410 - acc: 0.9869 - val_loss: 0.0309 - val_acc: 0.9903\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 46s 774us/step - loss: 0.0271 - acc: 0.9919 - val_loss: 0.0316 - val_acc: 0.9897\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 47s 777us/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0337 - val_acc: 0.9904\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 46s 773us/step - loss: 0.0164 - acc: 0.9947 - val_loss: 0.0295 - val_acc: 0.9913\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 48s 793us/step - loss: 0.0140 - acc: 0.9954 - val_loss: 0.0322 - val_acc: 0.9895\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 47s 788us/step - loss: 0.0117 - acc: 0.9963 - val_loss: 0.0287 - val_acc: 0.9912\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 48s 793us/step - loss: 0.0111 - acc: 0.9966 - val_loss: 0.0284 - val_acc: 0.9911\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 46s 775us/step - loss: 0.0085 - acc: 0.9971 - val_loss: 0.0300 - val_acc: 0.9919\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 47s 788us/step - loss: 0.0095 - acc: 0.9968 - val_loss: 0.0312 - val_acc: 0.9919\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 49s 814us/step - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0309 - val_acc: 0.9918\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 47s 788us/step - loss: 0.0067 - acc: 0.9979 - val_loss: 0.0358 - val_acc: 0.9917\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 48s 792us/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0400 - val_acc: 0.9904\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 47s 785us/step - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0482 - val_acc: 0.9909\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 48s 792us/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0404 - val_acc: 0.9906\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 49s 811us/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0355 - val_acc: 0.9915\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 49s 810us/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0345 - val_acc: 0.9929\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 48s 802us/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0379 - val_acc: 0.9911\n",
      "Epoch 19/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9985"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-78b81b5931cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test loss {:.4f}, accuracy {:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[0;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                                              verbose=0)\n\u001b[0m\u001b[0;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                         \u001b[1;31m# Same labels assumed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel size\n",
    "seed = 42\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [4],\n",
    "              'batch_size': [10, 50, 100, 120, 200],\n",
    "              'optimizer': [['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam', 'Adamax']],\n",
    "              'activation:_1' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_2' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_3' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_4' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'kernel_size' : [[3,3], [4,4], [5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "#BEST BATCH SIZE 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pool size\n",
    "seed = 42\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [4],\n",
    "              'batch_size': [10, 50, 100, 120, 200],\n",
    "              'optimizer': [['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam', 'Adamax']],\n",
    "              'activation:_1' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_2' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_3' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_4' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'kernel_size' : [[3,3], [4,4], [5,5]],\n",
    "              'pool_size' : [[1,1], [2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "#BEST BATCH SIZE 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout 1\n",
    "seed = 42\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [4],\n",
    "              'batch_size': [10, 50, 100, 120, 200],\n",
    "              'optimizer': [['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam', 'Adamax']],\n",
    "              'activation:_1' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_2' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_3' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_4' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'kernel_size' : [[3,3], [4,4], [5,5]],\n",
    "              'pool_size' : [[1,1], [2,2]],\n",
    "              'dropout_1' : [0.05, 0.1, 0.2, 0.25, 0.3],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "#BEST BATCH SIZE 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout 2\n",
    "seed = 42\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [4],\n",
    "              'batch_size': [10, 50, 100, 120, 200],\n",
    "              'optimizer': [['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam', 'Adamax']],\n",
    "              'activation:_1' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_2' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_3' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'activation:_4' : ['elu','relu', 'linear', 'sigmoid', 'tanh', 'selu'],\n",
    "              'kernel_size' : [[3,3], [4,4], [5,5]],\n",
    "              'pool_size' : [[1,1], [2,2]],\n",
    "              'dropout_1' : [0.05, 0.1, 0.2, 0.25, 0.3],\n",
    "              'dropout_2' : [0.05, 0.1, 0.2, 0.25, 0.3]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "#BEST BATCH SIZE 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=50, verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "cb_list = [cb]\n",
    "hist = model.fit(x=x_train,y=y_train, epochs=20, batch_size=128, validation_data=(x_test, y_test), verbose=1)\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "#Test 1: all activations relu, 96.82% acc\n",
    "#Test 2: first layer tanh, 96.75% acc\n",
    "#Test 3: third layer tanh, 95.84% acc\n",
    "#Test 4: fifth layer tanh, 95.39% acc\n",
    "#Test 5: sixth layer tanh, 96.22% acc\n",
    "#It seems that the most successful activation function is rectified linear unit, so I am sticking with relu for 1st, 3rd, 5th, and 6h layer.\n",
    "#Test 6: Adadelta optimizer, 98.84% acc\n",
    "#Test 7: Adamax optimizer, 99.04% acc\n",
    "#Test 8: RMSprop optimizer, 99.03% acc\n",
    "#Test 9: Adagrad optimizer, 98.95% acc\n",
    "#Test 10: Adam optimizer, 99.01% acc\n",
    "#Test 11: Nadam optimizer, 99.15% acc <----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['acc'], 'o-')\n",
    "ax.plot([None] + hist.history['val_acc'], 'x-')\n",
    "ax.legend(['Train acc', 'Validation acc'], loc = 0)\n",
    "ax.set_title('Training/Validation acc per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['loss'], 'o-')\n",
    "ax.plot([None] + hist.history['val_loss'], 'x-')\n",
    "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
    "ax.set_title('Training/Validation Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
