{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.utils as np_utils\n",
    "from keras.models import Sequential\n",
    "from keras import models, layers\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import keras\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# resources:\n",
    "# https://engmrk.com/lenet-5-a-classic-cnn-architecture/\n",
    "# https://keras.io/\n",
    "# https://github.com/ryanleeallred/MNIST-convnet-gridsearch/blob/master/param_tuning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18c7e9bb488>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array(x_train[0], dtype='uint8')\n",
    "pixels = image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize value to [0, 1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Transform lables to one-hot encoding\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Reshape the dataset into 4D array\n",
    "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer, activation_1, activation_2, activation_3, activation_4, kernel_size, pool_size, dropout_1, dropout_2):\n",
    "    model = Sequential()\n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(6, kernel_size=kernel_size, strides=(1, 1), activation=activation_1, input_shape=(28,28,1), padding=\"same\"))\n",
    "\n",
    "    # First pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(1, 1), padding='valid'))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation=activation_2, padding='valid'))\n",
    "    \n",
    "    # Second pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "    \n",
    "    # Connected convolutional layer\n",
    "    model.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation=activation_3, padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dropout(dropout_1)) \n",
    "    # Connected layer\n",
    "    model.add(layers.Dense(84, activation=activation_4))\n",
    "    model.add(Dropout(dropout_2)) \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # build/compile\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.5045 - acc: 0.8432\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.3738 - acc: 0.8863\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 52s 2ms/step - loss: 0.3427 - acc: 0.8964\n",
      "30000/30000 [==============================] - 12s 405us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 0.4868 - acc: 0.8489\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 59s 2ms/step - loss: 0.3705 - acc: 0.8875\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 0.3467 - acc: 0.8921: 1s - loss\n",
      "30000/30000 [==============================] - 12s 405us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 29s 979us/step - loss: 0.4108 - acc: 0.8751\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 27s 909us/step - loss: 0.3092 - acc: 0.9068\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 908us/step - loss: 0.2672 - acc: 0.9187\n",
      "30000/30000 [==============================] - 8s 272us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 858us/step - loss: 0.4187 - acc: 0.8737\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 0.3205 - acc: 0.9025\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 885us/step - loss: 0.2715 - acc: 0.9182\n",
      "30000/30000 [==============================] - 9s 301us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 873us/step - loss: 0.4065 - acc: 0.8780\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.2869 - acc: 0.9141\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 24s 789us/step - loss: 0.2482 - acc: 0.9256\n",
      "30000/30000 [==============================] - 8s 260us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 806us/step - loss: 0.3881 - acc: 0.8834\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 24s 809us/step - loss: 0.2792 - acc: 0.9149\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 23s 773us/step - loss: 0.2512 - acc: 0.9230\n",
      "30000/30000 [==============================] - 8s 254us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 771us/step - loss: 0.3951 - acc: 0.8792\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 776us/step - loss: 0.2690 - acc: 0.9195\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 746us/step - loss: 0.2179 - acc: 0.9346\n",
      "30000/30000 [==============================] - 7s 247us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.3833 - acc: 0.8845\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 22s 748us/step - loss: 0.2793 - acc: 0.9167\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 728us/step - loss: 0.2465 - acc: 0.9255\n",
      "30000/30000 [==============================] - 8s 255us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 799us/step - loss: 0.4084 - acc: 0.8758\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 22s 717us/step - loss: 0.2584 - acc: 0.9224\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 25s 826us/step - loss: 0.2179 - acc: 0.9357\n",
      "30000/30000 [==============================] - 8s 257us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 856us/step - loss: 0.3892 - acc: 0.8824\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 24s 793us/step - loss: 0.2524 - acc: 0.9251\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 717us/step - loss: 0.2195 - acc: 0.9325\n",
      "30000/30000 [==============================] - 8s 257us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 16.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 47s 777us/step - loss: 0.3427 - acc: 0.8976\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 46s 774us/step - loss: 0.2414 - acc: 0.9273\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 45s 745us/step - loss: 0.1901 - acc: 0.9423\n",
      "Best: 0.947733 using {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [5, 5], 'optimizer': 'SGD', 'pool_size': [2, 2]}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0f792a6a5bcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mstds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'std_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test loss {:.4f}, accuracy {:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [10, 50, 100, 120, 200],\n",
    "              'optimizer': ['SGD'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['tanh'],\n",
    "              'activation_3' : ['tanh'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 7 candidates, totalling 14 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.2893 - acc: 0.9112\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 701us/step - loss: 0.0869 - acc: 0.9739\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 744us/step - loss: 0.0605 - acc: 0.9825\n",
      "30000/30000 [==============================] - 7s 234us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 786us/step - loss: 0.2673 - acc: 0.9184\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 717us/step - loss: 0.0703 - acc: 0.9789\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 717us/step - loss: 0.0489 - acc: 0.9852\n",
      "30000/30000 [==============================] - 7s 232us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 814us/step - loss: 0.2732 - acc: 0.9137\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 768us/step - loss: 0.0760 - acc: 0.9762\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 719us/step - loss: 0.0511 - acc: 0.9854\n",
      "30000/30000 [==============================] - 7s 243us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 755us/step - loss: 0.3068 - acc: 0.9066\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 704us/step - loss: 0.0789 - acc: 0.9772\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 705us/step - loss: 0.0556 - acc: 0.9829\n",
      "30000/30000 [==============================] - 8s 280us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 878us/step - loss: 0.2849 - acc: 0.9104\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 700us/step - loss: 0.0803 - acc: 0.9756\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 703us/step - loss: 0.0531 - acc: 0.9842\n",
      "30000/30000 [==============================] - 7s 237us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 758us/step - loss: 0.2668 - acc: 0.9157\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 698us/step - loss: 0.0710 - acc: 0.9777\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 697us/step - loss: 0.0478 - acc: 0.9852\n",
      "30000/30000 [==============================] - 7s 239us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 757us/step - loss: 0.2923 - acc: 0.9081\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 699us/step - loss: 0.0733 - acc: 0.9776\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 728us/step - loss: 0.0516 - acc: 0.9848\n",
      "30000/30000 [==============================] - 8s 277us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 780us/step - loss: 0.2576 - acc: 0.9196\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 702us/step - loss: 0.0782 - acc: 0.9759\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 701us/step - loss: 0.0532 - acc: 0.9834\n",
      "30000/30000 [==============================] - 8s 257us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.2827 - acc: 0.9114\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 705us/step - loss: 0.0822 - acc: 0.9761\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 713us/step - loss: 0.0548 - acc: 0.9834\n",
      "30000/30000 [==============================] - 7s 247us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 25s 837us/step - loss: 0.2750 - acc: 0.9132\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 762us/step - loss: 0.0767 - acc: 0.9770\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 744us/step - loss: 0.0481 - acc: 0.9854\n",
      "30000/30000 [==============================] - 8s 252us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 762us/step - loss: 0.3066 - acc: 0.9053\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 22s 729us/step - loss: 0.0875 - acc: 0.9739\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.0590 - acc: 0.982 - 21s 704us/step - loss: 0.0588 - acc: 0.9829\n",
      "30000/30000 [==============================] - 7s 242us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 0.2487 - acc: 0.9257\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 751us/step - loss: 0.0681 - acc: 0.9794\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 23s 754us/step - loss: 0.0469 - acc: 0.9859\n",
      "30000/30000 [==============================] - 7s 248us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.2964 - acc: 0.9049\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 710us/step - loss: 0.0843 - acc: 0.9739\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 709us/step - loss: 0.0568 - acc: 0.9832\n",
      "30000/30000 [==============================] - 7s 246us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.2925 - acc: 0.9104\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 706us/step - loss: 0.0799 - acc: 0.9760\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 709us/step - loss: 0.0542 - acc: 0.9833\n",
      "30000/30000 [==============================] - 8s 250us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 17.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 48s 793us/step - loss: 0.1751 - acc: 0.9461\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 46s 768us/step - loss: 0.0518 - acc: 0.9844\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 44s 737us/step - loss: 0.0375 - acc: 0.9882\n",
      "Best: 0.986650 using {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n"
     ]
    }
   ],
   "source": [
    "#optimizer\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam', 'Adamax'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['tanh'],\n",
    "              'activation_3' : ['tanh'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE: 64\n",
    "#BEST OPTIMIZER: NADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 81 candidates, totalling 162 fits\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3068 - acc: 0.9061\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 850us/step - loss: 0.0878 - acc: 0.9728\n",
      "30000/30000 [==============================] - 7s 244us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 944us/step - loss: 0.2691 - acc: 0.9176\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 786us/step - loss: 0.0740 - acc: 0.9777\n",
      "30000/30000 [==============================] - 7s 223us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 22s 742us/step - loss: 0.3370 - acc: 0.9051\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 0.0987 - acc: 0.9725\n",
      "30000/30000 [==============================] - 7s 245us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 0.3500 - acc: 0.9018\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 803us/step - loss: 0.0910 - acc: 0.9761\n",
      "30000/30000 [==============================] - 7s 221us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 842us/step - loss: 0.2273 - acc: 0.9307\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 741us/step - loss: 0.0617 - acc: 0.9816\n",
      "30000/30000 [==============================] - 7s 234us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 23s 776us/step - loss: 0.2408 - acc: 0.9249\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 763us/step - loss: 0.0669 - acc: 0.97970s - loss: 0.0679 - acc\n",
      "30000/30000 [==============================] - 8s 280us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 24s 812us/step - loss: 1.2013 - acc: 0.6314\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 825us/step - loss: 0.4596 - acc: 0.8500\n",
      "30000/30000 [==============================] - 7s 248us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 1.0654 - acc: 0.6352\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 0.3424 - acc: 0.8884\n",
      "30000/30000 [==============================] - 7s 244us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 915us/step - loss: 0.5992 - acc: 0.8150\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 822us/step - loss: 0.1239 - acc: 0.9643\n",
      "30000/30000 [==============================] - 8s 264us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 905us/step - loss: 2.3941 - acc: 0.0992\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 859us/step - loss: 2.3301 - acc: 0.1004\n",
      "30000/30000 [==============================] - 8s 261us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 24s 817us/step - loss: 2.7127 - acc: 0.1005\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 905us/step - loss: 2.3988 - acc: 0.1017\n",
      "30000/30000 [==============================] - 9s 308us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 946us/step - loss: 2.5833 - acc: 0.1006\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 2.3869 - acc: 0.1045\n",
      "30000/30000 [==============================] - 9s 297us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 893us/step - loss: 0.2715 - acc: 0.9138\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 770us/step - loss: 0.0894 - acc: 0.9735\n",
      "30000/30000 [==============================] - 8s 259us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 849us/step - loss: 0.2657 - acc: 0.9185\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 0.0864 - acc: 0.9739\n",
      "30000/30000 [==============================] - 7s 249us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 875us/step - loss: 0.3550 - acc: 0.90410s - loss: 0.3590 - acc: 0\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.1097 - acc: 0.9707\n",
      "30000/30000 [==============================] - 8s 259us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 837us/step - loss: 0.3511 - acc: 0.9029\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 21s 716us/step - loss: 0.1085 - acc: 0.9706\n",
      "30000/30000 [==============================] - 7s 248us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.2769 - acc: 0.9157\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 873us/step - loss: 0.0874 - acc: 0.9738\n",
      "30000/30000 [==============================] - 11s 364us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.2240 - acc: 0.9305\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 903us/step - loss: 0.0824 - acc: 0.9749\n",
      "30000/30000 [==============================] - 9s 302us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.9773 - acc: 0.6693\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.2088 - acc: 0.9362\n",
      "30000/30000 [==============================] - 10s 341us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.8088 - acc: 0.7175\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 938us/step - loss: 0.1293 - acc: 0.9612\n",
      "30000/30000 [==============================] - 8s 271us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 865us/step - loss: 0.7441 - acc: 0.7501\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 60s 2ms/step - loss: 0.1149 - acc: 0.9682: 5s - los\n",
      "30000/30000 [==============================] - 26s 851us/step\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.8855 - acc: 0.6967\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 839us/step - loss: 0.1198 - acc: 0.96781s - loss: 0.\n",
      "30000/30000 [==============================] - 9s 292us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 873us/step - loss: 0.7246 - acc: 0.7613\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 0.1414 - acc: 0.9572\n",
      "30000/30000 [==============================] - 9s 288us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 937us/step - loss: 0.6164 - acc: 0.8063\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 818us/step - loss: 0.1214 - acc: 0.9633\n",
      "30000/30000 [==============================] - 9s 294us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 950us/step - loss: 2.3693 - acc: 0.10800s - loss: 2.3703 - acc: \n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 2.2348 - acc: 0.1306\n",
      "30000/30000 [==============================] - 9s 288us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 981us/step - loss: 2.1251 - acc: 0.207110s - loss: 2.2621 - acc: - E\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 784us/step - loss: 1.4868 - acc: 0.4507\n",
      "30000/30000 [==============================] - 9s 290us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 941us/step - loss: 2.0728 - acc: 0.2412\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.2377 - acc: 0.9359\n",
      "30000/30000 [==============================] - 11s 372us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 2.4168 - acc: 0.1029\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.3282 - acc: 0.1035- ETA: 1s - loss: 2.3285 - acc: 0.103 - ETA: 1s - loss: 2.3 - 25s 830us/step - loss: 2.3281 - acc: 0.1035\n",
      "30000/30000 [==============================] - 8s 277us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 939us/step - loss: 2.6148 - acc: 0.0983\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 844us/step - loss: 2.3942 - acc: 0.1036\n",
      "30000/30000 [==============================] - 8s 281us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 907us/step - loss: 2.5931 - acc: 0.1023\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 856us/step - loss: 2.3978 - acc: 0.0997\n",
      "30000/30000 [==============================] - 9s 291us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 921us/step - loss: 2.3815 - acc: 0.1090\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 2.3015 - acc: 0.11062s - l\n",
      "30000/30000 [==============================] - 9s 297us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 963us/step - loss: 2.4272 - acc: 0.1085\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 9s 296us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.4159 - acc: 0.1025\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 840us/step - loss: 2.3303 - acc: 0.10217\n",
      "30000/30000 [==============================] - 9s 289us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 0.7081 - acc: 0.7856\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 915us/step - loss: 0.2039 - acc: 0.9451\n",
      "30000/30000 [==============================] - 10s 332us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.6365 - acc: 0.1000\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 2.4060 - acc: 0.1029\n",
      "30000/30000 [==============================] - 13s 442us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 46s 2ms/step - loss: 2.5748 - acc: 0.1001: 5\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 2.3961 - acc: 0.1020\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2679 - acc: 0.9174\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.0854 - acc: 0.9747\n",
      "30000/30000 [==============================] - 14s 479us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.2619 - acc: 0.9207\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 809us/step - loss: 0.0870 - acc: 0.97381s - loss: 0.0880 - ETA: 0s - loss: 0.0874 - acc: 0.\n",
      "30000/30000 [==============================] - 9s 287us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 940us/step - loss: 0.3253 - acc: 0.9105\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 826us/step - loss: 0.0897 - acc: 0.9762\n",
      "30000/30000 [==============================] - 9s 301us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 992us/step - loss: 0.2876 - acc: 0.9204\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 863us/step - loss: 0.0982 - acc: 0.9725\n",
      "30000/30000 [==============================] - 9s 291us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 0.2034 - acc: 0.93733s\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 810us/step - loss: 0.0636 - acc: 0.9797\n",
      "30000/30000 [==============================] - 9s 297us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 928us/step - loss: 0.2062 - acc: 0.9367\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 813us/step - loss: 0.0657 - acc: 0.9796\n",
      "30000/30000 [==============================] - 9s 301us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 1.9946 - acc: 0.2695\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 937us/step - loss: 1.3857 - acc: 0.5064\n",
      "30000/30000 [==============================] - 9s 293us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 1.9863 - acc: 0.2574\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 1.0810 - acc: 0.6029\n",
      "30000/30000 [==============================] - 12s 392us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 42s 1ms/step - loss: 2.3942 - acc: 0.1010\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3301 - acc: 0.1011\n",
      "30000/30000 [==============================] - 10s 350us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.7000 - acc: 0.7858\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.1282 - acc: 0.9654\n",
      "30000/30000 [==============================] - 11s 351us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.6079 - acc: 0.1025\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 936us/step - loss: 2.3895 - acc: 0.1029\n",
      "30000/30000 [==============================] - 11s 367us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.6407 - acc: 0.1023\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 909us/step - loss: 2.3959 - acc: 0.10170s - loss: 2.3971 - acc: \n",
      "30000/30000 [==============================] - 9s 308us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3017 - acc: 0.9071\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 942us/step - loss: 0.1117 - acc: 0.9673\n",
      "30000/30000 [==============================] - 13s 439us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.2920 - acc: 0.9107\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 882us/step - loss: 0.1275 - acc: 0.9627\n",
      "30000/30000 [==============================] - 10s 334us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 982us/step - loss: 0.4199 - acc: 0.8846\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 840us/step - loss: 0.1571 - acc: 0.9564\n",
      "30000/30000 [==============================] - 9s 310us/step\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.4001 - acc: 0.8910\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 902us/step - loss: 0.1593 - acc: 0.9571\n",
      "30000/30000 [==============================] - 9s 303us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.2615 - acc: 0.9205\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 998us/step - loss: 0.1240 - acc: 0.96164s - loss: 0.1258 - acc - ETA: 3s - \n",
      "30000/30000 [==============================] - 12s 409us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.2490 - acc: 0.9241\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 914us/step - loss: 0.1056 - acc: 0.9685\n",
      "30000/30000 [==============================] - 10s 322us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.5384 - acc: 0.8248\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.1473 - acc: 0.9554\n",
      "30000/30000 [==============================] - 12s 385us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.6885 - acc: 0.7706\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 770us/step - loss: 0.1862 - acc: 0.9436\n",
      "30000/30000 [==============================] - 9s 300us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 0.6520 - acc: 0.7923\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1546 - acc: 0.9554\n",
      "30000/30000 [==============================] - 10s 324us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 962us/step - loss: 0.6232 - acc: 0.8083\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 781us/step - loss: 0.1532 - acc: 0.9573\n",
      "30000/30000 [==============================] - 10s 323us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 934us/step - loss: 0.5838 - acc: 0.8115\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 764us/step - loss: 0.1321 - acc: 0.9585\n",
      "30000/30000 [==============================] - 14s 457us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.4659 - acc: 0.8559\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1324 - acc: 0.9594\n",
      "30000/30000 [==============================] - 13s 434us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.3595 - acc: 0.111 - 29s 961us/step - loss: 2.3592 - acc: 0.1114\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 958us/step - loss: 1.2928 - acc: 0.5558\n",
      "30000/30000 [==============================] - 9s 305us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3863 - acc: 0.1135\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 897us/step - loss: 2.3011 - acc: 0.1141\n",
      "30000/30000 [==============================] - 12s 402us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 2.3786 - acc: 0.1018\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 800us/step - loss: 2.3239 - acc: 0.10422\n",
      "30000/30000 [==============================] - 11s 350us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 970us/step - loss: 2.3869 - acc: 0.1020\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 2.3317 - acc: 0.1023\n",
      "30000/30000 [==============================] - 10s 333us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.5996 - acc: 0.0998\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 734us/step - loss: 2.3917 - acc: 0.1028\n",
      "30000/30000 [==============================] - 10s 339us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.6082 - acc: 0.0994\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.3949 - acc: 0.099 - 24s 791us/step - loss: 2.3947 - acc: 0.0996\n",
      "30000/30000 [==============================] - 9s 315us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.7952 - acc: 0.734 - 29s 982us/step - loss: 0.7936 - acc: 0.7348\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 781us/step - loss: 0.2785 - acc: 0.9166\n",
      "30000/30000 [==============================] - 10s 330us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.6540 - acc: 0.7857\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.2552 - acc: 0.9227\n",
      "30000/30000 [==============================] - 10s 318us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 973us/step - loss: 0.6443 - acc: 0.8049\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 754us/step - loss: 0.2827 - acc: 0.9188\n",
      "30000/30000 [==============================] - 10s 322us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 993us/step - loss: 1.0580 - acc: 0.6501\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 772us/step - loss: 0.3137 - acc: 0.9113\n",
      "30000/30000 [==============================] - 10s 324us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 999us/step - loss: 0.5935 - acc: 0.8164\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 791us/step - loss: 0.2421 - acc: 0.9275\n",
      "30000/30000 [==============================] - 10s 328us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 997us/step - loss: 0.6823 - acc: 0.7985\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 780us/step - loss: 0.2696 - acc: 0.9193\n",
      "30000/30000 [==============================] - 10s 330us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3099 - acc: 0.1072\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 833us/step - loss: 2.3016 - acc: 0.1106\n",
      "30000/30000 [==============================] - 11s 359us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3062 - acc: 0.1122\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 11s 360us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3126 - acc: 0.1081\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 860us/step - loss: 2.3049 - acc: 0.1071\n",
      "30000/30000 [==============================] - 11s 378us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3152 - acc: 0.1122: 1s - loss: 2.3161\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 912us/step - loss: 2.3037 - acc: 0.1102\n",
      "30000/30000 [==============================] - 12s 385us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.3176 - acc: 0.1072\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 2.3020 - acc: 0.1100\n",
      "30000/30000 [==============================] - 12s 393us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.3209 - acc: 0.1125\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 918us/step - loss: 2.3016 - acc: 0.1134\n",
      "30000/30000 [==============================] - 12s 403us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3416 - acc: 0.1088\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 892us/step - loss: 2.3015 - acc: 0.1106\n",
      "30000/30000 [==============================] - 12s 388us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 2.3696 - acc: 0.1097\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 893us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 11s 379us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.4168 - acc: 0.1016\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 863us/step - loss: 2.3386 - acc: 0.1009\n",
      "30000/30000 [==============================] - 12s 394us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 2.3345 - acc: 0.1078\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 851us/step - loss: 2.3013 - acc: 0.1140\n",
      "30000/30000 [==============================] - 11s 369us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.6424 - acc: 0.1013: 8s - los\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 843us/step - loss: 2.4050 - acc: 0.1005\n",
      "30000/30000 [==============================] - 11s 373us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 2.6207 - acc: 0.1045\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 844us/step - loss: 2.3943 - acc: 0.0982\n",
      "30000/30000 [==============================] - 12s 416us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.4100 - acc: 0.1076\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 833us/step - loss: 2.3016 - acc: 0.1106\n",
      "30000/30000 [==============================] - 11s 376us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3954 - acc: 0.1107\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 847us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 12s 384us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 1.1090 - acc: 0.6230\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 944us/step - loss: 0.3247 - acc: 0.9056\n",
      "30000/30000 [==============================] - 14s 457us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.3719 - acc: 0.0991\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 894us/step - loss: 2.3205 - acc: 0.1046\n",
      "30000/30000 [==============================] - 12s 407us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.5792 - acc: 0.102 - 38s 1ms/step - loss: 2.5783 - acc: 0.1027\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 875us/step - loss: 2.3947 - acc: 0.1008\n",
      "30000/30000 [==============================] - 12s 406us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 2.5431 - acc: 0.1009: 6s - loss: - ETA: 3s - loss\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 903us/step - loss: 2.3918 - acc: 0.1057\n",
      "30000/30000 [==============================] - 13s 425us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.4916 - acc: 0.8377\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 892us/step - loss: 0.1318 - acc: 0.9603\n",
      "30000/30000 [==============================] - 12s 402us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.8665 - acc: 0.7036\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.1594 - acc: 0.9527\n",
      "30000/30000 [==============================] - 18s 583us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.4519 - acc: 0.8635\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.1269 - acc: 0.9646\n",
      "30000/30000 [==============================] - 18s 615us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 0.5286 - acc: 0.8363\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.1307 - acc: 0.9639\n",
      "30000/30000 [==============================] - 19s 633us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 66s 2ms/step - loss: 0.6131 - acc: 0.8036\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 46s 2ms/step - loss: 0.1305 - acc: 0.9594\n",
      "30000/30000 [==============================] - 33s 1ms/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 80s 3ms/step - loss: 0.5222 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 45s 2ms/step - loss: 0.1120 - acc: 0.9653\n",
      "30000/30000 [==============================] - 14s 475us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 2.3959 - acc: 0.1079\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 950us/step - loss: 2.3009 - acc: 0.1100\n",
      "30000/30000 [==============================] - 13s 429us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 2.3674 - acc: 0.1131\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.1624 - acc: 0.1770\n",
      "30000/30000 [==============================] - 14s 474us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 2.4001 - acc: 0.0987\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 930us/step - loss: 2.3328 - acc: 0.1014\n",
      "30000/30000 [==============================] - 13s 445us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 1.0532 - acc: 0.6432\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 942us/step - loss: 0.1748 - acc: 0.9517\n",
      "30000/30000 [==============================] - 14s 458us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 2.6046 - acc: 0.1039\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 928us/step - loss: 2.3978 - acc: 0.1015\n",
      "30000/30000 [==============================] - 16s 519us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 2.6197 - acc: 0.1016\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 2.4023 - acc: 0.1013\n",
      "30000/30000 [==============================] - 16s 524us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 2.3936 - acc: 0.1184\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 926us/step - loss: 2.3016 - acc: 0.1106\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.5717 - acc: 0.8132\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 930us/step - loss: 0.2347 - acc: 0.9277\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.6377 - acc: 0.8112\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 912us/step - loss: 0.2786 - acc: 0.9213\n",
      "30000/30000 [==============================] - 14s 476us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.6327 - acc: 0.8137\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.2914 - acc: 0.9180\n",
      "30000/30000 [==============================] - 14s 471us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 45s 1ms/step - loss: 2.6483 - acc: 0.0980\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 952us/step - loss: 2.4084 - acc: 0.1017\n",
      "30000/30000 [==============================] - 14s 478us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 0.5954 - acc: 0.8302\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 970us/step - loss: 0.2757 - acc: 0.9182\n",
      "30000/30000 [==============================] - 14s 470us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.2676 - acc: 0.917 - 38s 1ms/step - loss: 0.2672 - acc: 0.9174\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 932us/step - loss: 0.0741 - acc: 0.9769\n",
      "30000/30000 [==============================] - 14s 466us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 45s 2ms/step - loss: 0.2616 - acc: 0.9210: 5s -\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 898us/step - loss: 0.0724 - acc: 0.9777\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 42s 1ms/step - loss: 0.3030 - acc: 0.9176\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 851us/step - loss: 0.0847 - acc: 0.97700s - loss: 0.0851 - acc: \n",
      "30000/30000 [==============================] - 14s 454us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 39s 1ms/step - loss: 0.3291 - acc: 0.9057: 11s - l - ETA: 7s - loss: 0.3778 - acc:\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 767us/step - loss: 0.0930 - acc: 0.9751\n",
      "30000/30000 [==============================] - 13s 418us/step\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.2296 - acc: 0.9289\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 882us/step - loss: 0.0676 - acc: 0.9795\n",
      "30000/30000 [==============================] - 14s 480us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 42s 1ms/step - loss: 0.2045 - acc: 0.9361\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 848us/step - loss: 0.0626 - acc: 0.9813\n",
      "30000/30000 [==============================] - 14s 479us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 45s 1ms/step - loss: 1.1618 - acc: 0.6427\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 0.3634 - acc: 0.8830\n",
      "30000/30000 [==============================] - 14s 475us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 0.9788 - acc: 0.6917: 3s - loss: \n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 904us/step - loss: 0.3287 - acc: 0.8964\n",
      "30000/30000 [==============================] - 16s 546us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.5789 - acc: 0.8237\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 943us/step - loss: 0.1272 - acc: 0.9649\n",
      "30000/30000 [==============================] - 15s 496us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.6186 - acc: 0.8108\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 950us/step - loss: 0.1254 - acc: 0.9652\n",
      "30000/30000 [==============================] - 16s 543us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 2.5931 - acc: 0.1000: \n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 923us/step - loss: 2.3818 - acc: 0.1002\n",
      "30000/30000 [==============================] - 17s 583us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.6142 - acc: 0.1030\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.4059 - acc: 0.0988\n",
      "30000/30000 [==============================] - 18s 596us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.2559 - acc: 0.9217\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.0914 - acc: 0.9732\n",
      "30000/30000 [==============================] - 17s 562us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.2401 - acc: 0.9252: 3s - loss: 0.24 - ETA: 0s - loss: 0.2412 - acc: 0.92\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 985us/step - loss: 0.0855 - acc: 0.9750\n",
      "30000/30000 [==============================] - 18s 606us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.3212 - acc: 0.9124\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 895us/step - loss: 0.1136 - acc: 0.9684\n",
      "30000/30000 [==============================] - 15s 494us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.3279 - acc: 0.9125\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 895us/step - loss: 0.1091 - acc: 0.9707\n",
      "30000/30000 [==============================] - 15s 505us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.2371 - acc: 0.9278\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 925us/step - loss: 0.0840 - acc: 0.9757\n",
      "30000/30000 [==============================] - 15s 493us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.2213 - acc: 0.9332\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 896us/step - loss: 0.0838 - acc: 0.9746\n",
      "30000/30000 [==============================] - 16s 526us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.7564 - acc: 0.7460\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 945us/step - loss: 0.1891 - acc: 0.9413\n",
      "30000/30000 [==============================] - 16s 542us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.8830 - acc: 0.6932\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1683 - acc: 0.9497\n",
      "30000/30000 [==============================] - 17s 557us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.7694 - acc: 0.7549\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 975us/step - loss: 0.1865 - acc: 0.9479\n",
      "30000/30000 [==============================] - 17s 573us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.7521 - acc: 0.7620\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 956us/step - loss: 0.2027 - acc: 0.9416\n",
      "30000/30000 [==============================] - 19s 619us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 2.3178 - acc: 0.1081\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 971us/step - loss: 2.3020 - acc: 0.1094\n",
      "30000/30000 [==============================] - 17s 569us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 1.3112 - acc: 0.5234\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 979us/step - loss: 0.1522 - acc: 0.9542\n",
      "30000/30000 [==============================] - 17s 577us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 1.8433 - acc: 0.3294\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.6902 - acc: 0.7578\n",
      "30000/30000 [==============================] - 21s 707us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 65s 2ms/step - loss: 2.2924 - acc: 0.1381\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 1.7268 - acc: 0.3586\n",
      "30000/30000 [==============================] - 17s 559us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 1.1062 - acc: 0.6376\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1898 - acc: 0.9473\n",
      "30000/30000 [==============================] - 18s 596us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.8587 - acc: 0.7286\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 0.1830 - acc: 0.9501\n",
      "30000/30000 [==============================] - 18s 616us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.6756 - acc: 0.1037\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.4071 - acc: 0.1007\n",
      "30000/30000 [==============================] - 19s 647us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.5617 - acc: 0.1005\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3888 - acc: 0.0996\n",
      "30000/30000 [==============================] - 17s 552us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 2.3584 - acc: 0.1084\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 907us/step - loss: 2.3016 - acc: 0.1103\n",
      "30000/30000 [==============================] - 16s 542us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.3843 - acc: 0.1118\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3011 - acc: 0.1142\n",
      "30000/30000 [==============================] - 19s 650us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.4940 - acc: 0.0998\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 987us/step - loss: 2.3498 - acc: 0.1028\n",
      "30000/30000 [==============================] - 18s 599us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 1.3521 - acc: 0.5263\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.2496 - acc: 0.9293\n",
      "30000/30000 [==============================] - 19s 627us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 59s 2ms/step - loss: 2.6631 - acc: 0.0990\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3968 - acc: 0.0990\n",
      "30000/30000 [==============================] - 20s 651us/step\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.6428 - acc: 0.1021\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3912 - acc: 0.0983\n",
      "30000/30000 [==============================] - 20s 677us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.2509 - acc: 0.9241\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 0.0941 - acc: 0.9718\n",
      "30000/30000 [==============================] - 19s 627us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.2474 - acc: 0.9243\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.0924 - acc: 0.9720\n",
      "30000/30000 [==============================] - 19s 645us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 58s 2ms/step - loss: 0.2918 - acc: 0.9190\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.0995 - acc: 0.9728\n",
      "30000/30000 [==============================] - 21s 687us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.3055 - acc: 0.9172\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.1005 - acc: 0.9729: 0s - loss: 0.1007 - acc: 0\n",
      "30000/30000 [==============================] - 17s 566us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.2136 - acc: 0.9338\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 0.0840 - acc: 0.9738\n",
      "30000/30000 [==============================] - 17s 565us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.2215 - acc: 0.9335\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 946us/step - loss: 0.0801 - acc: 0.9754\n",
      "30000/30000 [==============================] - 20s 668us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 1.6021 - acc: 0.4322\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.7850 - acc: 0.6976\n",
      "30000/30000 [==============================] - 20s 656us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 60s 2ms/step - loss: 1.3191 - acc: 0.5560\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.5775 - acc: 0.7959\n",
      "30000/30000 [==============================] - 19s 641us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 61s 2ms/step - loss: 0.6512 - acc: 0.7991\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 0.1207 - acc: 0.9667\n",
      "30000/30000 [==============================] - 24s 806us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 1.8445 - acc: 0.3339\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.1730 - acc: 0.9535\n",
      "30000/30000 [==============================] - 20s 654us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 55s 2ms/step - loss: 2.6058 - acc: 0.0965\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.3906 - acc: 0.1032\n",
      "30000/30000 [==============================] - 20s 658us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.6059 - acc: 0.1038\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3946 - acc: 0.1023\n",
      "30000/30000 [==============================] - 19s 630us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.3718 - acc: 0.8872\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 981us/step - loss: 0.2129 - acc: 0.9364\n",
      "30000/30000 [==============================] - 19s 622us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.3641 - acc: 0.8905\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 983us/step - loss: 0.2208 - acc: 0.9347\n",
      "30000/30000 [==============================] - 19s 632us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.4252 - acc: 0.8852\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 985us/step - loss: 0.1745 - acc: 0.9515\n",
      "30000/30000 [==============================] - 21s 688us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 67s 2ms/step - loss: 0.4293 - acc: 0.8825\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1979 - acc: 0.9449\n",
      "30000/30000 [==============================] - 18s 614us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.3736 - acc: 0.8884\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 985us/step - loss: 0.2565 - acc: 0.9232\n",
      "30000/30000 [==============================] - 19s 621us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 60s 2ms/step - loss: 0.3912 - acc: 0.8807\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.2770 - acc: 0.9166\n",
      "30000/30000 [==============================] - 18s 614us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed: 222.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.1467 - acc: 0.9543\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 59s 984us/step - loss: 0.0474 - acc: 0.9856\n",
      "Best: 0.983333 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.983100 (0.001367) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981167 (0.000600) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.982650 (0.000217) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.958250 (0.005183) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.543033 (0.432400) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.103233 (0.007400) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981467 (0.000700) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.975683 (0.003283) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.979317 (0.002017) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.972117 (0.004217) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.976633 (0.000333) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.973900 (0.001367) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.544983 (0.259817) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.537467 (0.426833) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.533700 (0.430133) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.106533 (0.004100) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981617 (0.000717) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981117 (0.001017) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.979517 (0.003783) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.879150 (0.054083) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.537950 (0.437850) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.103233 (0.007400) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.976067 (0.001400) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.969067 (0.000200) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.969183 (0.003317) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.968950 (0.003183) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.970950 (0.000950) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.971183 (0.001783) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.494950 (0.384317) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.109683 (0.004417) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.949267 (0.001533) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.943850 (0.001083) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.943767 (0.006300) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.100833 (0.002733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.106417 (0.007683) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.521483 (0.410850) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.972200 (0.001533) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.970467 (0.001767) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.972067 (0.003633) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.422233 (0.308133) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.536567 (0.433000) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.105367 (0.005267) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.533617 (0.419517) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.940833 (0.001767) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.516667 (0.417967) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981567 (0.001300) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.980467 (0.001100) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.983333 (0.001200) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.961700 (0.002567) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.974083 (0.000117) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.980867 (0.001000) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.977683 (0.000417) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.980650 (0.000550) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.971083 (0.000783) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.965633 (0.002733) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.541417 (0.427317) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.775783 (0.158417) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.965500 (0.000167) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.105650 (0.008450) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.535217 (0.421117) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.104450 (0.006183) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.979050 (0.002183) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.977733 (0.000467) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.978100 (0.000333) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.947850 (0.008617) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.973317 (0.003050) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.108017 (0.006083) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.959717 (0.000150) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.963767 (0.001600) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.936933 (0.005800) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "Best: 0.983333 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 14s 1ms/step\n",
      "Test Accuracy 0.9882000062465668\n"
     ]
    }
   ],
   "source": [
    "#activations\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [2],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation_2' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation_3' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation_4' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam\n",
    "#BEST ACTIVATIONS tanh, relu, relu, tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.2527 - acc: 0.9246\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 0.0674 - acc: 0.9795\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 879us/step - loss: 0.0484 - acc: 0.9850\n",
      "30000/30000 [==============================] - 17s 577us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2119 - acc: 0.9360\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 861us/step - loss: 0.0561 - acc: 0.9829\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 0.0385 - acc: 0.9879\n",
      "30000/30000 [==============================] - 18s 589us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2103 - acc: 0.9345\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 867us/step - loss: 0.0648 - acc: 0.9806\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 855us/step - loss: 0.0441 - acc: 0.9865\n",
      "30000/30000 [==============================] - 18s 611us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 52s 2ms/step - loss: 0.2170 - acc: 0.9339: 3s - loss: 0.2258\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 881us/step - loss: 0.0624 - acc: 0.9808\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 884us/step - loss: 0.0393 - acc: 0.9875\n",
      "30000/30000 [==============================] - 18s 588us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2287 - acc: 0.9307\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 849us/step - loss: 0.0677 - acc: 0.9794\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 0.0435 - acc: 0.9867\n",
      "30000/30000 [==============================] - 18s 594us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.2214 - acc: 0.9315\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 28s 938us/step - loss: 0.0654 - acc: 0.9795\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 28s 937us/step - loss: 0.0435 - acc: 0.9864\n",
      "30000/30000 [==============================] - 18s 608us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 12.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.1395 - acc: 0.957 - 76s 1ms/step - loss: 0.1393 - acc: 0.9579\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 52s 866us/step - loss: 0.0487 - acc: 0.9848\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 52s 861us/step - loss: 0.0359 - acc: 0.9890\n",
      "Best: 0.986400 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.985950 (0.000683) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [3, 3], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.986400 (0.001067) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.984433 (0.000833) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "Best: 0.986400 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "Test Accuracy 0.9908000066280365\n"
     ]
    }
   ],
   "source": [
    "#kernel size\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[3,3], [4,4], [5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam\n",
    "#BEST ACTIVATIONS tanh, relu, relu, tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.1788 - acc: 0.9440\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 882us/step - loss: 0.0474 - acc: 0.9849\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 0.0274 - acc: 0.9914\n",
      "30000/30000 [==============================] - 18s 601us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 0.1776 - acc: 0.9472\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 877us/step - loss: 0.0431 - acc: 0.9872\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 0.0231 - acc: 0.9936\n",
      "30000/30000 [==============================] - 18s 599us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 0.1835 - acc: 0.9423\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 872us/step - loss: 0.0474 - acc: 0.9860\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 864us/step - loss: 0.0309 - acc: 0.9903\n",
      "30000/30000 [==============================] - 18s 604us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.1943 - acc: 0.9389- ETA: 1s - loss: 0.1996 - ac\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 818us/step - loss: 0.0466 - acc: 0.9865\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.0258 - acc: 0.9922\n",
      "30000/30000 [==============================] - 18s 597us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.1136 - acc: 0.9648\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 52s 862us/step - loss: 0.0338 - acc: 0.9893\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 52s 863us/step - loss: 0.0223 - acc: 0.9932\n",
      "Best: 0.985667 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985667 (0.000733) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.983400 (0.000033) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "Best: 0.985667 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "Test Accuracy 0.9916000044345856\n"
     ]
    }
   ],
   "source": [
    "#pool size\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[4,4]],\n",
    "              'pool_size' : [[1,1], [2,2]],\n",
    "              'dropout_1' : [0.0],\n",
    "              'dropout_2' : [0.0]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 110s 4ms/step - loss: 0.1808 - acc: 0.9440\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 59s 2ms/step - loss: 0.0480 - acc: 0.9847\n",
      "30000/30000 [==============================] - 43s 1ms/step\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a092c8ad35df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_classifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;31m# summarize results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best: %f using %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2697\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2698\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2699\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;31m# hack for list_devices() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dropouts\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [2],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[4,4]],\n",
    "              'pool_size' : [[1,1]],\n",
    "              'dropout_1' : [0.0, 0.25, 0.5, 0.75],\n",
    "              'dropout_2' : [0.0, 0.25, 0.5, 0.75]\n",
    "             }\n",
    "\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=50, verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "cb_list = [cb]\n",
    "hist = model.fit(x=x_train,y=y_train, epochs=20, batch_size=128, validation_data=(x_test, y_test), verbose=1)\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "#Test 1: all activations relu, 96.82% acc\n",
    "#Test 2: first layer tanh, 96.75% acc\n",
    "#Test 3: third layer tanh, 95.84% acc\n",
    "#Test 4: fifth layer tanh, 95.39% acc\n",
    "#Test 5: sixth layer tanh, 96.22% acc\n",
    "#It seems that the most successful activation function is rectified linear unit, so I am sticking with relu for 1st, 3rd, 5th, and 6h layer.\n",
    "#Test 6: Adadelta optimizer, 98.84% acc\n",
    "#Test 7: Adamax optimizer, 99.04% acc\n",
    "#Test 8: RMSprop optimizer, 99.03% acc\n",
    "#Test 9: Adagrad optimizer, 98.95% acc\n",
    "#Test 10: Adam optimizer, 99.01% acc\n",
    "#Test 11: Nadam optimizer, 99.15% acc <----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['acc'], 'o-')\n",
    "ax.plot([None] + hist.history['val_acc'], 'x-')\n",
    "ax.legend(['Train acc', 'Validation acc'], loc = 0)\n",
    "ax.set_title('Training/Validation acc per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['loss'], 'o-')\n",
    "ax.plot([None] + hist.history['val_loss'], 'x-')\n",
    "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
    "ax.set_title('Training/Validation Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
