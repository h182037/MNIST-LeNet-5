{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.utils as np_utils\n",
    "from keras.models import Sequential\n",
    "from keras import models, layers\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras import regularizers\n",
    "import keras\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# resources:\n",
    "# https://engmrk.com/lenet-5-a-classic-cnn-architecture/\n",
    "# https://keras.io/\n",
    "# https://github.com/ryanleeallred/MNIST-convnet-gridsearch/blob/master/param_tuning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19d581fb9e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array(x_train[0], dtype='uint8')\n",
    "pixels = image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# transformation\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# reshape\n",
    "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creation function, this is used to build a specific model for each of the parameter selection steps.\n",
    "def create_model(optimizer, activation_1, activation_2, activation_3, activation_4, kernel_size, pool_size, dropout_1, dropout_2):\n",
    "    model = Sequential()\n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(6, kernel_size=kernel_size, strides=(1, 1), activation=activation_1, input_shape=(28,28,1), padding=\"same\"))\n",
    "\n",
    "    # First pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(1, 1), padding='valid'))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(16, kernel_size=kernel_size, strides=(1, 1), activation=activation_2, padding='valid'))\n",
    "    \n",
    "    # Second pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(2, 2), padding='valid'))\n",
    "    \n",
    "    # Connected convolutional layer\n",
    "    model.add(layers.Conv2D(120, kernel_size=kernel_size, strides=(1, 1), activation=activation_3, padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dropout(dropout_1)) \n",
    "    # Connected layer\n",
    "    model.add(layers.Dense(84, activation=activation_4))\n",
    "    model.add(Dropout(dropout_2)) \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # build/compile\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.5045 - acc: 0.8432\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.3738 - acc: 0.8863\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 52s 2ms/step - loss: 0.3427 - acc: 0.8964\n",
      "30000/30000 [==============================] - 12s 405us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 0.4868 - acc: 0.8489\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 59s 2ms/step - loss: 0.3705 - acc: 0.8875\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 0.3467 - acc: 0.8921: 1s - loss\n",
      "30000/30000 [==============================] - 12s 405us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 29s 979us/step - loss: 0.4108 - acc: 0.8751\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 27s 909us/step - loss: 0.3092 - acc: 0.9068\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 908us/step - loss: 0.2672 - acc: 0.9187\n",
      "30000/30000 [==============================] - 8s 272us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 858us/step - loss: 0.4187 - acc: 0.8737\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 0.3205 - acc: 0.9025\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 885us/step - loss: 0.2715 - acc: 0.9182\n",
      "30000/30000 [==============================] - 9s 301us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 873us/step - loss: 0.4065 - acc: 0.8780\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.2869 - acc: 0.9141\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 24s 789us/step - loss: 0.2482 - acc: 0.9256\n",
      "30000/30000 [==============================] - 8s 260us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 806us/step - loss: 0.3881 - acc: 0.8834\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 24s 809us/step - loss: 0.2792 - acc: 0.9149\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 23s 773us/step - loss: 0.2512 - acc: 0.9230\n",
      "30000/30000 [==============================] - 8s 254us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 771us/step - loss: 0.3951 - acc: 0.8792\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 776us/step - loss: 0.2690 - acc: 0.9195\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 746us/step - loss: 0.2179 - acc: 0.9346\n",
      "30000/30000 [==============================] - 7s 247us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.3833 - acc: 0.8845\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 22s 748us/step - loss: 0.2793 - acc: 0.9167\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 728us/step - loss: 0.2465 - acc: 0.9255\n",
      "30000/30000 [==============================] - 8s 255us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 799us/step - loss: 0.4084 - acc: 0.8758\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 22s 717us/step - loss: 0.2584 - acc: 0.9224\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 25s 826us/step - loss: 0.2179 - acc: 0.9357\n",
      "30000/30000 [==============================] - 8s 257us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 856us/step - loss: 0.3892 - acc: 0.8824\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 24s 793us/step - loss: 0.2524 - acc: 0.9251\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 717us/step - loss: 0.2195 - acc: 0.9325\n",
      "30000/30000 [==============================] - 8s 257us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 16.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 47s 777us/step - loss: 0.3427 - acc: 0.8976\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 46s 774us/step - loss: 0.2414 - acc: 0.9273\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 45s 745us/step - loss: 0.1901 - acc: 0.9423\n",
      "Best: 0.947733 using {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [5, 5], 'optimizer': 'SGD', 'pool_size': [2, 2]}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0f792a6a5bcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mstds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'std_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test loss {:.4f}, accuracy {:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [10, 50, 100, 120, 200],\n",
    "              'optimizer': ['SGD'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['tanh'],\n",
    "              'activation_3' : ['tanh'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 7 candidates, totalling 14 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.2893 - acc: 0.9112\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 701us/step - loss: 0.0869 - acc: 0.9739\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 744us/step - loss: 0.0605 - acc: 0.9825\n",
      "30000/30000 [==============================] - 7s 234us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 786us/step - loss: 0.2673 - acc: 0.9184\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 717us/step - loss: 0.0703 - acc: 0.9789\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 717us/step - loss: 0.0489 - acc: 0.9852\n",
      "30000/30000 [==============================] - 7s 232us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 814us/step - loss: 0.2732 - acc: 0.9137\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 768us/step - loss: 0.0760 - acc: 0.9762\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 719us/step - loss: 0.0511 - acc: 0.9854\n",
      "30000/30000 [==============================] - 7s 243us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 755us/step - loss: 0.3068 - acc: 0.9066\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 704us/step - loss: 0.0789 - acc: 0.9772\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 705us/step - loss: 0.0556 - acc: 0.9829\n",
      "30000/30000 [==============================] - 8s 280us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 878us/step - loss: 0.2849 - acc: 0.9104\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 700us/step - loss: 0.0803 - acc: 0.9756\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 703us/step - loss: 0.0531 - acc: 0.9842\n",
      "30000/30000 [==============================] - 7s 237us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 758us/step - loss: 0.2668 - acc: 0.9157\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 698us/step - loss: 0.0710 - acc: 0.9777\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 697us/step - loss: 0.0478 - acc: 0.9852\n",
      "30000/30000 [==============================] - 7s 239us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 757us/step - loss: 0.2923 - acc: 0.9081\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 699us/step - loss: 0.0733 - acc: 0.9776\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 728us/step - loss: 0.0516 - acc: 0.9848\n",
      "30000/30000 [==============================] - 8s 277us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 780us/step - loss: 0.2576 - acc: 0.9196\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 702us/step - loss: 0.0782 - acc: 0.9759\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 701us/step - loss: 0.0532 - acc: 0.9834\n",
      "30000/30000 [==============================] - 8s 257us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.2827 - acc: 0.9114\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 705us/step - loss: 0.0822 - acc: 0.9761\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 713us/step - loss: 0.0548 - acc: 0.9834\n",
      "30000/30000 [==============================] - 7s 247us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 25s 837us/step - loss: 0.2750 - acc: 0.9132\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 762us/step - loss: 0.0767 - acc: 0.9770\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 744us/step - loss: 0.0481 - acc: 0.9854\n",
      "30000/30000 [==============================] - 8s 252us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 762us/step - loss: 0.3066 - acc: 0.9053\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 22s 729us/step - loss: 0.0875 - acc: 0.9739\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.0590 - acc: 0.982 - 21s 704us/step - loss: 0.0588 - acc: 0.9829\n",
      "30000/30000 [==============================] - 7s 242us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 0.2487 - acc: 0.9257\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 751us/step - loss: 0.0681 - acc: 0.9794\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 23s 754us/step - loss: 0.0469 - acc: 0.9859\n",
      "30000/30000 [==============================] - 7s 248us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.2964 - acc: 0.9049\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 710us/step - loss: 0.0843 - acc: 0.9739\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 709us/step - loss: 0.0568 - acc: 0.9832\n",
      "30000/30000 [==============================] - 7s 246us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.2925 - acc: 0.9104\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 706us/step - loss: 0.0799 - acc: 0.9760\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 709us/step - loss: 0.0542 - acc: 0.9833\n",
      "30000/30000 [==============================] - 8s 250us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 17.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 48s 793us/step - loss: 0.1751 - acc: 0.9461\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 46s 768us/step - loss: 0.0518 - acc: 0.9844\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 44s 737us/step - loss: 0.0375 - acc: 0.9882\n",
      "Best: 0.986650 using {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n"
     ]
    }
   ],
   "source": [
    "#optimizer\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam', 'Adamax'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['tanh'],\n",
    "              'activation_3' : ['tanh'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE: 64\n",
    "#BEST OPTIMIZER: NADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 81 candidates, totalling 162 fits\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3068 - acc: 0.9061\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 850us/step - loss: 0.0878 - acc: 0.9728\n",
      "30000/30000 [==============================] - 7s 244us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 944us/step - loss: 0.2691 - acc: 0.9176\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 786us/step - loss: 0.0740 - acc: 0.9777\n",
      "30000/30000 [==============================] - 7s 223us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 22s 742us/step - loss: 0.3370 - acc: 0.9051\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 0.0987 - acc: 0.9725\n",
      "30000/30000 [==============================] - 7s 245us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 0.3500 - acc: 0.9018\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 803us/step - loss: 0.0910 - acc: 0.9761\n",
      "30000/30000 [==============================] - 7s 221us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 842us/step - loss: 0.2273 - acc: 0.9307\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 741us/step - loss: 0.0617 - acc: 0.9816\n",
      "30000/30000 [==============================] - 7s 234us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 23s 776us/step - loss: 0.2408 - acc: 0.9249\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 763us/step - loss: 0.0669 - acc: 0.97970s - loss: 0.0679 - acc\n",
      "30000/30000 [==============================] - 8s 280us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 24s 812us/step - loss: 1.2013 - acc: 0.6314\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 825us/step - loss: 0.4596 - acc: 0.8500\n",
      "30000/30000 [==============================] - 7s 248us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 1.0654 - acc: 0.6352\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 0.3424 - acc: 0.8884\n",
      "30000/30000 [==============================] - 7s 244us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 915us/step - loss: 0.5992 - acc: 0.8150\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 822us/step - loss: 0.1239 - acc: 0.9643\n",
      "30000/30000 [==============================] - 8s 264us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 905us/step - loss: 2.3941 - acc: 0.0992\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 859us/step - loss: 2.3301 - acc: 0.1004\n",
      "30000/30000 [==============================] - 8s 261us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 24s 817us/step - loss: 2.7127 - acc: 0.1005\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 905us/step - loss: 2.3988 - acc: 0.1017\n",
      "30000/30000 [==============================] - 9s 308us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 946us/step - loss: 2.5833 - acc: 0.1006\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 2.3869 - acc: 0.1045\n",
      "30000/30000 [==============================] - 9s 297us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 893us/step - loss: 0.2715 - acc: 0.9138\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 770us/step - loss: 0.0894 - acc: 0.9735\n",
      "30000/30000 [==============================] - 8s 259us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 849us/step - loss: 0.2657 - acc: 0.9185\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 0.0864 - acc: 0.9739\n",
      "30000/30000 [==============================] - 7s 249us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 875us/step - loss: 0.3550 - acc: 0.90410s - loss: 0.3590 - acc: 0\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.1097 - acc: 0.9707\n",
      "30000/30000 [==============================] - 8s 259us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 837us/step - loss: 0.3511 - acc: 0.9029\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 21s 716us/step - loss: 0.1085 - acc: 0.9706\n",
      "30000/30000 [==============================] - 7s 248us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.2769 - acc: 0.9157\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 873us/step - loss: 0.0874 - acc: 0.9738\n",
      "30000/30000 [==============================] - 11s 364us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.2240 - acc: 0.9305\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 903us/step - loss: 0.0824 - acc: 0.9749\n",
      "30000/30000 [==============================] - 9s 302us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.9773 - acc: 0.6693\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.2088 - acc: 0.9362\n",
      "30000/30000 [==============================] - 10s 341us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.8088 - acc: 0.7175\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 938us/step - loss: 0.1293 - acc: 0.9612\n",
      "30000/30000 [==============================] - 8s 271us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 865us/step - loss: 0.7441 - acc: 0.7501\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 60s 2ms/step - loss: 0.1149 - acc: 0.9682: 5s - los\n",
      "30000/30000 [==============================] - 26s 851us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.8855 - acc: 0.6967\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 839us/step - loss: 0.1198 - acc: 0.96781s - loss: 0.\n",
      "30000/30000 [==============================] - 9s 292us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 873us/step - loss: 0.7246 - acc: 0.7613\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 0.1414 - acc: 0.9572\n",
      "30000/30000 [==============================] - 9s 288us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 937us/step - loss: 0.6164 - acc: 0.8063\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 818us/step - loss: 0.1214 - acc: 0.9633\n",
      "30000/30000 [==============================] - 9s 294us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 950us/step - loss: 2.3693 - acc: 0.10800s - loss: 2.3703 - acc: \n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 2.2348 - acc: 0.1306\n",
      "30000/30000 [==============================] - 9s 288us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 981us/step - loss: 2.1251 - acc: 0.207110s - loss: 2.2621 - acc: - E\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 784us/step - loss: 1.4868 - acc: 0.4507\n",
      "30000/30000 [==============================] - 9s 290us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 941us/step - loss: 2.0728 - acc: 0.2412\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.2377 - acc: 0.9359\n",
      "30000/30000 [==============================] - 11s 372us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 2.4168 - acc: 0.1029\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.3282 - acc: 0.1035- ETA: 1s - loss: 2.3285 - acc: 0.103 - ETA: 1s - loss: 2.3 - 25s 830us/step - loss: 2.3281 - acc: 0.1035\n",
      "30000/30000 [==============================] - 8s 277us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 939us/step - loss: 2.6148 - acc: 0.0983\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 844us/step - loss: 2.3942 - acc: 0.1036\n",
      "30000/30000 [==============================] - 8s 281us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 907us/step - loss: 2.5931 - acc: 0.1023\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 856us/step - loss: 2.3978 - acc: 0.0997\n",
      "30000/30000 [==============================] - 9s 291us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 921us/step - loss: 2.3815 - acc: 0.1090\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 2.3015 - acc: 0.11062s - l\n",
      "30000/30000 [==============================] - 9s 297us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 963us/step - loss: 2.4272 - acc: 0.1085\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 9s 296us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.4159 - acc: 0.1025\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 840us/step - loss: 2.3303 - acc: 0.10217\n",
      "30000/30000 [==============================] - 9s 289us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 0.7081 - acc: 0.7856\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 915us/step - loss: 0.2039 - acc: 0.9451\n",
      "30000/30000 [==============================] - 10s 332us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.6365 - acc: 0.1000\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 2.4060 - acc: 0.1029\n",
      "30000/30000 [==============================] - 13s 442us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 46s 2ms/step - loss: 2.5748 - acc: 0.1001: 5\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 2.3961 - acc: 0.1020\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2679 - acc: 0.9174\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.0854 - acc: 0.9747\n",
      "30000/30000 [==============================] - 14s 479us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.2619 - acc: 0.9207\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 809us/step - loss: 0.0870 - acc: 0.97381s - loss: 0.0880 - ETA: 0s - loss: 0.0874 - acc: 0.\n",
      "30000/30000 [==============================] - 9s 287us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 940us/step - loss: 0.3253 - acc: 0.9105\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 826us/step - loss: 0.0897 - acc: 0.9762\n",
      "30000/30000 [==============================] - 9s 301us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 992us/step - loss: 0.2876 - acc: 0.9204\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 863us/step - loss: 0.0982 - acc: 0.9725\n",
      "30000/30000 [==============================] - 9s 291us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 0.2034 - acc: 0.93733s\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 810us/step - loss: 0.0636 - acc: 0.9797\n",
      "30000/30000 [==============================] - 9s 297us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 928us/step - loss: 0.2062 - acc: 0.9367\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 813us/step - loss: 0.0657 - acc: 0.9796\n",
      "30000/30000 [==============================] - 9s 301us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 1.9946 - acc: 0.2695\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 937us/step - loss: 1.3857 - acc: 0.5064\n",
      "30000/30000 [==============================] - 9s 293us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 1.9863 - acc: 0.2574\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 1.0810 - acc: 0.6029\n",
      "30000/30000 [==============================] - 12s 392us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 42s 1ms/step - loss: 2.3942 - acc: 0.1010\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3301 - acc: 0.1011\n",
      "30000/30000 [==============================] - 10s 350us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.7000 - acc: 0.7858\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.1282 - acc: 0.9654\n",
      "30000/30000 [==============================] - 11s 351us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.6079 - acc: 0.1025\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 936us/step - loss: 2.3895 - acc: 0.1029\n",
      "30000/30000 [==============================] - 11s 367us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.6407 - acc: 0.1023\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 909us/step - loss: 2.3959 - acc: 0.10170s - loss: 2.3971 - acc: \n",
      "30000/30000 [==============================] - 9s 308us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3017 - acc: 0.9071\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 942us/step - loss: 0.1117 - acc: 0.9673\n",
      "30000/30000 [==============================] - 13s 439us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.2920 - acc: 0.9107\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 882us/step - loss: 0.1275 - acc: 0.9627\n",
      "30000/30000 [==============================] - 10s 334us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 982us/step - loss: 0.4199 - acc: 0.8846\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 840us/step - loss: 0.1571 - acc: 0.9564\n",
      "30000/30000 [==============================] - 9s 310us/step\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.4001 - acc: 0.8910\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 902us/step - loss: 0.1593 - acc: 0.9571\n",
      "30000/30000 [==============================] - 9s 303us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.2615 - acc: 0.9205\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 998us/step - loss: 0.1240 - acc: 0.96164s - loss: 0.1258 - acc - ETA: 3s - \n",
      "30000/30000 [==============================] - 12s 409us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.2490 - acc: 0.9241\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 914us/step - loss: 0.1056 - acc: 0.9685\n",
      "30000/30000 [==============================] - 10s 322us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.5384 - acc: 0.8248\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.1473 - acc: 0.9554\n",
      "30000/30000 [==============================] - 12s 385us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.6885 - acc: 0.7706\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 770us/step - loss: 0.1862 - acc: 0.9436\n",
      "30000/30000 [==============================] - 9s 300us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 0.6520 - acc: 0.7923\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1546 - acc: 0.9554\n",
      "30000/30000 [==============================] - 10s 324us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 962us/step - loss: 0.6232 - acc: 0.8083\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 781us/step - loss: 0.1532 - acc: 0.9573\n",
      "30000/30000 [==============================] - 10s 323us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 934us/step - loss: 0.5838 - acc: 0.8115\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 764us/step - loss: 0.1321 - acc: 0.9585\n",
      "30000/30000 [==============================] - 14s 457us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.4659 - acc: 0.8559\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1324 - acc: 0.9594\n",
      "30000/30000 [==============================] - 13s 434us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.3595 - acc: 0.111 - 29s 961us/step - loss: 2.3592 - acc: 0.1114\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 958us/step - loss: 1.2928 - acc: 0.5558\n",
      "30000/30000 [==============================] - 9s 305us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3863 - acc: 0.1135\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 897us/step - loss: 2.3011 - acc: 0.1141\n",
      "30000/30000 [==============================] - 12s 402us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 2.3786 - acc: 0.1018\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 800us/step - loss: 2.3239 - acc: 0.10422\n",
      "30000/30000 [==============================] - 11s 350us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 970us/step - loss: 2.3869 - acc: 0.1020\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 2.3317 - acc: 0.1023\n",
      "30000/30000 [==============================] - 10s 333us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.5996 - acc: 0.0998\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 734us/step - loss: 2.3917 - acc: 0.1028\n",
      "30000/30000 [==============================] - 10s 339us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.6082 - acc: 0.0994\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.3949 - acc: 0.099 - 24s 791us/step - loss: 2.3947 - acc: 0.0996\n",
      "30000/30000 [==============================] - 9s 315us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.7952 - acc: 0.734 - 29s 982us/step - loss: 0.7936 - acc: 0.7348\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 781us/step - loss: 0.2785 - acc: 0.9166\n",
      "30000/30000 [==============================] - 10s 330us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.6540 - acc: 0.7857\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.2552 - acc: 0.9227\n",
      "30000/30000 [==============================] - 10s 318us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 973us/step - loss: 0.6443 - acc: 0.8049\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 754us/step - loss: 0.2827 - acc: 0.9188\n",
      "30000/30000 [==============================] - 10s 322us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 993us/step - loss: 1.0580 - acc: 0.6501\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 772us/step - loss: 0.3137 - acc: 0.9113\n",
      "30000/30000 [==============================] - 10s 324us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 999us/step - loss: 0.5935 - acc: 0.8164\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 791us/step - loss: 0.2421 - acc: 0.9275\n",
      "30000/30000 [==============================] - 10s 328us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 997us/step - loss: 0.6823 - acc: 0.7985\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 780us/step - loss: 0.2696 - acc: 0.9193\n",
      "30000/30000 [==============================] - 10s 330us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3099 - acc: 0.1072\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 833us/step - loss: 2.3016 - acc: 0.1106\n",
      "30000/30000 [==============================] - 11s 359us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3062 - acc: 0.1122\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 11s 360us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3126 - acc: 0.1081\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 860us/step - loss: 2.3049 - acc: 0.1071\n",
      "30000/30000 [==============================] - 11s 378us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3152 - acc: 0.1122: 1s - loss: 2.3161\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 912us/step - loss: 2.3037 - acc: 0.1102\n",
      "30000/30000 [==============================] - 12s 385us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.3176 - acc: 0.1072\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 2.3020 - acc: 0.1100\n",
      "30000/30000 [==============================] - 12s 393us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.3209 - acc: 0.1125\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 918us/step - loss: 2.3016 - acc: 0.1134\n",
      "30000/30000 [==============================] - 12s 403us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3416 - acc: 0.1088\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 892us/step - loss: 2.3015 - acc: 0.1106\n",
      "30000/30000 [==============================] - 12s 388us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 2.3696 - acc: 0.1097\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 893us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 11s 379us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.4168 - acc: 0.1016\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 863us/step - loss: 2.3386 - acc: 0.1009\n",
      "30000/30000 [==============================] - 12s 394us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 2.3345 - acc: 0.1078\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 851us/step - loss: 2.3013 - acc: 0.1140\n",
      "30000/30000 [==============================] - 11s 369us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.6424 - acc: 0.1013: 8s - los\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 843us/step - loss: 2.4050 - acc: 0.1005\n",
      "30000/30000 [==============================] - 11s 373us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 2.6207 - acc: 0.1045\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 844us/step - loss: 2.3943 - acc: 0.0982\n",
      "30000/30000 [==============================] - 12s 416us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.4100 - acc: 0.1076\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 833us/step - loss: 2.3016 - acc: 0.1106\n",
      "30000/30000 [==============================] - 11s 376us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3954 - acc: 0.1107\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 847us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 12s 384us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 1.1090 - acc: 0.6230\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 944us/step - loss: 0.3247 - acc: 0.9056\n",
      "30000/30000 [==============================] - 14s 457us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.3719 - acc: 0.0991\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 894us/step - loss: 2.3205 - acc: 0.1046\n",
      "30000/30000 [==============================] - 12s 407us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.5792 - acc: 0.102 - 38s 1ms/step - loss: 2.5783 - acc: 0.1027\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 875us/step - loss: 2.3947 - acc: 0.1008\n",
      "30000/30000 [==============================] - 12s 406us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 2.5431 - acc: 0.1009: 6s - loss: - ETA: 3s - loss\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 903us/step - loss: 2.3918 - acc: 0.1057\n",
      "30000/30000 [==============================] - 13s 425us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.4916 - acc: 0.8377\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 892us/step - loss: 0.1318 - acc: 0.9603\n",
      "30000/30000 [==============================] - 12s 402us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.8665 - acc: 0.7036\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.1594 - acc: 0.9527\n",
      "30000/30000 [==============================] - 18s 583us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.4519 - acc: 0.8635\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.1269 - acc: 0.9646\n",
      "30000/30000 [==============================] - 18s 615us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 0.5286 - acc: 0.8363\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.1307 - acc: 0.9639\n",
      "30000/30000 [==============================] - 19s 633us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 66s 2ms/step - loss: 0.6131 - acc: 0.8036\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 46s 2ms/step - loss: 0.1305 - acc: 0.9594\n",
      "30000/30000 [==============================] - 33s 1ms/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 80s 3ms/step - loss: 0.5222 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 45s 2ms/step - loss: 0.1120 - acc: 0.9653\n",
      "30000/30000 [==============================] - 14s 475us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 2.3959 - acc: 0.1079\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 950us/step - loss: 2.3009 - acc: 0.1100\n",
      "30000/30000 [==============================] - 13s 429us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 2.3674 - acc: 0.1131\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.1624 - acc: 0.1770\n",
      "30000/30000 [==============================] - 14s 474us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 2.4001 - acc: 0.0987\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 930us/step - loss: 2.3328 - acc: 0.1014\n",
      "30000/30000 [==============================] - 13s 445us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 1.0532 - acc: 0.6432\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 942us/step - loss: 0.1748 - acc: 0.9517\n",
      "30000/30000 [==============================] - 14s 458us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 2.6046 - acc: 0.1039\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 928us/step - loss: 2.3978 - acc: 0.1015\n",
      "30000/30000 [==============================] - 16s 519us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 2.6197 - acc: 0.1016\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 2.4023 - acc: 0.1013\n",
      "30000/30000 [==============================] - 16s 524us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 2.3936 - acc: 0.1184\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 926us/step - loss: 2.3016 - acc: 0.1106\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.5717 - acc: 0.8132\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 930us/step - loss: 0.2347 - acc: 0.9277\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.6377 - acc: 0.8112\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 912us/step - loss: 0.2786 - acc: 0.9213\n",
      "30000/30000 [==============================] - 14s 476us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.6327 - acc: 0.8137\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.2914 - acc: 0.9180\n",
      "30000/30000 [==============================] - 14s 471us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 45s 1ms/step - loss: 2.6483 - acc: 0.0980\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 952us/step - loss: 2.4084 - acc: 0.1017\n",
      "30000/30000 [==============================] - 14s 478us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 0.5954 - acc: 0.8302\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 970us/step - loss: 0.2757 - acc: 0.9182\n",
      "30000/30000 [==============================] - 14s 470us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.2676 - acc: 0.917 - 38s 1ms/step - loss: 0.2672 - acc: 0.9174\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 932us/step - loss: 0.0741 - acc: 0.9769\n",
      "30000/30000 [==============================] - 14s 466us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 45s 2ms/step - loss: 0.2616 - acc: 0.9210: 5s -\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 898us/step - loss: 0.0724 - acc: 0.9777\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 42s 1ms/step - loss: 0.3030 - acc: 0.9176\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 851us/step - loss: 0.0847 - acc: 0.97700s - loss: 0.0851 - acc: \n",
      "30000/30000 [==============================] - 14s 454us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 39s 1ms/step - loss: 0.3291 - acc: 0.9057: 11s - l - ETA: 7s - loss: 0.3778 - acc:\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 767us/step - loss: 0.0930 - acc: 0.9751\n",
      "30000/30000 [==============================] - 13s 418us/step\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.2296 - acc: 0.9289\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 882us/step - loss: 0.0676 - acc: 0.9795\n",
      "30000/30000 [==============================] - 14s 480us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 42s 1ms/step - loss: 0.2045 - acc: 0.9361\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 848us/step - loss: 0.0626 - acc: 0.9813\n",
      "30000/30000 [==============================] - 14s 479us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 45s 1ms/step - loss: 1.1618 - acc: 0.6427\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 0.3634 - acc: 0.8830\n",
      "30000/30000 [==============================] - 14s 475us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 0.9788 - acc: 0.6917: 3s - loss: \n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 904us/step - loss: 0.3287 - acc: 0.8964\n",
      "30000/30000 [==============================] - 16s 546us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.5789 - acc: 0.8237\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 943us/step - loss: 0.1272 - acc: 0.9649\n",
      "30000/30000 [==============================] - 15s 496us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.6186 - acc: 0.8108\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 950us/step - loss: 0.1254 - acc: 0.9652\n",
      "30000/30000 [==============================] - 16s 543us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 2.5931 - acc: 0.1000: \n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 923us/step - loss: 2.3818 - acc: 0.1002\n",
      "30000/30000 [==============================] - 17s 583us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.6142 - acc: 0.1030\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.4059 - acc: 0.0988\n",
      "30000/30000 [==============================] - 18s 596us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.2559 - acc: 0.9217\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.0914 - acc: 0.9732\n",
      "30000/30000 [==============================] - 17s 562us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.2401 - acc: 0.9252: 3s - loss: 0.24 - ETA: 0s - loss: 0.2412 - acc: 0.92\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 985us/step - loss: 0.0855 - acc: 0.9750\n",
      "30000/30000 [==============================] - 18s 606us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.3212 - acc: 0.9124\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 895us/step - loss: 0.1136 - acc: 0.9684\n",
      "30000/30000 [==============================] - 15s 494us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.3279 - acc: 0.9125\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 895us/step - loss: 0.1091 - acc: 0.9707\n",
      "30000/30000 [==============================] - 15s 505us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.2371 - acc: 0.9278\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 925us/step - loss: 0.0840 - acc: 0.9757\n",
      "30000/30000 [==============================] - 15s 493us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.2213 - acc: 0.9332\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 896us/step - loss: 0.0838 - acc: 0.9746\n",
      "30000/30000 [==============================] - 16s 526us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.7564 - acc: 0.7460\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 945us/step - loss: 0.1891 - acc: 0.9413\n",
      "30000/30000 [==============================] - 16s 542us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.8830 - acc: 0.6932\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1683 - acc: 0.9497\n",
      "30000/30000 [==============================] - 17s 557us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.7694 - acc: 0.7549\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 975us/step - loss: 0.1865 - acc: 0.9479\n",
      "30000/30000 [==============================] - 17s 573us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.7521 - acc: 0.7620\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 956us/step - loss: 0.2027 - acc: 0.9416\n",
      "30000/30000 [==============================] - 19s 619us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 2.3178 - acc: 0.1081\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 971us/step - loss: 2.3020 - acc: 0.1094\n",
      "30000/30000 [==============================] - 17s 569us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 1.3112 - acc: 0.5234\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 979us/step - loss: 0.1522 - acc: 0.9542\n",
      "30000/30000 [==============================] - 17s 577us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 1.8433 - acc: 0.3294\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.6902 - acc: 0.7578\n",
      "30000/30000 [==============================] - 21s 707us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 65s 2ms/step - loss: 2.2924 - acc: 0.1381\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 1.7268 - acc: 0.3586\n",
      "30000/30000 [==============================] - 17s 559us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 1.1062 - acc: 0.6376\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1898 - acc: 0.9473\n",
      "30000/30000 [==============================] - 18s 596us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.8587 - acc: 0.7286\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 0.1830 - acc: 0.9501\n",
      "30000/30000 [==============================] - 18s 616us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.6756 - acc: 0.1037\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.4071 - acc: 0.1007\n",
      "30000/30000 [==============================] - 19s 647us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.5617 - acc: 0.1005\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3888 - acc: 0.0996\n",
      "30000/30000 [==============================] - 17s 552us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 2.3584 - acc: 0.1084\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 907us/step - loss: 2.3016 - acc: 0.1103\n",
      "30000/30000 [==============================] - 16s 542us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.3843 - acc: 0.1118\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3011 - acc: 0.1142\n",
      "30000/30000 [==============================] - 19s 650us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.4940 - acc: 0.0998\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 987us/step - loss: 2.3498 - acc: 0.1028\n",
      "30000/30000 [==============================] - 18s 599us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 1.3521 - acc: 0.5263\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.2496 - acc: 0.9293\n",
      "30000/30000 [==============================] - 19s 627us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 59s 2ms/step - loss: 2.6631 - acc: 0.0990\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3968 - acc: 0.0990\n",
      "30000/30000 [==============================] - 20s 651us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.6428 - acc: 0.1021\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3912 - acc: 0.0983\n",
      "30000/30000 [==============================] - 20s 677us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.2509 - acc: 0.9241\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 0.0941 - acc: 0.9718\n",
      "30000/30000 [==============================] - 19s 627us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.2474 - acc: 0.9243\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.0924 - acc: 0.9720\n",
      "30000/30000 [==============================] - 19s 645us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 58s 2ms/step - loss: 0.2918 - acc: 0.9190\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.0995 - acc: 0.9728\n",
      "30000/30000 [==============================] - 21s 687us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.3055 - acc: 0.9172\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.1005 - acc: 0.9729: 0s - loss: 0.1007 - acc: 0\n",
      "30000/30000 [==============================] - 17s 566us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.2136 - acc: 0.9338\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 0.0840 - acc: 0.9738\n",
      "30000/30000 [==============================] - 17s 565us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.2215 - acc: 0.9335\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 946us/step - loss: 0.0801 - acc: 0.9754\n",
      "30000/30000 [==============================] - 20s 668us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 1.6021 - acc: 0.4322\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.7850 - acc: 0.6976\n",
      "30000/30000 [==============================] - 20s 656us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 60s 2ms/step - loss: 1.3191 - acc: 0.5560\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.5775 - acc: 0.7959\n",
      "30000/30000 [==============================] - 19s 641us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 61s 2ms/step - loss: 0.6512 - acc: 0.7991\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 0.1207 - acc: 0.9667\n",
      "30000/30000 [==============================] - 24s 806us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 1.8445 - acc: 0.3339\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.1730 - acc: 0.9535\n",
      "30000/30000 [==============================] - 20s 654us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 55s 2ms/step - loss: 2.6058 - acc: 0.0965\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.3906 - acc: 0.1032\n",
      "30000/30000 [==============================] - 20s 658us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.6059 - acc: 0.1038\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3946 - acc: 0.1023\n",
      "30000/30000 [==============================] - 19s 630us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.3718 - acc: 0.8872\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 981us/step - loss: 0.2129 - acc: 0.9364\n",
      "30000/30000 [==============================] - 19s 622us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.3641 - acc: 0.8905\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 983us/step - loss: 0.2208 - acc: 0.9347\n",
      "30000/30000 [==============================] - 19s 632us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.4252 - acc: 0.8852\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 985us/step - loss: 0.1745 - acc: 0.9515\n",
      "30000/30000 [==============================] - 21s 688us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 67s 2ms/step - loss: 0.4293 - acc: 0.8825\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1979 - acc: 0.9449\n",
      "30000/30000 [==============================] - 18s 614us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.3736 - acc: 0.8884\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 985us/step - loss: 0.2565 - acc: 0.9232\n",
      "30000/30000 [==============================] - 19s 621us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 60s 2ms/step - loss: 0.3912 - acc: 0.8807\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.2770 - acc: 0.9166\n",
      "30000/30000 [==============================] - 18s 614us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed: 222.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.1467 - acc: 0.9543\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 59s 984us/step - loss: 0.0474 - acc: 0.9856\n",
      "Best: 0.983333 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.983100 (0.001367) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981167 (0.000600) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.982650 (0.000217) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.958250 (0.005183) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.543033 (0.432400) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.103233 (0.007400) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981467 (0.000700) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.975683 (0.003283) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.979317 (0.002017) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.972117 (0.004217) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.976633 (0.000333) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.973900 (0.001367) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.544983 (0.259817) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.537467 (0.426833) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.533700 (0.430133) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.106533 (0.004100) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981617 (0.000717) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981117 (0.001017) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.979517 (0.003783) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.879150 (0.054083) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.537950 (0.437850) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.103233 (0.007400) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.976067 (0.001400) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.969067 (0.000200) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.969183 (0.003317) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.968950 (0.003183) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.970950 (0.000950) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.971183 (0.001783) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.494950 (0.384317) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.109683 (0.004417) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.949267 (0.001533) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.943850 (0.001083) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.943767 (0.006300) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.100833 (0.002733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.106417 (0.007683) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.521483 (0.410850) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.972200 (0.001533) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.970467 (0.001767) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.972067 (0.003633) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.422233 (0.308133) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.536567 (0.433000) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.105367 (0.005267) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.533617 (0.419517) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.940833 (0.001767) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.516667 (0.417967) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981567 (0.001300) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.980467 (0.001100) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.983333 (0.001200) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.961700 (0.002567) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.974083 (0.000117) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.980867 (0.001000) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.977683 (0.000417) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.980650 (0.000550) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.971083 (0.000783) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.965633 (0.002733) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.541417 (0.427317) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.775783 (0.158417) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.965500 (0.000167) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.105650 (0.008450) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.535217 (0.421117) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.104450 (0.006183) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.979050 (0.002183) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.977733 (0.000467) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.978100 (0.000333) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.947850 (0.008617) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.973317 (0.003050) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.108017 (0.006083) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.959717 (0.000150) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.963767 (0.001600) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.936933 (0.005800) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "Best: 0.983333 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 14s 1ms/step\n",
      "Test Accuracy 0.9882000062465668\n"
     ]
    }
   ],
   "source": [
    "#activations\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [2],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation_2' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation_3' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation_4' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam\n",
    "#BEST ACTIVATIONS tanh, relu, relu, tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.2527 - acc: 0.9246\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 0.0674 - acc: 0.9795\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 879us/step - loss: 0.0484 - acc: 0.9850\n",
      "30000/30000 [==============================] - 17s 577us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2119 - acc: 0.9360\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 861us/step - loss: 0.0561 - acc: 0.9829\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 0.0385 - acc: 0.9879\n",
      "30000/30000 [==============================] - 18s 589us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2103 - acc: 0.9345\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 867us/step - loss: 0.0648 - acc: 0.9806\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 855us/step - loss: 0.0441 - acc: 0.9865\n",
      "30000/30000 [==============================] - 18s 611us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 52s 2ms/step - loss: 0.2170 - acc: 0.9339: 3s - loss: 0.2258\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 881us/step - loss: 0.0624 - acc: 0.9808\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 884us/step - loss: 0.0393 - acc: 0.9875\n",
      "30000/30000 [==============================] - 18s 588us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2287 - acc: 0.9307\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 849us/step - loss: 0.0677 - acc: 0.9794\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 0.0435 - acc: 0.9867\n",
      "30000/30000 [==============================] - 18s 594us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.2214 - acc: 0.9315\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 28s 938us/step - loss: 0.0654 - acc: 0.9795\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 28s 937us/step - loss: 0.0435 - acc: 0.9864\n",
      "30000/30000 [==============================] - 18s 608us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 12.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.1395 - acc: 0.957 - 76s 1ms/step - loss: 0.1393 - acc: 0.9579\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 52s 866us/step - loss: 0.0487 - acc: 0.9848\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 52s 861us/step - loss: 0.0359 - acc: 0.9890\n",
      "Best: 0.986400 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.985950 (0.000683) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [3, 3], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.986400 (0.001067) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.984433 (0.000833) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "Best: 0.986400 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "Test Accuracy 0.9908000066280365\n"
     ]
    }
   ],
   "source": [
    "#kernel size\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[3,3], [4,4], [5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam\n",
    "#BEST ACTIVATIONS tanh, relu, relu, tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.1788 - acc: 0.9440\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 882us/step - loss: 0.0474 - acc: 0.9849\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 0.0274 - acc: 0.9914\n",
      "30000/30000 [==============================] - 18s 601us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 0.1776 - acc: 0.9472\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 877us/step - loss: 0.0431 - acc: 0.9872\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 0.0231 - acc: 0.9936\n",
      "30000/30000 [==============================] - 18s 599us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 0.1835 - acc: 0.9423\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 872us/step - loss: 0.0474 - acc: 0.9860\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 864us/step - loss: 0.0309 - acc: 0.9903\n",
      "30000/30000 [==============================] - 18s 604us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.1943 - acc: 0.9389- ETA: 1s - loss: 0.1996 - ac\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 818us/step - loss: 0.0466 - acc: 0.9865\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.0258 - acc: 0.9922\n",
      "30000/30000 [==============================] - 18s 597us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.1136 - acc: 0.9648\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 52s 862us/step - loss: 0.0338 - acc: 0.9893\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 52s 863us/step - loss: 0.0223 - acc: 0.9932\n",
      "Best: 0.985667 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985667 (0.000733) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.983400 (0.000033) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "Best: 0.985667 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "Test Accuracy 0.9916000044345856\n"
     ]
    }
   ],
   "source": [
    "#pool size\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[4,4]],\n",
    "              'pool_size' : [[1,1], [2,2]],\n",
    "              'dropout_1' : [0.0],\n",
    "              'dropout_2' : [0.0]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.2254 - acc: 0.9333\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 915us/step - loss: 0.0541 - acc: 0.9829\n",
      "30000/30000 [==============================] - 7s 222us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 21s 705us/step - loss: 0.1710 - acc: 0.9479\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 794us/step - loss: 0.0466 - acc: 0.9852\n",
      "30000/30000 [==============================] - 7s 246us/step\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.1990 - acc: 0.9375\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.0554 - acc: 0.9834\n",
      "30000/30000 [==============================] - 10s 341us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.1895 - acc: 0.9402\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.0519 - acc: 0.9842\n",
      "30000/30000 [==============================] - 11s 354us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.2181 - acc: 0.9338\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.0641 - acc: 0.9804\n",
      "30000/30000 [==============================] - 11s 369us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.2110 - acc: 0.9349\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.0576 - acc: 0.9830\n",
      "30000/30000 [==============================] - 11s 354us/step\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 45s 1ms/step - loss: 0.3117 - acc: 0.9082\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.0981 - acc: 0.9732\n",
      "30000/30000 [==============================] - 8s 258us/step\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 23s 758us/step - loss: 0.2925 - acc: 0.9127\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 807us/step - loss: 0.0965 - acc: 0.9734\n",
      "30000/30000 [==============================] - 7s 246us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 949us/step - loss: 0.1823 - acc: 0.9427\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 835us/step - loss: 0.0507 - acc: 0.9841\n",
      "30000/30000 [==============================] - 8s 259us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 898us/step - loss: 0.1892 - acc: 0.9421\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 845us/step - loss: 0.0491 - acc: 0.9850\n",
      "30000/30000 [==============================] - 7s 243us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 24s 786us/step - loss: 0.2086 - acc: 0.9356\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 777us/step - loss: 0.0610 - acc: 0.9813\n",
      "30000/30000 [==============================] - 7s 240us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 862us/step - loss: 0.2078 - acc: 0.9355\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 762us/step - loss: 0.0563 - acc: 0.9830\n",
      "30000/30000 [==============================] - 7s 224us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 819us/step - loss: 0.2440 - acc: 0.9255\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 786us/step - loss: 0.0756 - acc: 0.9783\n",
      "30000/30000 [==============================] - 7s 237us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 817us/step - loss: 0.2177 - acc: 0.9338\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 821us/step - loss: 0.0698 - acc: 0.9800\n",
      "30000/30000 [==============================] - 7s 234us/step\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 900us/step - loss: 0.2956 - acc: 0.9117\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 770us/step - loss: 0.0995 - acc: 0.9725\n",
      "30000/30000 [==============================] - 8s 274us/step\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 909us/step - loss: 0.3305 - acc: 0.9017\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 881us/step - loss: 0.1064 - acc: 0.9712\n",
      "30000/30000 [==============================] - 7s 242us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 864us/step - loss: 0.1957 - acc: 0.94111s - loss: 0.2\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 772us/step - loss: 0.0570 - acc: 0.9823\n",
      "30000/30000 [==============================] - 7s 238us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 829us/step - loss: 0.2055 - acc: 0.9360\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 743us/step - loss: 0.0561 - acc: 0.9830\n",
      "30000/30000 [==============================] - 7s 241us/step\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 817us/step - loss: 0.2119 - acc: 0.9338\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 753us/step - loss: 0.0671 - acc: 0.9791\n",
      "30000/30000 [==============================] - 7s 242us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 829us/step - loss: 0.2182 - acc: 0.9330\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 782us/step - loss: 0.0668 - acc: 0.9799\n",
      "30000/30000 [==============================] - 7s 249us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 0.2382 - acc: 0.9275\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 772us/step - loss: 0.0831 - acc: 0.9751\n",
      "30000/30000 [==============================] - 7s 246us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 843us/step - loss: 0.2396 - acc: 0.9297\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 799us/step - loss: 0.0812 - acc: 0.9760\n",
      "30000/30000 [==============================] - 8s 279us/step\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 928us/step - loss: 0.3317 - acc: 0.9002\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 767us/step - loss: 0.1201 - acc: 0.96711s - loss:\n",
      "30000/30000 [==============================] - 7s 245us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 904us/step - loss: 0.3276 - acc: 0.9017\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 806us/step - loss: 0.1208 - acc: 0.9663\n",
      "30000/30000 [==============================] - 8s 276us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 925us/step - loss: 0.2279 - acc: 0.9289\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 852us/step - loss: 0.0826 - acc: 0.9738\n",
      "30000/30000 [==============================] - 7s 244us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 965us/step - loss: 0.2299 - acc: 0.9285\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 771us/step - loss: 0.0791 - acc: 0.9755\n",
      "30000/30000 [==============================] - 7s 249us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 919us/step - loss: 0.2577 - acc: 0.9195\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 0.0915 - acc: 0.97140s - loss: 0.0914 - acc: \n",
      "30000/30000 [==============================] - 8s 281us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 851us/step - loss: 0.2524 - acc: 0.9218\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 747us/step - loss: 0.0971 - acc: 0.9700\n",
      "30000/30000 [==============================] - 7s 245us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 827us/step - loss: 0.3097 - acc: 0.9048\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 789us/step - loss: 0.1170 - acc: 0.96561s - loss: 0.117\n",
      "30000/30000 [==============================] - 8s 253us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 862us/step - loss: 0.3155 - acc: 0.9031\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 782us/step - loss: 0.1153 - acc: 0.96492s \n",
      "30000/30000 [==============================] - 8s 269us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 901us/step - loss: 0.4011 - acc: 0.87693s - los - ETA: 0s - loss: 0.4051 - acc: 0\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 745us/step - loss: 0.1549 - acc: 0.9577\n",
      "30000/30000 [==============================] - 8s 265us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 846us/step - loss: 0.3987 - acc: 0.8790\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 763us/step - loss: 0.1548 - acc: 0.9557\n",
      "30000/30000 [==============================] - 7s 247us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 33.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 47s 779us/step - loss: 0.1350 - acc: 0.9592\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 42s 694us/step - loss: 0.0395 - acc: 0.9878\n",
      "Best: 0.985283 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.983767 (0.000233) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985283 (0.000250) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.982283 (0.001450) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.5, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985183 (0.000817) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.75, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.984367 (0.002500) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.0, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985033 (0.000533) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.984033 (0.001633) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.5, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985050 (0.000083) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.75, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.982967 (0.000033) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.5, 'dropout_2': 0.0, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985183 (0.000550) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.5, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.984367 (0.000233) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.5, 'dropout_2': 0.5, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.983200 (0.001233) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.5, 'dropout_2': 0.75, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.982933 (0.000033) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.75, 'dropout_2': 0.0, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.983250 (0.000783) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.75, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.981450 (0.000050) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.75, 'dropout_2': 0.5, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.981983 (0.000150) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.75, 'dropout_2': 0.75, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "Best: 0.985283 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "10000/10000 [==============================] - 3s 308us/step\n",
      "Test Accuracy 0.9899000067710877\n"
     ]
    }
   ],
   "source": [
    "#dropouts\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [2],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[4,4]],\n",
    "              'pool_size' : [[1,1]],\n",
    "              'dropout_1' : [0.0],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 971us/step - loss: 0.3488 - acc: 0.9380\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 841us/step - loss: 0.1913 - acc: 0.9741\n",
      "30000/30000 [==============================] - 9s 287us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.3720 - acc: 0.9336\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 891us/step - loss: 0.1884 - acc: 0.9744\n",
      "30000/30000 [==============================] - 9s 298us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 960us/step - loss: 0.5543 - acc: 0.9188\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 841us/step - loss: 0.2882 - acc: 0.96081s - loss: 0.2874 -\n",
      "30000/30000 [==============================] - 9s 300us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 0.5545 - acc: 0.9187\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 877us/step - loss: 0.2782 - acc: 0.9619\n",
      "30000/30000 [==============================] - 8s 276us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 921us/step - loss: 1.0115 - acc: 0.8761\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 848us/step - loss: 0.4879 - acc: 0.9362\n",
      "30000/30000 [==============================] - 8s 281us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 1.0355 - acc: 0.8635\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 0.4474 - acc: 0.93941s - loss: 0.447\n",
      "30000/30000 [==============================] - 8s 283us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 945us/step - loss: 0.4508 - acc: 0.9266\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 837us/step - loss: 0.2188 - acc: 0.9662\n",
      "30000/30000 [==============================] - 9s 284us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 936us/step - loss: 0.4335 - acc: 0.9310\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 832us/step - loss: 0.2078 - acc: 0.9700\n",
      "30000/30000 [==============================] - 9s 313us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.6107 - acc: 0.9115\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 0.2988 - acc: 0.9561\n",
      "30000/30000 [==============================] - 9s 284us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.6171 - acc: 0.9136\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 884us/step - loss: 0.2899 - acc: 0.9589\n",
      "30000/30000 [==============================] - 9s 299us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 1.0813 - acc: 0.8619\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 932us/step - loss: 0.4444 - acc: 0.93413s -\n",
      "30000/30000 [==============================] - 10s 326us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 1.1465 - acc: 0.8590\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 965us/step - loss: 0.4773 - acc: 0.9315\n",
      "30000/30000 [==============================] - 10s 318us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.6535 - acc: 0.9099\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 847us/step - loss: 0.2495 - acc: 0.9603\n",
      "30000/30000 [==============================] - 9s 287us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 950us/step - loss: 0.6096 - acc: 0.9188\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 832us/step - loss: 0.2356 - acc: 0.9643\n",
      "30000/30000 [==============================] - 9s 288us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.8045 - acc: 0.8865\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 874us/step - loss: 0.4734 - acc: 0.9340\n",
      "30000/30000 [==============================] - 10s 322us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.7980 - acc: 0.8891\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 875us/step - loss: 0.3490 - acc: 0.9477\n",
      "30000/30000 [==============================] - 9s 303us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 1.2692 - acc: 0.8437\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 965us/step - loss: 0.6132 - acc: 0.9142\n",
      "30000/30000 [==============================] - 9s 298us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 1.2328 - acc: 0.8412\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 916us/step - loss: 0.7773 - acc: 0.9044\n",
      "30000/30000 [==============================] - 11s 351us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 19.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.2774 - acc: 0.9550\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 55s 922us/step - loss: 0.1662 - acc: 0.9775\n",
      "Best: 0.978967 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.978967 (0.000267) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.971250 (0.000283) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.01, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.947100 (0.002467) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.1, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.974967 (0.000700) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.01, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.969217 (0.002150) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.01, 'kreg2': 0.01, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.953667 (0.003400) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.01, 'kreg2': 0.1, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.971200 (0.000233) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.1, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.959817 (0.000350) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.1, 'kreg2': 0.01, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.936567 (0.000133) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.1, 'kreg2': 0.1, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "Best: 0.978967 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "10000/10000 [==============================] - 4s 410us/step\n",
      "Test Accuracy 0.981000004529953\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "def create_model(optimizer, activation_1, activation_2, activation_3, activation_4, kernel_size, pool_size, dropout_1, dropout_2, kreg1, kreg2, breg1, breg2):\n",
    "    model = Sequential()\n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(6, kernel_size=kernel_size, strides=(1, 1), activation=activation_1, input_shape=(28,28,1), padding=\"same\"))\n",
    "\n",
    "    # First pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(1, 1), padding='valid'))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(16, kernel_size=kernel_size, strides=(1, 1), activation=activation_2, padding='valid'))\n",
    "    \n",
    "    # Second pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(2, 2), padding='valid'))\n",
    "    \n",
    "    # Connected convolutional layer\n",
    "    model.add(layers.Conv2D(120, kernel_regularizer=regularizers.l2(kreg1), bias_regularizer=regularizers.l2(breg1), kernel_size=kernel_size, strides=(1, 1), activation=activation_3, padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dropout(dropout_1)) \n",
    "    # Connected layer\n",
    "    model.add(layers.Dense(84, kernel_regularizer=regularizers.l2(kreg2), bias_regularizer=regularizers.l2(breg2), activation=activation_4))\n",
    "    model.add(Dropout(dropout_2)) \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # build/compile\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [2],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[4,4]],\n",
    "              'pool_size' : [[1,1]],\n",
    "              'dropout_1' : [0.0],\n",
    "              'dropout_2' : [0.25],\n",
    "              'kreg1' : [0.001 ,0.01, 0.1],\n",
    "              'kreg2' : [0.001, 0.01, 0.1],\n",
    "              'breg1' : [0.0],\n",
    "              'breg2' : [0.0]\n",
    "             }\n",
    "\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3487 - acc: 0.9374\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 926us/step - loss: 0.1897 - acc: 0.9741\n",
      "30000/30000 [==============================] - 10s 325us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3710 - acc: 0.9340\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 889us/step - loss: 0.1875 - acc: 0.9744\n",
      "30000/30000 [==============================] - 10s 324us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.3526 - acc: 0.9377\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 862us/step - loss: 0.1909 - acc: 0.97250s - loss: 0.1899 - acc:\n",
      "30000/30000 [==============================] - 9s 314us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.3535 - acc: 0.9383\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 960us/step - loss: 0.1925 - acc: 0.9737\n",
      "30000/30000 [==============================] - 10s 331us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.3527 - acc: 0.9393\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 0.1968 - acc: 0.9730\n",
      "30000/30000 [==============================] - 9s 314us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.3715 - acc: 0.9313: 0s - loss: 0.3733 - acc: 0.9\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 862us/step - loss: 0.1945 - acc: 0.9736\n",
      "30000/30000 [==============================] - 10s 317us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3750 - acc: 0.9328\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 865us/step - loss: 0.2002 - acc: 0.9714\n",
      "30000/30000 [==============================] - 10s 331us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3638 - acc: 0.9367\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 889us/step - loss: 0.1844 - acc: 0.9749\n",
      "30000/30000 [==============================] - 12s 396us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 46s 2ms/step - loss: 0.3557 - acc: 0.9375\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 0.1952 - acc: 0.9734\n",
      "30000/30000 [==============================] - 10s 336us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3554 - acc: 0.9382\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 914us/step - loss: 0.1903 - acc: 0.9741\n",
      "30000/30000 [==============================] - 11s 352us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3734 - acc: 0.9332\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 899us/step - loss: 0.1969 - acc: 0.9722\n",
      "30000/30000 [==============================] - 10s 331us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3769 - acc: 0.9313\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 890us/step - loss: 0.2045 - acc: 0.9715\n",
      "30000/30000 [==============================] - 10s 337us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.3700 - acc: 0.9326\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1966 - acc: 0.9726\n",
      "30000/30000 [==============================] - 11s 361us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3454 - acc: 0.9414\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 879us/step - loss: 0.1871 - acc: 0.9760\n",
      "30000/30000 [==============================] - 10s 349us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3751 - acc: 0.9306\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 920us/step - loss: 0.1970 - acc: 0.9727\n",
      "30000/30000 [==============================] - 11s 359us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3727 - acc: 0.9318\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 919us/step - loss: 0.1942 - acc: 0.9733\n",
      "30000/30000 [==============================] - 10s 349us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3568 - acc: 0.9361\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1942 - acc: 0.9734\n",
      "30000/30000 [==============================] - 11s 379us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 39s 1ms/step - loss: 0.3751 - acc: 0.9325\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 914us/step - loss: 0.1886 - acc: 0.9746\n",
      "30000/30000 [==============================] - 11s 359us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 21.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.2774 - acc: 0.9550\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 56s 925us/step - loss: 0.1667 - acc: 0.9769\n",
      "Best: 0.979900 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.001, 'breg2': 0.001, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.979900 (0.000033) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.001, 'breg2': 0.001, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.977150 (0.001183) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.001, 'breg2': 0.01, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.968983 (0.003717) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.001, 'breg2': 0.1, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.978783 (0.002050) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.01, 'breg2': 0.001, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.979017 (0.000150) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.01, 'breg2': 0.01, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.977850 (0.003017) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.01, 'breg2': 0.1, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.979450 (0.000917) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.1, 'breg2': 0.001, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.978400 (0.000667) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.1, 'breg2': 0.01, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.973867 (0.002500) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.1, 'breg2': 0.1, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "Best: 0.979900 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.001, 'breg2': 0.001, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "10000/10000 [==============================] - 6s 617us/step\n",
      "Test Accuracy 0.9805000035762786\n"
     ]
    }
   ],
   "source": [
    "def create_model(optimizer, activation_1, activation_2, activation_3, activation_4, kernel_size, pool_size, dropout_1, dropout_2, kreg1, kreg2, breg1, breg2):\n",
    "    model = Sequential()\n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(6, kernel_size=kernel_size, strides=(1, 1), activation=activation_1, input_shape=(28,28,1), padding=\"same\"))\n",
    "\n",
    "    # First pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(1, 1), padding='valid'))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(16, kernel_size=kernel_size, strides=(1, 1), activation=activation_2, padding='valid'))\n",
    "    \n",
    "    # Second pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(2, 2), padding='valid'))\n",
    "    \n",
    "    # Connected convolutional layer\n",
    "    model.add(layers.Conv2D(120, kernel_regularizer=regularizers.l2(kreg1), bias_regularizer=regularizers.l2(breg1), kernel_size=kernel_size, strides=(1, 1), activation=activation_3, padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dropout(dropout_1)) \n",
    "    # Connected layer\n",
    "    model.add(layers.Dense(84, kernel_regularizer=regularizers.l2(kreg2), bias_regularizer=regularizers.l2(breg2), activation=activation_4))\n",
    "    model.add(Dropout(dropout_2)) \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # build/compile\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [2],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[4,4]],\n",
    "              'pool_size' : [[1,1]],\n",
    "              'dropout_1' : [0.0],\n",
    "              'dropout_2' : [0.25],\n",
    "              'kreg1' : [0.001],\n",
    "              'kreg2' : [0.001],\n",
    "              'breg1' : [0.001, 0.01, 0.1],\n",
    "              'breg2' : [0.001, 0.01, 0.1]\n",
    "             }\n",
    "\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.2679 - acc: 0.9199 - val_loss: 0.2019 - val_acc: 0.9372\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 52s 871us/step - loss: 0.1646 - acc: 0.9503 - val_loss: 0.1232 - val_acc: 0.9611\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.1215 - acc: 0.9637 - val_loss: 0.1015 - val_acc: 0.9686\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 53s 877us/step - loss: 0.1011 - acc: 0.9693 - val_loss: 0.0963 - val_acc: 0.9691\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 53s 891us/step - loss: 0.0907 - acc: 0.9722 - val_loss: 0.0758 - val_acc: 0.9795\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 55s 916us/step - loss: 0.0842 - acc: 0.9740 - val_loss: 0.0744 - val_acc: 0.9782\n",
      "10000/10000 [==============================] - 4s 430us/step\n",
      "Test loss 0.0744, accuracy 97.82%\n"
     ]
    }
   ],
   "source": [
    "# ORIGINAL MODEL ARCHITECTURE\n",
    "model = Sequential()\n",
    "#First convolutional layer\n",
    "model.add(layers.Conv2D(6, kernel_size=(5,5), strides=(1, 1), activation='tanh', input_shape=(28,28,1), padding=\"same\"))\n",
    "# First pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2,2), strides=(1, 1), padding='valid'))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(layers.Conv2D(16, kernel_size=(5,5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    " \n",
    "# Second pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2,2), strides=(2, 2), padding='valid'))\n",
    "   \n",
    "# Connected convolutional layer\n",
    "model.add(layers.Conv2D(120, kernel_size=(5,5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "model.add(layers.Flatten())\n",
    "# Connected layer\n",
    "model.add(layers.Dense(84, activation='tanh'))\n",
    "# Output layer\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "  \n",
    "# build/compile\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    \n",
    "hist = model.fit(x=x_train,y=y_train, epochs=6, batch_size=120, validation_data=(x_test, y_test), verbose=1)\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'acc')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['acc'], 'o-')\n",
    "ax.plot([None] + hist.history['val_acc'], 'x-')\n",
    "ax.legend(['Train acc', 'Validation acc'], loc = 0)\n",
    "ax.set_title('Training/Validation acc per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3hUZfbA8e9JDymEEiA06SVAgBhALAiIAlJVQFBUbKz6s+y6umJZC4u7uljQXRsWlFVBEEGq2ECwIaGF3lsSSmghkIS09/fHvYEhmTTI5Kacz/PMk5lbz4QwZ94uxhiUUkqp4vJyOgCllFIViyYOpZRSJaKJQymlVIlo4lBKKVUimjiUUkqViCYOpZRSJaKJQ5WIiHiLyCkRaVyax5Y1EflURJ63n/cUkY3FOfYC7lNufwfqnIv5N66KNHFUcvaHVu4jR0TSXF7fWtLrGWOyjTHBxph9pXlscYnIRyLynIikiEg1N/vXi8h9JbmmMWapMaZdKcX3s4iMcbl2qf8OXO4VLyI9S/u6ThORCSKSmedv94jTcalzNHFUcvaHVrAxJhjYBwxy2fZZ3uNFxKfsoyweERGgLzAZOATcmGd/J6Al8EXZR6cuRCF/b5+5/u0aY2qXaWCqUJo4qjj7290XIjJNRFKA0SLSXUR+F5ETInJARN4UEV/7eB8RMSLSxH79qb1/kV0K+E1Empb0WHt/fxHZJiLJIvIfEfnF9ds70Bk4ZIw5AEwFbs/zdm4H5hpjjouIl4h8KSIH7fexVETaFvA76CMie1xeXyoia+0YpwH+LvtqichCEUkSkeMiMk9EGtj7Xga6A+/a35InufkdhNm/hyQR2SMiT9oJERG5R0R+EpHX7Zh3ich1xf/XPO893SciO0TkqIjMEZEIe7uX/W9w2P49x4lIpL1voIhstt93vIj8pYBr3yMiy0Tkbfsam0Wkl8v+MBGZYv/txIvIeBHxynPumyJyDHimhO8r9/f5kIjsFpEjIvKSy/W9RORZEdlrv8ePRSTU5fwe9t92sojsF5HbXC5fs6C/TXU+TRwK4Abgc6A61rf1LOARoDZwBdAP+FMh598C/B2oiVWq+UdJjxWROsAM4HH7vruBrnnOvR5YYD+fCvRy+dD2BkbZ23PNxyqB1AM2AP8rJC7s6/gDXwMf2TF+DQx1OcQLeB9oDFwCZAJvABhjngB+A+6zvyX/2c0t3gaqAc2A3sDdnJ8ALwfWA7WA14EPi4rZzXu4DhgPDAMaAIlAbumyP3AZ1u+lBjASOGbvmwLcbYwJAaKAnwq5zeXAFqx/q38As0UkzN73KZAGNAdigAHAnXnO3QyEAy+X9P3ZhgDR9vWHce53eA8wGuhp378G9r+PnQgWAK9h/X47Y/2uc5Xk77hqM8boo4o8gD1AnzzbJgA/FnHeY8BM+7kPYIAm9utPgXddjh0MbLiAY+8ClrvsE+AAMMZl229Ad5fXS4G/2c/7Y1Vf+RTwHmrbsQS5xPK8/bwPsMd+3hvYD4jLuX/kHuvmujFAksvrn/PEfPZ3APhiJeVWLvv/D/jefn4PsMVlX6h9bu0C7h0P9HSz/RPgn3mukw00BK7D+sDvBnjlOS/RjiGkiL+He9z8jlZjJe4GWEnD32XfbcB3LufuKuL6E4AM4ITLI/f83N9nH5fjHwYW289/Asa67GsHnMFK+H/H/jt2c88C/zb1kf+hJQ4F1ofAWSLSRkQW2NU8J7G+vRZWx3zQ5XkqEHwBx9Z3jcNY/3vjXWKqhfUtfYXL+Z9w7pvmbVj14ln28d4i8m+7uucksMM+rqi68vpAvH3/XHtd4ggSkQ9EZJ993R+Lcc1cdQBv1+vZzxu4vM77+4HCf5/u1He9hzHmJHAcaGCM+RZ4F3gHOCQi74pIiH3oDVgfmPvsqr1uhdzD3e+oPlYpzN++9gkROQG8BdR1Ofa8v7cCfG6MCXN5XJtnv+s1cu8Ned67/dwPq3TTCNhZyD1L8ndcpWniUGB9g3P1HlbVTgtjTCjwLFYJwJMOYH0jBs42hLt+oPbD+taZ47JtJtBURK7Gqrpwraa6HatqqzdWFVyL3EuXJA6ba1favwFNga7276Z3nmMLm276MNY3/0vyXDuhiJhKKtH1HnZiqJF7H2PMJGNMNNAeiAQetbevMMYMxkpw84HphdzD3e8oEesDPRWo6fKhH2qMiXI5tjSm5G7k5t6Q573b+zKAJDu25qVw7ypPE4dyJwRIBk7bDcqFtW+UlvlAtIgMEqunzSNY3xJzDQAWup5gjDkFfIVV8thhjFnrsjsEq4riKFabwovFjONnwEtEHrQbYodj1aW7XjcVOG6Xgp7Nc/4hrJJRPsaYTOBL4J8iEmzXuf8Fq5rkQvmJSIDLwweYBtwtIlF2m82/sKoB40Wkq/3wAU5jfahmi0igiNwiIqF2nClYSa4gES6/o5FYH8jfGGP2Y1UXvSIioXZjdQsR6XER79Gdv9mN8I2xqqpye9JNAx4VkSZ2wnwRmGZ/4fgU6CciN9lx1xaRjqUcV5WgiUO581fgDqwPj/cog+6txphDwM1YDZdHsT6I1gBn7B4z1wCL3Zz6CdY3zKl5tk/B+vaZCGwEfi1mHGewqmzuxareuRGY43LIa1glmKP2NRflucQkYJRdTfOam1s8gPVhvRvrA/YTN7GXxGKsNoXcxzPGmG+wqhdnY5WgGgO5Y3bCsBrcT2C1eR3AaoQH6998r10FdzdW9V9BfsVqPzgGPA/cZIw5bu8bDQQBm7B+hzOxOiiUxK1y/jiOU3aizjUPWIv1NzIb+Nje/j7W3+tyYBfW3/AjAMaY3cAg4Ak77tVAhxLGpbAbt5Qqb+xeUolYPWaygVeMMZc7G5UCq0stMNoY09OBe/tg9WRraozZU9b3VxYtcahyQ0T6iUh1u3rl71g9kP4AcoAXHA1OKXVWuR0lrKqkK7HGG/hhVS8NtauOfnc0KqXUebSqSimlVIloVZVSSqkS8WhVlYj0wxru7w18YIx5Kc/+R7FGkmZh9bO+yxiz15735nWXQ9sAI40xc0TkY+BqrO6iYI3Sde2GmU/t2rVNkyZNSuEdKaVU1bFq1aojxpjwvNs9VlVl94rZBlyLNQJ4JTDKGLPJ5ZhewApjTKqI3I81fcLNea5TE2vUb0P7uI+B+caYL4sbS0xMjImNjb3o96SUUlWJiKwyxsTk3e7JqqquWIOydhljMrBGoQ5xPcAYs8QYkzutwu/kH40KVnfMRS7HKaWUcpAnE0cDzp9PJp7zp5DI627yD6YCa/bOaXm2vSjWdNCv21038xGRsSISKyKxSUlJJYlbKaVUITyZONzNCeS2XkxERmPNMjoxz/YIrJGdriOGn8Rq8+iCNf3xE+6uaYyZbIyJMcbEhIfnq6JTSil1gTzZOB7P+RORNeTcRGRniUgf4GngarvPvqsRwGx77hwAjLWID1hTUUzBmvJbKeWwzMxM4uPjSU9PdzoUVUIBAQE0bNgQX1/fYh3vycSxEmhpT+SWgFXldIvrASLSGWsupH7GmMNurjEKq4Thek6EMeaAPXvqUKxZXJVSDouPjyckJIQmTZpg/fdUFYExhqNHjxIfH0/TpsVb9NBjicMYkyUiD2JVM3kDHxljNorIeCDWGDMXq2oqGJhp/6Hts6d1RqylNhuRfxWyz0QkHKsqbC1wnyfin7MmgYmLt5J4Io36YYE83rc1QzsX1kSjVNWWnp6uSaMCEhFq1apFSdqCPTqOwxizkPxTYT/r8rxPIefuwU1jujEm7/oHpW7OmgSe/Go9aZnWrNIJJ9J48itrhUlNHkoVTJNGxVTSfzcdOe7GxMVbzyaNXGmZ2UxcvNWhiJRSqvzQxOFG4om0Em1XSjnv6NGjdOrUiU6dOlGvXj0aNGhw9nVGRkaxrnHnnXeydWvxvyB+8MEH/PnPf77QkCssnR3XjfphgSS4SRL1wwIdiEapyqm02xFr1arF2rXW7EPPP/88wcHBPPbY+Z0ujTEYY/Dycv+decqUKRd8/6pESxxuPN63NYG+3udt8/fx4vG+rR2KSKnKJbcdMeFEGoZz7Yhz1pT28uuwY8cO2rdvz3333Ud0dDQHDhxg7NixxMTE0K5dO8aPH3/22CuvvJK1a9eSlZVFWFgY48aNo2PHjnTv3p3Dh911/HTv008/pUOHDrRv356nnnoKgKysLG677baz2998800AXn/9dSIjI+nYsSOjR48u3TfvIVricCP3W0/utyERqBvqz+CO9R2OTKmK4YV5G9mUeLLA/Wv2nSAjO+e8bWmZ2fztyzim/bHP7TmR9UN5blC7C4pn06ZNTJkyhXfffReAl156iZo1a5KVlUWvXr0YNmwYkZGR552TnJzM1VdfzUsvvcSjjz7KRx99xLhx44q8V3x8PM888wyxsbFUr16dPn36MH/+fMLDwzly5Ajr11sdbU6cOAHAv//9b/bu3Yufn9/ZbeWdljgKMLRzA34Z15vdLw1g4rCO7DuWxpy1pf9tSKmqKG/SKGr7xWrevDldunQ5+3ratGlER0cTHR3N5s2b2bRpU75zAgMD6d+/PwCXXnope/bsKda9VqxYQe/evalduza+vr7ccsstLFu2jBYtWrB161YeeeQRFi9eTPXq1QFo164do0eP5rPPPiv2ADynaYmjGG7o3ICpv+/lpUVb6NuuHkH++mtTqjBFlQyueOlHt+2IDcIC+eJP3Us9nqCgoLPPt2/fzhtvvMEff/xBWFgYo0ePdjva3c/P7+xzb29vsrKyinWvgmYcr1WrFnFxcSxatIg333yTWbNmMXnyZBYvXsxPP/3E119/zYQJE9iwYQPe3t5ur1FeaImjGLy8hGcHRnI45QzvLN3pdDhKVXju2hEDfb3LpB3x5MmThISEEBoayoEDB1i8eHHRJ5XAZZddxpIlSzh69ChZWVlMnz6dq6++mqSkJIwxDB8+nBdeeIHVq1eTnZ1NfHw8vXv3ZuLEiSQlJZGaWv4nAtevzsV06SU1uKFzAyYv38XNXRrRqGY1p0NSqsLK245YlrMzREdHExkZSfv27WnWrBlXXHHFRV3vww8/5Msvzy0PFBsby/jx4+nZsyfGGAYNGsSAAQNYvXo1d999N8YYRISXX36ZrKwsbrnlFlJSUsjJyeGJJ54gJCTkYt+ix1WJNcdLayGng8np9HplKT1bh/PO6EtLITKlKo/NmzfTtm1bp8NQF8jdv58TCzlVOvWqB/BAz+Ys2nCQ33YedTocpZRyhCaOErq3RzMahAXywryNZOdU/tKaUkrlpYmjhAJ8vXl6QFu2HExh+kr3/c2VUqoy08RxAfq3r0e3pjV59dttJKdlFn2CUkpVIpo4LoCI8OygSI6nZvDmD9udDkcppcqUJo4L1K5+dUZ2acwnv+5hx+FTToejlFJlxqOJQ0T6ichWEdkhIvkmeRGRR0Vkk4jEicgPInKJy75sEVlrP+a6bG8qIitEZLuIfCEifnmvW1Yeu64VgX7eTFiQf7oCpVTZ6tmzZ77BfJMmTeKBBx4o9Lzg4GAAEhMTGTZsWIHXLqpL/6RJk84bvHf99deXytxTzz//PK+88spFX6c0eSxxiIg38BbQH4gERolIZJ7D1gAxxpgo4Evg3y770owxnezHYJftLwOvG2NaAseBuz31HopSK9ifR65pydKtSSzZUvyZM5Wq8n6eBLuXnb9t9zJr+wUaNWoU06dPP2/b9OnTGTVqVLHOr1+//nkD+Uoqb+JYuHAhYWFhF3y98syTJY6uwA5jzC5jTAYwHRjieoAxZokxJvc3/TvQsLALirW+YW+sJAPwCTC0VKMuodu7N6FZ7SD+sWATGVmemaBNqUqnQTTMHHMueexeZr1uEH3Blxw2bBjz58/nzJkzAOzZs4fExESuvPJKTp06xTXXXEN0dDQdOnTg66+/znf+nj17aN++PQBpaWmMHDmSqKgobr75ZtLSzs2rdf/995+dkv25554D4M033yQxMZFevXrRq1cvAJo0acKRI0cAeO2112jfvj3t27dn0qRJZ+/Xtm1b7r33Xtq1a8d111133n2K4u6ap0+fZsCAAXTs2JH27dvzxRdfADBu3DgiIyOJiorKt0bJhfDklCMNgP0ur+OBboUcfzewyOV1gIjEAlnAS8aYOUAt4IQxJne2sXjcrEtelvx8vPj7wEju/HglU3/bwz1XNXMyHKXKh0Xj4OD6wo8JiYD/3WD9TDkA4W1g6cvWw516HaD/SwVerlatWnTt2pVvvvmGIUOGMH36dG6++WZEhICAAGbPnk1oaChHjhzhsssuY/DgwQWutf3OO+9QrVo14uLiiIuLIzr6XEJ78cUXqVmzJtnZ2VxzzTXExcXx8MMP89prr7FkyRJq16593rVWrVrFlClTWLFiBcYYunXrxtVXX02NGjXYvn0706ZN4/3332fEiBHMmjWrWGtyFHTNXbt2Ub9+fRYsWABYU8MfO3aM2bNns2XLFkSkVKrPPFnicPcv4nbEnIiMBmKAiS6bG9tD3W8BJolI8xJec6yIxIpIbFJSUskiL6FeberQs3U4b/ywnSOnznj0XkpVGgFhVtJI3m/9DLj4ah3X6irXaipjDE899RRRUVH06dOHhIQEDh06VOB1li1bdvYDPCoqiqioqLP7ZsyYQXR0NJ07d2bjxo1up2R39fPPP3PDDTcQFBREcHAwN954I8uXLwegadOmdOrUCSjZ1O0FXbNDhw58//33PPHEEyxfvpzq1asTGhpKQEAA99xzD1999RXVql38PHueLHHEA41cXjcEEvMeJCJ9gKeBq40xZz91jTGJ9s9dIrIU6AzMAsJExMcudbi9pn3eZGAyWHNVlcYbKswzAyLpN2kZr367jX/d2MHTt1OqfCukZHBWbvVUj79B7IfQ8wlo2uOibjt06FAeffRRVq9eTVpa2tmSwmeffUZSUhKrVq3C19eXJk2auJ1K3ZW70sju3bt55ZVXWLlyJTVq1GDMmDFFXqew+QD9/f3PPvf29i52VVVB12zVqhWrVq1i4cKFPPnkk1x33XU8++yz/PHHH/zwww9Mnz6d//73v/z444/Fuk9BPFniWAm0tHtB+QEjgbmuB4hIZ+A9YLAx5rDL9hoi4m8/rw1cAWwy1m9rCZDb9eEOIH9lpQNa1Anm9u5NmL5yHxsTk50OR6nyLTdpDP8Yej9t/XRt87hAwcHB9OzZk7vuuuu8RvHk5GTq1KmDr68vS5YsYe/evYVep0ePHnz22WcAbNiwgbi4OMCakj0oKIjq1atz6NAhFi06V7seEhJCSkqK22vNmTOH1NRUTp8+zezZs7nqqqsu6n0WdM3ExESqVavG6NGjeeyxx1i9ejWnTp0iOTmZ66+/nkmTJp1dl/1ieKzEYYzJEpEHgcWAN/CRMWajiIwHYo0xc7GqpoKBmXZ232f3oGoLvCciOVjJ7SVjTG558AlguohMwOqV9aGn3kNJPXJNS+asTWD8vE1MH3tZgfWnSlV5CautZJFbwmjaw3qdsPqiSx2jRo3ixhtvPK+H1a233sqgQYOIiYmhU6dOtGnTptBr3H///dx5551ERUXRqVMnunbtCkDHjh3p3Lkz7dq1yzcl+9ixY+nfvz8REREsWbLk7Pbo6GjGjBlz9hr33HMPnTt3Lna1FMCECRPONoCDtTytu2suXryYxx9/HC8vL3x9fXnnnXdISUlhyJAhpKenY4zh9ddfL/Z9C6LTqpeyz1bs5enZG3j71miu7xBRJvdUqjzQadUrNp1W3UEjuzSmTb0Q/rlwM+mZ2U6Ho5RSpU4TRynz9rLmsYo/nsYHy3c5HY5SSpU6TRwecHnz2vRvX4+3luzkYHLhPS6UqkyqQtV3ZVTSfzdNHB7y1PVtyTaGl7/Z4nQoSpWJgIAAjh49qsmjgjHGcPToUQICAop9jifHcVRpjWpW496rmvLWkp3c1v0SohvXcDokpTyqYcOGxMfH4+kBt6r0BQQE0LBhoTM+nUcThwc90LMFM2PjeWHeJmbffzleXto9V1Vevr6+NG3a1OkwVBnQqioPCvL3YVz/Nqzbf4LZaxKcDkcppUqFJg4PG9qpAR0bhfHyN1s4fSar6BOUUqqc08ThYV5ewnODIjmccoa3l+5wOhyllLpomjjKQHTjGtzYuQHvL9/NvqOpRZ+glFLlmCaOMvK3fm3w8RL+uXCz06EopdRF0cRRRupVD+CBns35ZuNBft15xOlwlFLqgmniKEP3XNWMhjUCGT9vE1nZusysUqpi0sRRhgJ8vXn6+rZsOZjC9JX7iz5BKaXKIU0cZaxf+3pc1qwmr367leTUTKfDUUqpEtPEUcZEhGcHtiM5LZM3ftjudDhKKVVimjgcEFk/lJFdGzP1tz3sOJx/qUmllCrPPJo4RKSfiGwVkR0iMs7N/kdFZJOIxInIDyJyib29k4j8JiIb7X03u5zzsYjsFpG19qOTJ9+Dp/z12lYE+nkzfv5mnU1UKVWheCxxiIg38BbQH4gERolIZJ7D1gAxxpgo4Evg3/b2VOB2Y0w7oB8wSUTCXM573BjTyX5c/MrrDqgV7M+f+7Ri2bYklmw97HQ4SilVbJ4scXQFdhhjdhljMoDpwBDXA4wxS4wxuUOpfwca2tu3GWO2288TgcNAuAdjdcTt3S+hWXgQE+ZvJiNLu+cqpSoGTyaOBoBrn9N4e1tB7gYW5d0oIl0BP2Cny+YX7Sqs10XE393FRGSsiMSKSGx5XR/A19uLvw+MZNeR00z9bY/T4SilVLF4MnG4W3zCbWW+iIwGYoCJebZHAP8D7jTG5H4lfxJoA3QBagJPuLumMWayMSbGGBMTHl5+Cyu9WtehV+tw3vh+O0dOnXE6HKWUKpInE0c80MjldUMgMe9BItIHeBoYbIw547I9FFgAPGOM+T13uzHmgLGcAaZgVYlVaM8MjCQtM5tXv93qdChKKVUkTyaOlUBLEWkqIn7ASGCu6wEi0hl4DytpHHbZ7gfMBqYaY2bmOSfC/inAUGCDB99DmWgeHswdlzdh+sr9bExMdjocpZQqlMcShzEmC3gQWAxsBmYYYzaKyHgRGWwfNhEIBmbaXWtzE8sIoAcwxk23289EZD2wHqgNTPDUeyhLD1/TkhrV/Hhh3ibtnquUKtekKnxIxcTEmNjYWKfDKNLnK/bx1Oz1vHVLNAOiIpwORylVxYnIKmNMTN7tOnK8HLm5SyPaRoTyz4WbSc/MdjocpZRySxNHOeLtJTw7MJKEE2m8v2yX0+EopZRbmjjKme7Na3F9h3q8vXQnB5LTnA5HKaXy0cRRDj3Zvy3ZxvDyoi1Oh6KUUvlo4iiHGtWsxtirmjFnbSKr9h53OhyllDqPJo5y6v6ezakb6s/4eRvJyan8Pd+UUhWHJo5yKsjfh3H927AuPpmv1iQ4HY5SSp2liaMcG9KxAZ0ahfHyN1s4dSbL6XCUUgrQxFGueXkJzw2KJCnlDG8v2eF0OEopBWjiKPc6N67BjdEN+GD5bvYdTS36BKWU8jBNHBXAE/3a4OMtvLhwk9OhKKWUJo6KoG5oAP/XqwWLNx7i1x1HnA5HKVXFaeKoIO6+sikNawQyfv4msrJ1mVmllHM0cVQQAb7ePDOgLVsOpjBt5f6iT1BKKQ/RxFGB9G1Xj+7NavHat1tJTs10OhylVBWlicOdnyfB7mXnb9u9zNruIBHh2UGRJKdlMumHbY7GopSqujyaOESkn4hsFZEdIjLOzf5HRWSTiMSJyA8iconLvjtEZLv9uMNl+6Uist6+5pv2ErKlq0E0zBwD276D5HgracwcY213WNuIUEZ1bczU3/ay/VCK0+EopaogjyUOEfEG3gL6A5HAKBGJzHPYGiDGGBMFfAn82z63JvAc0A3oCjwnIjXsc94BxgIt7Ue/Ug++aQ8YNgWmj4TJPWHmHTD8Y2t7OfDota0I8vNm/HxdZlYpVfY8WeLoCuwwxuwyxmQA04EhrgcYY5YYY3JHtf0ONLSf9wW+M8YcM8YcB74D+olIBBBqjPnNWJ+YU4GhHom+2dUQORROJ0Fow3KTNABqBfvzSJ9WLN9+hB+3HHY6HKVUFePJxNEAcO3+E29vK8jdwKIizm1gPy/uNS/c7mWwawk0ugwOxsF3z3vkNhfq9u6X0Dw8iAkLNpORpd1zlVJlx5OJw13bg9t6FREZDcQAE4s4tyTXHCsisSISm5SUVIxwXeS2aQz/GMYsgLrt4ZfXYc2nJbuOB/l6e/H3gZHsPnKaT37d43Q4SqkqxJOJIx5o5PK6IZCY9yAR6QM8DQw2xpwp4tx4zlVnFXhNAGPMZGNMjDEmJjw8vGSRJ6w+16bh7QOjZ0FAdfjuOThzqmTX8qCerevQu00d3vxhO0kpZ4o+QSmlSoEnE8dKoKWINBURP2AkMNf1ABHpDLyHlTRcK+sXA9eJSA27Ufw6YLEx5gCQIiKX2b2pbge+LvXIr/zz+W0aIfVgxP8g9SjM/wuUowbppwe0JS0zm1e/3ep0KEqpKsJjicMYkwU8iJUENgMzjDEbRWS8iAy2D5sIBAMzRWStiMy1zz0G/AMr+awExtvbAO4HPgB2ADs51y7iWc2uhl5PwfoZsPqTMrllcTQPD2bM5U34InY/GxKSnQ5HKVUFSFXozhkTE2NiY2Mv/kI5OfDZTbDnF7jne4iIuvhrloLktEx6v7KU5uHBfPGny/DE0BalVNUjIquMMTF5t+vI8ZLw8oIb34dqtayxHeknnY4IgOqBvjzWtzV/7DnGgvUHnA5HKVXJaeIoqaDaMOwjOL4X5j5Ubto7RsQ0om1EKP9auIX0zGynw1FKVWKaOC7EJd2hz3OwaQ788b7T0QDgbS8zm3AijcnLdjkdjlKqEtPEcaG6PwSt+sHipyBhldPRAHBZs1oM6BDB20t3kHgizelwlFKVlCaOC+XlBUPfsbrqzhgDacedjgiAcf3bYAy8/M0Wp0NRSlVSmjguRrWa1kDBlAMw+/5y0d7RqGY1xvZoxtdrE1m191jRJyilVAlp4rhYDWPgugmwbRH8+h+nowHg/p7NqRcawAvzNpGT43wyU0pVLpo4SkO3P0HbwfD987Dvd6ejoZqfD+P6tyEuPmgUaoEAACAASURBVJlZq+OLPkEppUpAE0dpEIEh/4WwxjDzTjh9xOmIGNKpPp0bh/HvxVs5dSbL6XCUUpWIJo7SElAdRnxizWf11b3WKHMHiQjPDWpHUsoZ3lqyw9FYlFKViyaO0hTREfq/DDt/hOWvOh0NnRqFcVN0Qz5cvpu9R087HY5SqpLQxFHaLh0DHUbA0n/Crp+cjoYn+rXG11t4ccFmp0NRSlUSmjhKmwgMfB1qtYBZ90DKQUfDqRMawAO9WvDtpkP8ssP5thelVMWnicMT/INhxFQ4k2Ilj2xnG6fvvrIpjWoGMn7eJrKydZlZpdTF0cThKXXawsDXYM9y+OklR0MJ8PXm6esj2XoohWl/7HM0FqVUxaeJw5M63QKdb4NlE2H7946G0rddXS5vXotXv9vGidQMR2NRSlVsxUocItJcRPzt5z1F5GERCfNsaJXE9ROhTjuri26yc4PxRIRnB0VyMi2TSd9vdywOpVTFV9wSxywgW0RaAB8CTYHPizpJRPqJyFYR2SEi49zs7yEiq0UkS0SGuWzvZS8lm/tIF5Gh9r6PRWS3y75OxXwPzvANtMZ3ZGfAl3dBdqZjobSpF8ot3Rrzv9/3sv1QimNxKKUqtuImjhx7DfEbgEnGmL8AEYWdICLewFtAfyASGCUikXkO2weMIU8SMsYsMcZ0MsZ0AnoDqcC3Loc8nrvfGLO2mO/BObVbwuA3Yf8K+OEFR0N59NrWBPl5M37+JqrCssFKqdJX3MSRKSKjgDuA+fY23yLO6QrsMMbsMsZkANOBIa4HGGP2GGPigMK6+gwDFhljUosZa/nU/iboco81EeKWBY6FUTPIjz/3acXy7Uf4YfNhx+JQSlVcxU0cdwLdgReNMbtFpCnwaRHnNAD2u7yOt7eV1EhgWp5tL4pInIi8ntv2kpeIjBWRWBGJTUpKuoDbekDff0JEJ5hzPxzf41gYt3W/hObhQUxYsImMLO2eq5QqmWIlDmPMJmPMw8aYaSJSAwgxxhTVx1TcXaokwYlIBNABWOyy+UmgDdAFqAk8UUDMk40xMcaYmPDw8JLc1nN8/K31OwwwcwxknXEkDF9vL54d1I49R1P5+NfdjsSglKq4ituraqmIhIpITWAdMEVEXivitHigkcvrhkBiCeMbAcw2xpxtUTbGHDCWM8AUrCqxiqNmUxj6NiSugW+fcSyMq1uFc02bOrz5ww6SUpxJYEqpiqm4VVXVjTEngRuBKcaYS4E+RZyzEmgpIk1FxA+rymluCeMbRZ5qKrsUgogIMBTYUMJrOq/tQOj+IPwxGTZ85VgYTw9oy5msbF5ZvNWxGJRSFU9xE4eP/YE9gnON44Wye2E9iFXNtBmYYYzZKCLjRWQwgIh0EZF4YDjwnohszD1fRJpglVjyzhT4mYisB9YDtYEJxXwP5Uuf56FhV5j7MBxxZtrzZuHBjLm8CTNW7WdDQrIjMSilKh4pTpdMERkO/B34xRhzv4g0AyYaY27ydIClISYmxsTGxjodRn7J8fDuVRBaH+753hrzUcZOpmfSa+JSmoUHMeNP3bEKckopBSKyyhgTk3d7cRvHZxpjoowx99uvd1WUpFGuVW8IN06GQxtgkds2fo8LDfDl8b6tWbnnOPPjDjgSg1KqYilu43hDEZktIodF5JCIzBKRhp4OrkpoeS1c9VdY/Qmsm+5ICMNjGhEZEcq/Fm4mLSPbkRiUUhVHcds4pmA1bNfHGosxz96mSkPPp+CSK2H+X+DwljK/vbeX8NygSBKT0+n6z+9pOm4BV7z0I3PWJJR5LEqp8q+4iSPcGDPFGJNlPz4GysngiErA2wdu+gD8gmDG7ZBR9su8HkhOx1sgJT0LAyScSOPJr9Zr8lBK5VPcxHFEREaLiLf9GA0c9WRgVU5ohJU8jmyD+Y9CGc8jNXHxVrLz3DItM5uJ2lVXKZVHcRPHXVhdcQ8CB7Dmj7rTU0FVWc16Qs8nIW46rJ5aprdOPJFWou1KqaqruL2q9hljBhtjwo0xdYwxQ7EGA6rS1uMxaNYLFj4OB+LK7Lb1w9x3BQ708yY1w9mlb5VS5cvFrAD4aKlFoc7x8oYb34dqNWHmHZB+skxu+3jf1gT6ep+3zcdLSM3IZtB/fmZTYtnEoZQq/y4mcehIMU8JDodhH8HxvTD3oTJp7xjauQH/urEDDcICEaBBWCCvDO/I5/d0IyU9i6Fv/cJHP+/WNTyUUsUbOe72RJF9xpjGpRyPR5TbkeNF+XkSfP8c9J8I3cY6Fsax0xn87ct1fL/5ML1ahzNxeEdqB7udzV4pVYlc0MhxEUkRkZNuHilYYzqUJ13+MLTqB4ufgoRVjoVRM8iP92+P4YXB7fhl51H6v7Gc5dvLyRonSqkyV2jiMMaEGGNC3TxCjDE+ZRVkleXlBUPfgZB6MGMMpB13LBQR4Y7Lm/D1/11BWKAvt334B/9auFkXglKqCrqYNg5VFqrVtBZ/SjkAcx4o8/EdebWNCGXug1dya7fGvLdsF8Pe/ZU9R8p+wKJSyjmaOCqChjFw3QTYuhB++6/T0RDo582LN3Tg3dHR7D2ayoA3lzNrVbw2nCtVRWjiqCi6/QnaDobvnoN9vzsdDQD92kew6JGraNegOn+duY4/f7GWlPTMok9USlVomjgqChEY8l8IawQz74TTR5yOCLAGDk679zL+em0r5scd4Po3l7Nmn3NtMUopz9PEUZEEVIfhn0DqUfhqLOSUj4Zpby/hoWtaMuNPl5GTA8Pf/Y23luwgO0errpSqjDyaOESkn4hsFZEdIjLOzf4eIrJaRLJEZFiefdkistZ+zHXZ3lREVojIdhH5wl7PvOqo3wn6vwQ7f4CfX3U6mvNceklNFj5yFf3a12Pi4q2M/mAFB5PTnQ5LKVXKPJY4RMQbeAvoD0QCo0QkMs9h+4AxwOduLpFmjOlkPwa7bH8ZeN0Y0xI4Dtxd6sGXd5feCR2Gw5J/wu5lTkdznuqBvvxnVGf+fVMUa/efoP8by/hu0yGnw1JKlSJPlji6AjvsZWYzgOnAENcDjDF7jDFxQLHqXMRaELs38KW96RNgaOmFXEGIwMBJUKsFfHk3pJSvD2YRYUSXRsx/+ErqhwVy79RYnv16A+mZurqgUpWBJxNHA2C/y+t4e1txBYhIrIj8LiK5yaEWcMIYkztda4HXFJGx9vmxSUmVcJSzf7DV3nEmBWbdDTnl70O5eXgwXz1wOXdf2ZSpv+1lyH9/YduhFKfDUkpdJE8mDneTIJaktbSxPUfKLcAkEWlekmsaYyYbY2KMMTHh4ZV0scK6kTDwNdizHJb+y+lo3PL38ebvAyP5+M4uHD19hkH/+ZlPf9+rYz6UqsA8mTjigUYurxsCicU92RiTaP/cBSwFOgNHgDARyZ3upETXrJQ63QKdR8OyibD9e6ejKVDP1nVY9EgPujWrxTNzNvCn/63iRGqG02EppS6AJxPHSqCl3QvKDxgJzC3iHABEpIaI+NvPawNXAJuM9TV1CdYKhAB3AF+XeuQVTf+JUKcdfHUvJMc7HU2BwkP8+XhMF54Z0JYlWw/T/43l/L5LVyBWqqLxWOKw2yEeBBYDm4EZxpiNIjJeRAYDiEgXEYkHhgPvichG+/S2QKyIrMNKFC8ZYzbZ+54AHhWRHVhtHh966j1UGH7VYMQnkJ0BX94F2eV39LaXl3DPVc346v4rCPD1ZtT7v/Pqt1vJyi4fY1KUUkW74PU4KpIKux5HSW2YZSWOyx+G6/7hdDRFOn0mi+fnbmTmqniiG4fxxsjONKpZzemwlFK2C1qPQ1Uw7W+CmLvh1zdhy0KnoylSkL8PE4d35M1Rndl+6BTXv7GceeuqdpOVUhWBJo7Kpu8/IaIjzLnPWnq2AhjcsT4LH7mKFnWDeWjaGh6fuY7TZ7KKPlEp5QhNHJWNb4A1vsMAM8dA1hmnIyqWRjWrMeNP3XmwVwu+XB3PoP/8zIaEZKfDUkq5oYmjMqrZFIa+BYmr4du/Ox1Nsfl6e/FY39Z8fs9lpGZkc8Pbv/DB8l3k6GSJSpUrmjgqq7aD4LL/gz/eg42znY6mRLo3r8WiR66iV+s6TFiwmTEfryQppWKUnJSqCjRxVGZ9noeGXeDrh+DoTqejKZEaQX68d9ul/GNoe1bsOkr/N5bx07ZKOHWMUhWQJo7KzMcPhk0Bbx+YcQdkpjkdUYmICLdddglzH7ySWkH+3PHRH0yYv4kzWeVvXi6lqhJNHJVdWCO4YTIcWg+LnnA6mgvSul4IXz94Bbd3v4QPft7NjW//ys6kU06HpVSVpYmjKmh1HVz5KKz+BNZNdzqaCxLg6834Ie2ZfNulJJxIY+CbPzMjdr9OlqiUAzRxVBW9noZLroD5f4HDW5yO5oJd164e3zzSg06Nwvjbl3E8NG0NyWnld4oVpSojTRxVhbcP3PQh+AXBzDsg47TTEV2wetUD+PSebjzetzWLNhzk+jeWs2rvMafDUqrK0MRRlYRGwE0fQNJWmP8oVOBqHm8v4f96tWDmfd3x8oIR7/3Of37YTraO+VDK4zRxVDXNekLPcRA3Hdb8z+loLlp04xosePgqBnSI4NXvtnHL+79zILli9R5TqqLRxFEV9XjcSiALH4eD652O5qKFBvjyxshOvDK8I+sTkuk3aTnfbDjodFhKVVqaOKoiL2+48QMICLPGd6SfdDqiiyYiDLu0IQsevorGNatx36ereHr2etIydMyHUqVNE0dVFRwOwz6C43tg7kMVur3DVdPaQcy6/3L+1KMZn63Yx+D//syWgxU/MSpVnng0cYhIPxHZKiI7RGScm/09RGS1iGSJyDCX7Z1E5DcR2SgicSJys8u+j0Vkt4istR+dPPkeKrUmV8A1f4dNc2DlB05HU2r8fLx48vq2TL2rK8dTMxn831+Y+tseHfOhVCnxWOIQEW/gLaA/EAmMEpHIPIftA8YAn+fZngrcboxpB/QDJolImMv+x40xnezHWo+8gari8kegZV/45klIWOV0NKWqR6twvvnzVVzRvBbPfr2Re6eu4tjpDKfDUqrC82SJoyuwwxizyxiTAUwHhrgeYIzZY4yJA3LybN9mjNluP08EDgPhHoy16vLyghvetdYt/3wkpB0/t2/3Mvh5knOxlYLawf58NKYLzw6MZNm2JPq/sYxfdxxxOiylKjRPJo4GwH6X1/H2thIRka6AH+A6veuLdhXW6yLiX8B5Y0UkVkRik5J0VtVCVasJvf8Opw/D5zdb7R27l1kLQTWIdjq6iyYi3HVlU7564HKC/H249cMV/PubLWRm5xR9slIqHx8PXlvcbCtRJbOIRAD/A+4wxuT+L38SOIiVTCYDTwDj893ImMn2fmJiYrRyuyhd77UGBq58H969CpL3wYj/QdMeTkdWato3qM78h65k/LxNvL10J7/uPMqgqAg++mUPiSfSqB8WyON9WzO0c4m/3yhVpXgyccQDjVxeNwQSi3uyiIQCC4BnjDG/5243xhywn54RkSnAY6UQqwK4fqLVzpG42nr9zZPQ8WboMMIadV4JVPPz4aWboriqZTiPzljD2v0nzu5LOJHGk19Z41o0eShVME9WVa0EWopIUxHxA0YCc4tzon38bGCqMWZmnn0R9k8BhgIbSjXqqmzPcjixF7o/ZM1plZMN3z0Lr0fC1KGw7osKPceVqwFREYRV88u3PS0zm4mLtzoQkVIVh8cShzEmC3gQWAxsBmYYYzaKyHgRGQwgIl1EJB4YDrwnIhvt00cAPYAxbrrdfiYi64H1QG1ggqfeQ5WS26Yx/GPoOwFGTYfUJLjhPWuk+bFdMHssTGwJs++DnUusxFKBHT7pfjnahBNpTPtjH8e1B5ZSbklV6NseExNjYmNjnQ6jfPt5ktUQ7tqmsXsZJKyGK/9sNZjv+x3WTYONc+BMMoTUh6jhEDUS6ubtaV3+XfHSjyScyD+vlY+XkJVj8PESrmxZm0FR9bm2XV1CA3wdiFIp54jIKmNMTL7tmjhUiWWmw7ZF1qJQO76HnCyoFwUdR0KH4RBcx+kIi2XOmgSe/Go9aZnnSk6Bvt7884b2tKwbwvy4A8xbl0jCiTT8fLzo1TqcQR3r07tNHar5ebJ5UKnyQROHJg7POJUEG2ZZs+0mrgHxhua9rSTSZgD4BjodYaHmrElg4uKtBfaqMsawZv8J5q1LZEHcAQ6nnCHQ15s+kXUZFBXB1a3D8ffxdvAdKOU5mjg0cXhe0larFBI3A07Gg18ItBtiVWVdcoU12LACy84xrNxzjHnrElm4/gDHUzMJCfChb7t6DIyK4IoWtfH1rtjvUSlXmjg0cZSdnBzY+7OVRDZ9DRmnoHojiBphJZHwVk5HeNEys3P4dedR5q1LZPGGg6ScyaJGNV/6d4hgUFR9ujatibeXu6FMSlUcmjg0cTgjIxW2LLCqsnb+CCYH6kdDx1HQ/iYIquV0hBftTFY2y7YdYd66RL7bdIi0zGzqhPhzfYcIBnWsT3TjMKze40pVLJo4NHE4L+UgrP/SKokcWg9ePtDyOoi6GVr1A98ApyO8aKkZWfy45TDz1iWyZGsSGVk5NAgLZGBHqyTSrn6oJhFVYWji0MRRvhzcYJVC4mbCqYMQUB3a3WCVRBp1g0rw4ZqSnsl3mw4xb10iy7cfISvH0Kx2EAOjrJJIy7ohToeoVKE0cWjiKJ9ysmHXUoj7AjbPg8xUqNHEagvpeDPUbOZ0hKXi+OkMvtl4kPlxify28yg5BtrUC2FQx/oMjIrgklpBToeoVD6aODRxlH9nUmDzfGuQ4e5lgLFKH1E3W6WRajWdjrBUHE5JZ9H6g8xbl0jsXmsa+6iG1RkUVZ8BURHUDyvfXZhV1aGJQxNHxZKcAOtnWO0hSVvA2w9a9bWqslpcCz7555mqiBJOpLEgLpH5cQeIi08GoEuTGgzqWJ/+7SMID3G7aoBSZUIThyaOiskYOLDOqspaPxNOJ0FgTatHVseR0ODSStEeArDnyGnmxyUyb90Bth5KwUuge/NaDIqqT7/29dxOyqiUJ2ni0MRR8WVnWpMrrpsGWxdCVjrUamG1h0SNgBqXOB1hqdl2KIX56xKZuy6RPUdT8fESerQKZ2BUBNdG1iVE581SZUAThyaOyiU92RpcuO4La7AhWKPTO46EyCFWL61KwBjDxsSTzFtnVWflzpvVu3Wds/NmBfrplCfKMzRxaOKovI7vPdcecnQH+ARA6+utJNK8N3hXjm/nOTmGNfuPM2/dARasP0BSyhmq+XlzbWRdBkbVp0er2jpvlipVmjg0cVR+xlgrGK6bDhu+hLTjEBQO7YdZSSSiY6VpD8nOMazYfZR56w7wzYZz82b1a1ePQR3rc3nzWvjovFnqImni0MRRtWRlwI7vrCSy7RvIzoDwNvbU7yOgeoOi1yCpIDKzc/hlxxHmrTvAtxutebNqBvnRv72VRLo2qYmXzpulLoAmDk0cVVfqMdg0x0oi+1cAYiWL+p1h9VQY8Yn12nUVRNdkUoGkZ2bz07Yk5q1L5IfNh0nLzKZuqD8DOtRnUMcIOjUK4+u1iYVOJa9ULkcSh4j0A94AvIEPjDEv5dnfA5gERAEjjTFfuuy7A3jGfjnBGPOJvf1S4GMgEFgIPGKKeBOaONRZR3da077HTYfje8DbHifR5EorqfR8ElpcA0F1ILBGhZ4KPjUjix82W/NmLd2aREZ2DjWq+ZKSnkVWzrn/MoG+3vzrxg6aPFQ+ZZ44RMQb2AZcC8QDK4FRxphNLsc0AUKBx4C5uYlDRGoCsUAMYIBVwKXGmOMi8gfwCPA7VuJ40xizqLBYNHGofIyxEsW66bD2c8h2s/64eEO1WtaKhkG1rfaSvI9gl+fleNGqk+mZfLvxEE/PXs+ZrJx8+6sH+vD2rZfSul4ItYN10KGyFJQ4PLn+ZVdghzFmlx3AdGAIcDZxGGP22Pvy/iX3Bb4zxhyz938H9BORpUCoMeY3e/tUYChQaOJQKh8RaHyZ1faxeS50vBfWfAo9HoOQCDh9xBpsePrwuefHdlvPM0+7v6ZfcJ7EUttOOvbzoDrn9pVxaSY0wJdhlzbk8Znr3O5PTsvi1g9WAFAryI9WdUNoXe/co1XdEIL9dblcZfHkX0IDYL/L63ig20Wc28B+xLvZno+IjAXGAjRu3LiYt1VVSt42jVZ9z73uMKzg8zJOuyQWl8cpl+fHd0P8H5B61FqDJC/xdinFuCYVe1veUk4plWbqhwWScCIt3/Z61QN4dXhHth5MsR6HUpgRu5/UjHPrsTesEUjrPAmlWe1g/HwqbnWeujCeTBzuunEUt16soHOLfU1jzGRgMlhVVcW8r6pKElaf3xDetIf1OmF14Y3jfkHWozgj1XOyrW7Bpw67JJkjdknGfn7qcDFKMyEFJ5Xzqs7qQEBYgaWZ95r9zMT11fgps+3ZbVf7bubx5qm0b3ENV7SofS70HEPCibSziSQ3qfy0LelsG4mPl9C0dpCVSFySSqMa1bQnVyXmycQRDzRyed0QSCzBuT3znLvU3t7wAq+p1Pncdblt2qN0e1R55ZYsahd9LNilmaRzJZpTh89/ffowHNtltc8UqzRzftVZ+7AsPvB/ndf9R/P+qcvpF7KHV+S/+HeZmj90L6FRzWo0qlmNPpF1z4WYlcPuI6ftZHKSrQdPsS7+BPPjDpw9JtDXm1Z1g89Wc+UmlPBgf13IqhLwZOO4D1bj+DVAAlbj+C3GmI1ujv0YmJ+ncXwVEG0fshqrcfyYiKwEHgJWYDWO/8cYs7CwWLRxXFVKOdlWV+O8VWbuqs5OJ1lrnbjyCQAM9H4WLrvfSnIX4fSZLLYfPnU2mWw9ZP08cupcx4Ma1XxdSiehtK4XTKu6ITr3VjnlVHfc67G623oDHxljXhSR8UCsMWauiHQBZgM1gHTgoDGmnX3uXcBT9qVeNMZMsbfHcK477iLgIe2Oq1QxuJZmfnnD6hTg5Qs5mRBc11rzpP1N0LBLqY6wP3rqDFsPpbDNpcpr26FTnDqTdfaYBmGBdgnFSiat64bSvE6QTqHiMB0AqIlDKUtup4CYu2HlB9D1Xji8CbZ9a3VLrt4Y2t8A7W702DQtxrhvP9mZdIrMbOszyTu3/aTu+dVdjWtWw1vbT8qEJg5NHErl70nm+jqikzVd/YZZsPNHyMmCms2tUkj7m6BOG4+Hl5mdw56z7SfnenjtO5ZK7kdVgK8XLeuE5GuQrxNScPvJnDUJOlr+Amji0MShVPHn50o9ZlVlbZgFu5cDBuq0g/Y3Wo8yXgs+NSOL7YdOuVR1pbDlYApJKefaT8Kq+Volk7rnjz9ZsuUwT361nrTMc12LdbR88Wji0MSh1IVJOWitfbJhlj3XF1A/2iqFtLvBmjDSIcdOZ7DtUMp5VV7bDqaQ4tJ+4iWQ4+Zjrl5oAL+O663dhguhiUMTh1IX78Q+2DjbSiIH7FHojS+3SiGRQ60pWBxmjCExOZ1tB61SycvfbCnwWF9voU5IABHVA6hXPfdn4NnX9UIDqBPiX2WnqNfEoYlDqdJ1dCds+Mpa+yRpC4gXNL3aKom0HWhNq1IOXPHSj25Hy1cP9OXWbo05mJzOgeR0Dp5M50ByGumZ54+N8RIID/G3Ekqoa4IJIMJOMnVC/StlDzBNHJo4lPKcQ5usUsiGWdZ0K16+0KKPlURa9wP/EMdCm7MmodhtHMYYktMyrUTiklAOJqed3XYwOf28qrBctYL88iWVeqHnXterHkA1v4o135cmDk0cSnmeMZC4xkogG2fDyQRroGGrvlYSaXmdI7MIl3avqpT0TA6dtBLLeUkmOY2DJ89wMDmN46mZ+c6rHuhLvXyllvOrx0L8fcrN6HpNHJo4lCpbOTlWY/qGWdZCWqeTrBmE2wywkkizXuDj53SUHpOeme1SaknLk2Csn66j6nMF+XmfLbHUDc2bYKztNar5FppcSitRauLQxKGUc7KzYM9yK4lsngvpydZkjJGDrSTS5KqLnvKkIsrIyuFwSv6E4ppoDp1Mz9crzM/Hy0okoedKLPVCrXaYbYdO8vaSnaS7rLtyod2PNXFo4lCqfMjKsAYYbphlDTjMOGVNK99uqD3lSdcKvfJiacvKzuHIqQwOJKflaXexE81Ja3vuiPuCNAgL5JdxvUt0bycWclJKqfx8/KwG89b9ICMVtn9rJZHVU+GPyRDa0JrypP1N1mj2clLf7xQfb6+zjesFyckxHEvN4GByOgP/87PbYxLd9Cy74JhK7UpKKVVSftWskka7oXAmBbYuspLI7+/Cr/+xRqifnfKkbdHXq6K8vITawf7UDvanQQGLddUPK71OCVoeVEqVD/4hEDUCbvkCHtsGg/8DYY1h+avw9mXwdndYNtEaP6IK9Hjf1gT6nt9eFOjrzeN9W5faPbSNQylVvp06fG7Kk32/WdsiOp2b8iSsUeHnV0Haq6oUaOJQqpJIjj835UniGmtbo8vsJDLUWjpXlRpNHJo4lKpcju6EjV9Z054c3mRNedLkKnvKk0FQraZ1XHFnBFb5FJQ4PNrGISL9RGSriOwQkXFu9vuLyBf2/hUi0sTefquIrHV55IhIJ3vfUvuaufv0K4ZSVVGt5tDjcXjgN7j/N7jqr5C8H+Y9DK+0hM9GwLovrHVEZo6xkgWcW4OkQXRhV1eF8OSa495Ya45fC8RjrTk+yhizyeWYB4AoY8x9IjISuMEYc3Oe63QAvjbGNLNfLwUeM8YUuwihJQ6lqghj4MBae96s2XAy3prypH40HIyDNgNh2yK45jlo1A28/cDb1/6Z57mXd8XsClyKJSwnxnF0BXYYY3bZAUwHhgCbXI4ZAjxvP/8S+K+ISJ41xEcB0zwYp1KqshCB+p2tR5/xEL/y3LxZGacgbrp13IJHi3Mx9wnl7HP7p49/4fsv6Llfya7nmuAaRBe8ymMp8WTiaADsd3kdD3Qr6Bhjpx9ZJQAABn1JREFUTJaIJAO1gCMux9yMlWBcTRGRbGAWMMG4KTaJyFhgLEDjxo0v4m0opSokLy9o3M16tL4eZt4OrfvDloVwxSNQuxVkZ0B2pv3T9bm7be6en7F+ZqZZ06gUdV5O/ll1S+e95kkuCEwdAgE1wGTDzf87vwRykTyZONyV8fJ+wBd6jIh0A1KNMRtc9t9qjEkQkRCsxHEbMDXfRYyZDEwGq6qqhLErpSqL3ctg1l1w86f5v4GX4odpseTkQE4BySnrTAmTVhHPE1fD4c3Q7YFSf5+eTBzxgGsH64ZAYgHHxIuID1AdOOayfyR5qqmMMQn2zxQR+RyrSixf4lBKKcCq23dNEk17WK8TVpd94vDyAi9/q3rLk3Yvg23fQI+/QeyH0KZ/hSlxrIT/b+/eQrWowjCO/5/UyhQRMkSy0ki6KDqICCVJVESRRFDRmYggiA6GUFE3UXTTTYQUQR6iyAqxhIiw85FOZNnB7CLCyFLUiygjrOzpYtaWre1dTc58g9/3/ODjm7327OF9LzbvrDVr1mKWpJnA91RF4PK9znkOuBp4D7gIeG1o2EnSAcDFwO5sS3GZbHu7pHHAAuCVFnOIiP3dSA+EZ87vfdHolb17VDNPa7yH1dp0XNt/ADcCLwIbgJW210u6R9L55bRlwKGSvgYWAcOn7M4HNg09XC8OAl6U9BmwjqogLWkrh4iI/c4/9bAakhcAIyJiRJ28ABgREf0nhSMiImpJ4YiIiFpSOCIiopYUjoiIqGUgZlVJ2gZ8+z//fAp7LoEyCJLzYEjO/W9f8z3K9mF7Nw5E4dgXkj4aaTpaP0vOgyE597+28s1QVURE1JLCERERtaRw/LtHug6gA8l5MCTn/tdKvnnGERERtaTHERERtaRwRERELSkco5C0XNJWSV/8+9n7P0lHSHpd0gZJ6yUt7Dqmtkk6WNKHkj4tOd/ddUy9ImmMpE8kPd91LL0gaaOkzyWtkzQQS2VLmixplaSvyv/1KY1dO884RiZpPrADeNz28V3H0zZJ04Bptj8u2/KuBS6w/WXHobVGkoAJtneUjcHeARbafr/j0FonaREwB5hke0HX8bRN0kZgju2BeflP0mPA27aXSjoQOMT2j01cOz2OUdh+iz23se1rtjfb/rgc/0y1+dbh3UbVLld2lB/HlU/f30lJmg6cByztOpZoh6RJVJvhLQOw/VtTRQNSOGIEkmYAJwMfdBtJ+8qQzTpgK/Cy7b7PGXgAuA34s+tAesjAS5LWSrqu62B64GhgG/BoGZJcKmlCUxdP4Yg9SJoIPAPcYvunruNpm+1dtk8CpgNzJfX1sKSkBcBW22u7jqXH5tmeDZwL3FCGovvZWGA28LDtk4Ff2HNr7n2SwhG7lXH+Z4AVtp/tOp5eKt34N4BzOg6lbfOA88uY/9PAGZKe6Dak9tn+oXxvBVYDc7uNqHWbgE3DetCrqApJI1I4Atj9oHgZsMH2/V3H0wuSDpM0uRyPB84Cvuo2qnbZvsP2dNszgEuB12xf2XFYrZI0oUz4oAzXnA309WxJ21uA7yQdW5rOBBqb6DK2qQv1G0lPAacDUyRtAu6yvazbqFo1D7gK+LyM+QPcafuFDmNq2zTgMUljqG6iVtoeiOmpA2YqsLq6N2Is8KTtNd2G1BM3ASvKjKpvgGuaunCm40ZERC0ZqoqIiFpSOCIiopYUjoiIqCWFIyIiaknhiIiIWlI4IhogaVdZeXXo09hbupJmDMoqzbF/yHscEc34tSxdEtH30uOIaFHZB+K+su/Hh5KOKe1HSXpV0mfl+8jSPlXS6rJHyKeSTi2XGiNpSdk35KXypntEJ1I4Ipoxfq+hqkuG/e4n23OBB6lWpqUcP277BGAFsLi0LwbetH0i1dpC60v7LOAh28cBPwIXtpxPxKjy5nhEAyTtsD1xhPaNwBm2vymLSG6xfaik7VQbZ/1e2jfbniJpGzDd9s5h15hBteT7rPLz7cA42/e2n1nE36XHEdE+j3I82jkj2TnseBd5PhkdSuGIaN8lw77fK8fvUq1OC3AF1ba1AK8C18PuTaYm9SrIiP8qdy0RzRg/bFVhgDW2h6bkHiTpA6obtctK283Ackm3Uu3UNrRy6ULgEUnXUvUsrgc2tx59RA15xhHRovKMY47t7V3HEtGUDFVFREQt6XFEREQt6XFEREQtKRwREVFLCkdERNSSwhEREbWkcERERC1/AZH7WlT6nJemAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['loss'], 'o-')\n",
    "ax.plot([None] + hist.history['val_loss'], 'x-')\n",
    "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
    "ax.set_title('Training/Validation Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 41s 678us/step - loss: 0.2824 - acc: 0.9543 - val_loss: 0.1561 - val_acc: 0.9820\n",
      "Epoch 2/20\n",
      " 1800/60000 [..............................] - ETA: 35s - loss: 0.1753 - acc: 0.9761"
     ]
    }
   ],
   "source": [
    "    model = Sequential()\n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(6, kernel_size=(4,4), strides=(1, 1), activation='tanh', input_shape=(28,28,1), padding=\"same\"))\n",
    "\n",
    "    # First pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=(1,1), strides=(1, 1), padding='valid'))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(16, kernel_size=(4,4), strides=(1, 1), activation='relu', padding='valid'))\n",
    "    \n",
    "    # Second pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=(1,1), strides=(2, 2), padding='valid'))\n",
    "    \n",
    "    # Connected convolutional layer\n",
    "    model.add(layers.Conv2D(120, kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001), kernel_size=(4,4), strides=(1, 1), activation='relu', padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    # Connected layer\n",
    "    model.add(layers.Dense(84, kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001), activation='tanh'))\n",
    "    model.add(Dropout(0.25)) \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # build/compile\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    \n",
    "hist = model.fit(x=x_train,y=y_train, epochs=20, batch_size=120, validation_data=(x_test, y_test), verbose=1)\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "# After all tuning, 98.65% acc\n",
    "# Freehand tuning 1, val_acc 99.08%, val_loss 0.0937, slightly overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'acc')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['acc'], 'o-')\n",
    "ax.plot([None] + hist.history['val_acc'], 'x-')\n",
    "ax.legend(['Train acc', 'Validation acc'], loc = 0)\n",
    "ax.set_title('Training/Validation acc per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['loss'], 'o-')\n",
    "ax.plot([None] + hist.history['val_loss'], 'x-')\n",
    "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
    "ax.set_title('Training/Validation Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
