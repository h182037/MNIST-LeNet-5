{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setting up Google Compute Engine\n",
    "\t\n",
    "\tFirstly a google compute engine instance was created, I used putty to generate private and public keys for the ssh protocol, but later I realized that Google had an easier way of connecting to the instance by autogenerating. There was no info telling us whether to use codelabs or jupyter notebooks, so I chose the latter. Installation of all the tools in GCE was a hassle, I tried to only install the neccessary tools, like python, jupyter, keras, tensorflow, plotting tools, etc,  but it seems 10 gigabytes is simply not enough. I am still looking to set up the instance in a more lightweight manner. Also, to launch the browserbased notebook, some firewall changes needed to be done, and a static external IP adress need to be reserved, so this might not be the optimal solution. \n",
    "\t\n",
    "\tTo summarize, I got parts of my notebook to work, and some parts are missing the neccessary tools. Also I noticed that the time it took to do the computations in GCE did not differ much from the time it took to run them locally on my machine. So unless we can use Tensor Proccessing Units in GCE the reward is not very big. \n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \t2. MNIST Classification using LeNet-5 architecture\n",
    "\t\n",
    "\tLink to my github repository: https://github.com/h182037/MNIST-LeNet-5\n",
    "    \n",
    "    Below are the tools used for this assignment, aswell as the simple data preproccessing and a quick check on how the data looks.\n",
    "    \n",
    "    The dataset is imported from keras, 60'000 training data, and 10'000 validation data, then its normalized, encoded, and reshaped before its ready to be trained on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.utils as np_utils\n",
    "from keras.models import Sequential\n",
    "from keras import models, layers\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras import regularizers\n",
    "import keras\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# resources:\n",
    "# https://engmrk.com/lenet-5-a-classic-cnn-architecture/\n",
    "# https://keras.io/\n",
    "# https://github.com/ryanleeallred/MNIST-convnet-gridsearch/blob/master/param_tuning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19d581fb9e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADmtJREFUeJzt3W+sVPWdx/HPFwT/UFQIV3ulKF00ZgmJYEbYhI2iRLSbKvCgBmIQTQM+ANkmEBfhATxwE6PbdlVMk4slQFJpGyorJGYtGo1L3BgGJQiLbNVc6V0QLqFYqw9Q+O6De2hu8c5vhpkzc+byfb8ScmfO9/zmfDPczz0z85uZn7m7AMQzpOgGABSD8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCOqSVh5szJgxPn78+FYeEgilu7tbJ06csFr2bSj8ZnavpGclDZX0ors/ldp//PjxKpfLjRwSQEKpVKp537of9pvZUEkvSPqBpImS5pvZxHpvD0BrNfKcf6qkj9z9E3c/LenXkmbn0xaAZmsk/GMl/bHf9Z5s298ws8VmVjazcm9vbwOHA5CnRsI/0IsK3/p8sLt3uXvJ3UsdHR0NHA5AnhoJf4+kcf2uf0/SkcbaAdAqjYR/t6SbzOz7ZjZc0jxJ2/NpC0Cz1T3V5+7fmNlSSa+pb6pvg7sfyK0zAE3V0Dy/u78q6dWcegHQQry9FwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAaWqXXzLolfSHpjKRv3L2UR1PIz5kzZ5L1zz//vKnHX7duXcXaV199lRx76NChZP2FF15I1lesWFGxtmXLluTYyy67LFlfuXJlsr5mzZpkvR00FP7Mne5+IofbAdBCPOwHgmo0/C7p92a2x8wW59EQgNZo9GH/dHc/YmbXSNppZh+6+9v9d8j+KCyWpOuvv77BwwHIS0Nnfnc/kv08LmmbpKkD7NPl7iV3L3V0dDRyOAA5qjv8ZjbCzEaeuyxplqT9eTUGoLkaedh/raRtZnbudl5y9//MpSsATVd3+N39E0m35NjLRevw4cPJ+unTp5P1d955J1nftWtXxdqpU6eSY7du3ZqsF2ncuHHJ+mOPPZasb9u2rWJt5MiRybG33JL+1b7jjjuS9cGAqT4gKMIPBEX4gaAIPxAU4QeCIvxAUHl8qi+8999/P1m/6667kvVmf6y2XQ0dOjRZf/LJJ5P1ESNGJOsPPvhgxdp1112XHDtq1Khk/eabb07WBwPO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFPP8ObjhhhuS9TFjxiTr7TzPP23atGS92nz4m2++WbE2fPjw5NgFCxYk62gMZ34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIp5/hyMHj06WX/mmWeS9R07diTrU6ZMSdaXLVuWrKdMnjw5WX/99deT9Wqfqd+/v/I6Ls8991xyLJqLMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBFV1nt/MNkj6oaTj7j4p2zZa0m8kjZfULekBd/9T89oc3ObMmZOsV/te/2rLSe/bt69i7cUXX0yOXbFiRbJebR6/mkmTJlWsdXV1NXTbaEwtZ/6Nku49b9tKSW+4+02S3siuAxhEqobf3d+WdPK8zbMlbcoub5KUPrUBaDv1Pue/1t2PSlL285r8WgLQCk1/wc/MFptZ2czKvb29zT4cgBrVG/5jZtYpSdnP45V2dPcudy+5e6mjo6POwwHIW73h3y5pYXZ5oaRX8mkHQKtUDb+ZbZH035JuNrMeM/uxpKck3W1mf5B0d3YdwCBSdZ7f3edXKM3MuZewrrzyyobGX3XVVXWPrfY+gHnz5iXrQ4bwPrHBiv85ICjCDwRF+IGgCD8QFOEHgiL8QFB8dfdFYO3atRVre/bsSY596623kvVqX909a9asZB3tizM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFPP9FIPX12uvXr0+OvfXWW5P1RYsWJet33nlnsl4qlSrWlixZkhxrZsk6GsOZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYp7/IjdhwoRkfePGjcn6I488kqxv3ry57vqXX36ZHPvQQw8l652dnck60jjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQVef5zWyDpB9KOu7uk7JtayUtktSb7bbK3V9tVpNonrlz5ybrN954Y7K+fPnyZD31vf9PPPFEcuynn36arK9evTpZHzt2bLIeXS1n/o2S7h1g+8/dfXL2j+ADg0zV8Lv725JOtqAXAC3UyHP+pWa2z8w2mNmo3DoC0BL1hv8XkiZImizpqKSfVtrRzBabWdnMyr29vZV2A9BidYXf3Y+5+xl3PytpvaSpiX273L3k7qWOjo56+wSQs7rCb2b9P041V9L+fNoB0Cq1TPVtkTRD0hgz65G0RtIMM5ssySV1S3q0iT0CaAJz95YdrFQqeblcbtnx0HynTp1K1nfs2FGx9vDDDyfHVvvdnDlzZrK+c+fOZP1iVCqVVC6Xa1rwgHf4AUERfiAowg8ERfiBoAg/EBThB4Jiqg+FufTSS5P1r7/+OlkfNmxYsv7aa69VrM2YMSM5drBiqg9AVYQfCIrwA0ERfiAowg8ERfiBoAg/EBRLdCNp3759yfrWrVuT9d27d1esVZvHr2bixInJ+u23397Q7V/sOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDM81/kDh06lKw///zzyfrLL7+crH/22WcX3FOtLrkk/evZ2dmZrA8ZwrkthXsHCIrwA0ERfiAowg8ERfiBoAg/EBThB4KqOs9vZuMkbZb0XUlnJXW5+7NmNlrSbySNl9Qt6QF3/1PzWo2r2lz6Sy+9VLG2bt265Nju7u56WsrFbbfdlqyvXr06Wb///vvzbCecWs7830ha7u5/L+kfJC0xs4mSVkp6w91vkvRGdh3AIFE1/O5+1N3fyy5/IemgpLGSZkvalO22SdKcZjUJIH8X9JzfzMZLmiLpXUnXuvtRqe8PhKRr8m4OQPPUHH4z+46k30n6ibv/+QLGLTazspmVe3t76+kRQBPUFH4zG6a+4P/K3c990uOYmXVm9U5Jxwca6+5d7l5y91JHR0cePQPIQdXwm5lJ+qWkg+7+s36l7ZIWZpcXSnol//YANEstH+mdLmmBpA/MbG+2bZWkpyT91sx+LOmwpB81p8XB79ixY8n6gQMHkvWlS5cm6x9++OEF95SXadOmJeuPP/54xdrs2bOTY/lIbnNVDb+775JUab3vmfm2A6BV+NMKBEX4gaAIPxAU4QeCIvxAUIQfCIqv7q7RyZMnK9YeffTR5Ni9e/cm6x9//HFdPeVh+vTpyfry5cuT9XvuuSdZv/zyyy+4J7QGZ34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCCrMPP+7776brD/99NPJ+u7duyvWenp66uopL1dccUXF2rJly5Jjq3099ogRI+rqCe2PMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBBVmnn/btm0N1RsxceLEZP2+++5L1ocOHZqsr1ixomLt6quvTo5FXJz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoc/f0DmbjJG2W9F1JZyV1ufuzZrZW0iJJvdmuq9z91dRtlUolL5fLDTcNYGClUknlctlq2beWN/l8I2m5u79nZiMl7TGznVnt5+7+b/U2CqA4VcPv7kclHc0uf2FmByWNbXZjAJrrgp7zm9l4SVMknftOrKVmts/MNpjZqApjFptZ2czKvb29A+0CoAA1h9/MviPpd5J+4u5/lvQLSRMkTVbfI4OfDjTO3bvcveTupY6OjhxaBpCHmsJvZsPUF/xfufvLkuTux9z9jLuflbRe0tTmtQkgb1XDb2Ym6ZeSDrr7z/pt7+y321xJ+/NvD0Cz1PJq/3RJCyR9YGbn1ppeJWm+mU2W5JK6JaXXqQbQVmp5tX+XpIHmDZNz+gDaG+/wA4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBFX1q7tzPZhZr6RP+20aI+lEyxq4MO3aW7v2JdFbvfLs7QZ3r+n78loa/m8d3Kzs7qXCGkho197atS+J3upVVG887AeCIvxAUEWHv6vg46e0a2/t2pdEb/UqpLdCn/MDKE7RZ34ABSkk/GZ2r5kdMrOPzGxlET1UYmbdZvaBme01s0KXFM6WQTtuZvv7bRttZjvN7A/ZzwGXSSuot7Vm9n/ZfbfXzP6poN7GmdmbZnbQzA6Y2T9n2wu97xJ9FXK/tfxhv5kNlfS/ku6W1CNpt6T57v4/LW2kAjPrllRy98LnhM3sdkl/kbTZ3Sdl256WdNLdn8r+cI5y939pk97WSvpL0Ss3ZwvKdPZfWVrSHEkPq8D7LtHXAyrgfivizD9V0kfu/om7n5b0a0mzC+ij7bn725JOnrd5tqRN2eVN6vvlabkKvbUFdz/q7u9ll7+QdG5l6ULvu0RfhSgi/GMl/bHf9R6115LfLun3ZrbHzBYX3cwArs2WTT+3fPo1BfdzvqorN7fSeStLt819V8+K13krIvwDrf7TTlMO0939Vkk/kLQke3iL2tS0cnOrDLCydFuod8XrvBUR/h5J4/pd/56kIwX0MSB3P5L9PC5pm9pv9eFj5xZJzX4eL7ifv2qnlZsHWllabXDftdOK10WEf7ekm8zs+2Y2XNI8SdsL6ONbzGxE9kKMzGyEpFlqv9WHt0tamF1eKOmVAnv5G+2ycnOllaVV8H3XbiteF/Imn2wq498lDZW0wd3/teVNDMDM/k59Z3upbxHTl4rszcy2SJqhvk99HZO0RtJ/SPqtpOslHZb0I3dv+QtvFXqbob6Hrn9dufncc+wW9/aPkv5L0geSzmabV6nv+XVh912ir/kq4H7jHX5AULzDDwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUP8Pt/ALPExulGgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array(x_train[0], dtype='uint8')\n",
    "pixels = image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# transformation\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# reshape\n",
    "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \tThis is how it looked before hyperparameterizing:\n",
    "\t\n",
    "\tThis project started out with a true copy of the LeNet-5 architecture. \n",
    "\tResource: https://engmrk.com/lenet-5-a-classic-cnn-architecture/\n",
    "\n",
    "\tLayer 1: Convolutional, dimension 6, kernel size (5,5), strides (1,1), activation tanh.\n",
    "\tLayer 2: Pooling,  pooling size (2,2), strides (2,2).\n",
    "\tLayer 3: Convolutional, dimension 16  kernel size (5,5), strides (1,1), activation tanh.\n",
    "\tLayer 4: Pooling, pooling size (2,2), strides (2,2). \n",
    "\tLayer 5: Convolutional, dimension 120, kernel size (5,5), strides (1,1), activation tanh.\n",
    "\tLayer 6: Dense, dimension 84, activation tanh.\n",
    "\tLayer 7: Dense/output, dimension 10, activation softmax.\n",
    "    With optimizer Stochastic Gradient Descent, batch size of 64, default learning rate (Which I believe is 0.01 and no momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creation function, this is used to build a specific model for each of the parameter selection steps.\n",
    "def create_model(optimizer, activation_1, activation_2, activation_3, activation_4, kernel_size, pool_size, dropout_1, dropout_2):\n",
    "    model = Sequential()\n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(6, kernel_size=kernel_size, strides=(1, 1), activation=activation_1, input_shape=(28,28,1), padding=\"same\"))\n",
    "\n",
    "    # First pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(1, 1), padding='valid'))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(16, kernel_size=kernel_size, strides=(1, 1), activation=activation_2, padding='valid'))\n",
    "    \n",
    "    # Second pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(2, 2), padding='valid'))\n",
    "    \n",
    "    # Connected convolutional layer\n",
    "    model.add(layers.Conv2D(120, kernel_size=kernel_size, strides=(1, 1), activation=activation_3, padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dropout(dropout_1)) \n",
    "    # Connected layer\n",
    "    model.add(layers.Dense(84, activation=activation_4))\n",
    "    model.add(Dropout(dropout_2)) \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # build/compile\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step GridSearchCV\n",
    "\tI use GridSearchCV for my hyperparameter tuning, as it makes the tuning more compact codewise. \n",
    "\tTo save some time the amount of epochs is limited to 3 or 4 per tuning step. \n",
    "\t4 epochs might not give the most representational data, but unfortunately tuning takes some time. \n",
    "    Loss is keras categorical crossentropy, and accuracy as metric.\n",
    "    \n",
    "    I ran a gridsearch for the best result over these parameters:\n",
    "\tBatch size\n",
    "\tOptimizer\n",
    "\t4 activations\n",
    "\tUniversal kernel size\n",
    "\tUniversal pool size\n",
    "\t2 dropouts\n",
    "\t2 kernel regularizations\n",
    "\t2 bias regularizations\n",
    "    \n",
    "    I do not have the resources to run gridsearch over all the parameters at the same time, as that would take me weeks of computing, so I am forced to to it step by step. This will not yield a true optimal tuning, but it is a start. So every step will compute a subset of parameters using the original architecture as a basis and change the parameters for the next parameter grid search. \n",
    "\t\n",
    "\tThe number of layers and nodes are not changed from the original architecture, and neither are strides. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.5045 - acc: 0.8432\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.3738 - acc: 0.8863\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 52s 2ms/step - loss: 0.3427 - acc: 0.8964\n",
      "30000/30000 [==============================] - 12s 405us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 0.4868 - acc: 0.8489\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 59s 2ms/step - loss: 0.3705 - acc: 0.8875\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 0.3467 - acc: 0.8921: 1s - loss\n",
      "30000/30000 [==============================] - 12s 405us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 29s 979us/step - loss: 0.4108 - acc: 0.8751\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 27s 909us/step - loss: 0.3092 - acc: 0.9068\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 908us/step - loss: 0.2672 - acc: 0.9187\n",
      "30000/30000 [==============================] - 8s 272us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 858us/step - loss: 0.4187 - acc: 0.8737\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 0.3205 - acc: 0.9025\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 885us/step - loss: 0.2715 - acc: 0.9182\n",
      "30000/30000 [==============================] - 9s 301us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 873us/step - loss: 0.4065 - acc: 0.8780\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.2869 - acc: 0.9141\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 24s 789us/step - loss: 0.2482 - acc: 0.9256\n",
      "30000/30000 [==============================] - 8s 260us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 806us/step - loss: 0.3881 - acc: 0.8834\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 24s 809us/step - loss: 0.2792 - acc: 0.9149\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 23s 773us/step - loss: 0.2512 - acc: 0.9230\n",
      "30000/30000 [==============================] - 8s 254us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 771us/step - loss: 0.3951 - acc: 0.8792\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 776us/step - loss: 0.2690 - acc: 0.9195\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 746us/step - loss: 0.2179 - acc: 0.9346\n",
      "30000/30000 [==============================] - 7s 247us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.3833 - acc: 0.8845\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 22s 748us/step - loss: 0.2793 - acc: 0.9167\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 728us/step - loss: 0.2465 - acc: 0.9255\n",
      "30000/30000 [==============================] - 8s 255us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 799us/step - loss: 0.4084 - acc: 0.8758\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 22s 717us/step - loss: 0.2584 - acc: 0.9224\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 25s 826us/step - loss: 0.2179 - acc: 0.9357\n",
      "30000/30000 [==============================] - 8s 257us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 856us/step - loss: 0.3892 - acc: 0.8824\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 24s 793us/step - loss: 0.2524 - acc: 0.9251\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 717us/step - loss: 0.2195 - acc: 0.9325\n",
      "30000/30000 [==============================] - 8s 257us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 16.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 47s 777us/step - loss: 0.3427 - acc: 0.8976\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 46s 774us/step - loss: 0.2414 - acc: 0.9273\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 45s 745us/step - loss: 0.1901 - acc: 0.9423\n",
      "Best: 0.947733 using {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [5, 5], 'optimizer': 'SGD', 'pool_size': [2, 2]}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0f792a6a5bcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mstds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'std_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test loss {:.4f}, accuracy {:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#batch size grid search over 10, 50, 100, 120, 200\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [10, 50, 100, 120, 200],\n",
    "              'optimizer': ['SGD'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['tanh'],\n",
    "              'activation_3' : ['tanh'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 7 candidates, totalling 14 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.2893 - acc: 0.9112\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 701us/step - loss: 0.0869 - acc: 0.9739\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 744us/step - loss: 0.0605 - acc: 0.9825\n",
      "30000/30000 [==============================] - 7s 234us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 786us/step - loss: 0.2673 - acc: 0.9184\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 717us/step - loss: 0.0703 - acc: 0.9789\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 717us/step - loss: 0.0489 - acc: 0.9852\n",
      "30000/30000 [==============================] - 7s 232us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 814us/step - loss: 0.2732 - acc: 0.9137\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 768us/step - loss: 0.0760 - acc: 0.9762\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 719us/step - loss: 0.0511 - acc: 0.9854\n",
      "30000/30000 [==============================] - 7s 243us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 755us/step - loss: 0.3068 - acc: 0.9066\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 704us/step - loss: 0.0789 - acc: 0.9772\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 705us/step - loss: 0.0556 - acc: 0.9829\n",
      "30000/30000 [==============================] - 8s 280us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 26s 878us/step - loss: 0.2849 - acc: 0.9104\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 700us/step - loss: 0.0803 - acc: 0.9756\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 703us/step - loss: 0.0531 - acc: 0.9842\n",
      "30000/30000 [==============================] - 7s 237us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 758us/step - loss: 0.2668 - acc: 0.9157\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 698us/step - loss: 0.0710 - acc: 0.9777\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 697us/step - loss: 0.0478 - acc: 0.9852\n",
      "30000/30000 [==============================] - 7s 239us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 757us/step - loss: 0.2923 - acc: 0.9081\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 699us/step - loss: 0.0733 - acc: 0.9776\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 728us/step - loss: 0.0516 - acc: 0.9848\n",
      "30000/30000 [==============================] - 8s 277us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 780us/step - loss: 0.2576 - acc: 0.9196\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 702us/step - loss: 0.0782 - acc: 0.9759\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 701us/step - loss: 0.0532 - acc: 0.9834\n",
      "30000/30000 [==============================] - 8s 257us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.2827 - acc: 0.9114\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 705us/step - loss: 0.0822 - acc: 0.9761\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 713us/step - loss: 0.0548 - acc: 0.9834\n",
      "30000/30000 [==============================] - 7s 247us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 25s 837us/step - loss: 0.2750 - acc: 0.9132\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 762us/step - loss: 0.0767 - acc: 0.9770\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 22s 744us/step - loss: 0.0481 - acc: 0.9854\n",
      "30000/30000 [==============================] - 8s 252us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 762us/step - loss: 0.3066 - acc: 0.9053\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 22s 729us/step - loss: 0.0875 - acc: 0.9739\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.0590 - acc: 0.982 - 21s 704us/step - loss: 0.0588 - acc: 0.9829\n",
      "30000/30000 [==============================] - 7s 242us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 0.2487 - acc: 0.9257\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 23s 751us/step - loss: 0.0681 - acc: 0.9794\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 23s 754us/step - loss: 0.0469 - acc: 0.9859\n",
      "30000/30000 [==============================] - 7s 248us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.2964 - acc: 0.9049\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 710us/step - loss: 0.0843 - acc: 0.9739\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 709us/step - loss: 0.0568 - acc: 0.9832\n",
      "30000/30000 [==============================] - 7s 246us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.2925 - acc: 0.9104\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 21s 706us/step - loss: 0.0799 - acc: 0.9760\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 21s 709us/step - loss: 0.0542 - acc: 0.9833\n",
      "30000/30000 [==============================] - 8s 250us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 17.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 48s 793us/step - loss: 0.1751 - acc: 0.9461\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 46s 768us/step - loss: 0.0518 - acc: 0.9844\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 44s 737us/step - loss: 0.0375 - acc: 0.9882\n",
      "Best: 0.986650 using {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n"
     ]
    }
   ],
   "source": [
    "#optimizer grid search over SGD, RMSprop, Adagrad, Adadelta, Adam, Nadam, Adamax\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam', 'Adamax'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['tanh'],\n",
    "              'activation_3' : ['tanh'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE: 64\n",
    "#BEST OPTIMIZER: NADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 81 candidates, totalling 162 fits\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3068 - acc: 0.9061\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 850us/step - loss: 0.0878 - acc: 0.9728\n",
      "30000/30000 [==============================] - 7s 244us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 944us/step - loss: 0.2691 - acc: 0.9176\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 786us/step - loss: 0.0740 - acc: 0.9777\n",
      "30000/30000 [==============================] - 7s 223us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 22s 742us/step - loss: 0.3370 - acc: 0.9051\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 0.0987 - acc: 0.9725\n",
      "30000/30000 [==============================] - 7s 245us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 0.3500 - acc: 0.9018\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 803us/step - loss: 0.0910 - acc: 0.9761\n",
      "30000/30000 [==============================] - 7s 221us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 842us/step - loss: 0.2273 - acc: 0.9307\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 741us/step - loss: 0.0617 - acc: 0.9816\n",
      "30000/30000 [==============================] - 7s 234us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 23s 776us/step - loss: 0.2408 - acc: 0.9249\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 763us/step - loss: 0.0669 - acc: 0.97970s - loss: 0.0679 - acc\n",
      "30000/30000 [==============================] - 8s 280us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 24s 812us/step - loss: 1.2013 - acc: 0.6314\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 825us/step - loss: 0.4596 - acc: 0.8500\n",
      "30000/30000 [==============================] - 7s 248us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 1.0654 - acc: 0.6352\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 0.3424 - acc: 0.8884\n",
      "30000/30000 [==============================] - 7s 244us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 915us/step - loss: 0.5992 - acc: 0.8150\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 822us/step - loss: 0.1239 - acc: 0.9643\n",
      "30000/30000 [==============================] - 8s 264us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 905us/step - loss: 2.3941 - acc: 0.0992\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 859us/step - loss: 2.3301 - acc: 0.1004\n",
      "30000/30000 [==============================] - 8s 261us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 24s 817us/step - loss: 2.7127 - acc: 0.1005\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 905us/step - loss: 2.3988 - acc: 0.1017\n",
      "30000/30000 [==============================] - 9s 308us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 946us/step - loss: 2.5833 - acc: 0.1006\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 2.3869 - acc: 0.1045\n",
      "30000/30000 [==============================] - 9s 297us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 893us/step - loss: 0.2715 - acc: 0.9138\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 770us/step - loss: 0.0894 - acc: 0.9735\n",
      "30000/30000 [==============================] - 8s 259us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 849us/step - loss: 0.2657 - acc: 0.9185\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 0.0864 - acc: 0.9739\n",
      "30000/30000 [==============================] - 7s 249us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 875us/step - loss: 0.3550 - acc: 0.90410s - loss: 0.3590 - acc: 0\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.1097 - acc: 0.9707\n",
      "30000/30000 [==============================] - 8s 259us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 837us/step - loss: 0.3511 - acc: 0.9029\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 21s 716us/step - loss: 0.1085 - acc: 0.9706\n",
      "30000/30000 [==============================] - 7s 248us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.2769 - acc: 0.9157\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 873us/step - loss: 0.0874 - acc: 0.9738\n",
      "30000/30000 [==============================] - 11s 364us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.2240 - acc: 0.9305\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 903us/step - loss: 0.0824 - acc: 0.9749\n",
      "30000/30000 [==============================] - 9s 302us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.9773 - acc: 0.6693\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.2088 - acc: 0.9362\n",
      "30000/30000 [==============================] - 10s 341us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.8088 - acc: 0.7175\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 938us/step - loss: 0.1293 - acc: 0.9612\n",
      "30000/30000 [==============================] - 8s 271us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 865us/step - loss: 0.7441 - acc: 0.7501\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 60s 2ms/step - loss: 0.1149 - acc: 0.9682: 5s - los\n",
      "30000/30000 [==============================] - 26s 851us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.8855 - acc: 0.6967\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 839us/step - loss: 0.1198 - acc: 0.96781s - loss: 0.\n",
      "30000/30000 [==============================] - 9s 292us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 873us/step - loss: 0.7246 - acc: 0.7613\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 0.1414 - acc: 0.9572\n",
      "30000/30000 [==============================] - 9s 288us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 937us/step - loss: 0.6164 - acc: 0.8063\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 818us/step - loss: 0.1214 - acc: 0.9633\n",
      "30000/30000 [==============================] - 9s 294us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 950us/step - loss: 2.3693 - acc: 0.10800s - loss: 2.3703 - acc: \n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 2.2348 - acc: 0.1306\n",
      "30000/30000 [==============================] - 9s 288us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 981us/step - loss: 2.1251 - acc: 0.207110s - loss: 2.2621 - acc: - E\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 784us/step - loss: 1.4868 - acc: 0.4507\n",
      "30000/30000 [==============================] - 9s 290us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 941us/step - loss: 2.0728 - acc: 0.2412\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.2377 - acc: 0.9359\n",
      "30000/30000 [==============================] - 11s 372us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 2.4168 - acc: 0.1029\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.3282 - acc: 0.1035- ETA: 1s - loss: 2.3285 - acc: 0.103 - ETA: 1s - loss: 2.3 - 25s 830us/step - loss: 2.3281 - acc: 0.1035\n",
      "30000/30000 [==============================] - 8s 277us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 939us/step - loss: 2.6148 - acc: 0.0983\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 844us/step - loss: 2.3942 - acc: 0.1036\n",
      "30000/30000 [==============================] - 8s 281us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 907us/step - loss: 2.5931 - acc: 0.1023\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 856us/step - loss: 2.3978 - acc: 0.0997\n",
      "30000/30000 [==============================] - 9s 291us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 921us/step - loss: 2.3815 - acc: 0.1090\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 2.3015 - acc: 0.11062s - l\n",
      "30000/30000 [==============================] - 9s 297us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 963us/step - loss: 2.4272 - acc: 0.1085\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 9s 296us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.4159 - acc: 0.1025\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 840us/step - loss: 2.3303 - acc: 0.10217\n",
      "30000/30000 [==============================] - 9s 289us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 0.7081 - acc: 0.7856\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 915us/step - loss: 0.2039 - acc: 0.9451\n",
      "30000/30000 [==============================] - 10s 332us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.6365 - acc: 0.1000\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 2.4060 - acc: 0.1029\n",
      "30000/30000 [==============================] - 13s 442us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 46s 2ms/step - loss: 2.5748 - acc: 0.1001: 5\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 2.3961 - acc: 0.1020\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2679 - acc: 0.9174\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.0854 - acc: 0.9747\n",
      "30000/30000 [==============================] - 14s 479us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.2619 - acc: 0.9207\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 809us/step - loss: 0.0870 - acc: 0.97381s - loss: 0.0880 - ETA: 0s - loss: 0.0874 - acc: 0.\n",
      "30000/30000 [==============================] - 9s 287us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 940us/step - loss: 0.3253 - acc: 0.9105\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 826us/step - loss: 0.0897 - acc: 0.9762\n",
      "30000/30000 [==============================] - 9s 301us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 992us/step - loss: 0.2876 - acc: 0.9204\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 863us/step - loss: 0.0982 - acc: 0.9725\n",
      "30000/30000 [==============================] - 9s 291us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 0.2034 - acc: 0.93733s\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 810us/step - loss: 0.0636 - acc: 0.9797\n",
      "30000/30000 [==============================] - 9s 297us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 928us/step - loss: 0.2062 - acc: 0.9367\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 813us/step - loss: 0.0657 - acc: 0.9796\n",
      "30000/30000 [==============================] - 9s 301us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 1.9946 - acc: 0.2695\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 937us/step - loss: 1.3857 - acc: 0.5064\n",
      "30000/30000 [==============================] - 9s 293us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 1.9863 - acc: 0.2574\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 1.0810 - acc: 0.6029\n",
      "30000/30000 [==============================] - 12s 392us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 42s 1ms/step - loss: 2.3942 - acc: 0.1010\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3301 - acc: 0.1011\n",
      "30000/30000 [==============================] - 10s 350us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.7000 - acc: 0.7858\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.1282 - acc: 0.9654\n",
      "30000/30000 [==============================] - 11s 351us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.6079 - acc: 0.1025\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 936us/step - loss: 2.3895 - acc: 0.1029\n",
      "30000/30000 [==============================] - 11s 367us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.6407 - acc: 0.1023\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 909us/step - loss: 2.3959 - acc: 0.10170s - loss: 2.3971 - acc: \n",
      "30000/30000 [==============================] - 9s 308us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3017 - acc: 0.9071\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 942us/step - loss: 0.1117 - acc: 0.9673\n",
      "30000/30000 [==============================] - 13s 439us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.2920 - acc: 0.9107\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 882us/step - loss: 0.1275 - acc: 0.9627\n",
      "30000/30000 [==============================] - 10s 334us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 982us/step - loss: 0.4199 - acc: 0.8846\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 840us/step - loss: 0.1571 - acc: 0.9564\n",
      "30000/30000 [==============================] - 9s 310us/step\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.4001 - acc: 0.8910\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 902us/step - loss: 0.1593 - acc: 0.9571\n",
      "30000/30000 [==============================] - 9s 303us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.2615 - acc: 0.9205\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 998us/step - loss: 0.1240 - acc: 0.96164s - loss: 0.1258 - acc - ETA: 3s - \n",
      "30000/30000 [==============================] - 12s 409us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.2490 - acc: 0.9241\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 914us/step - loss: 0.1056 - acc: 0.9685\n",
      "30000/30000 [==============================] - 10s 322us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.5384 - acc: 0.8248\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.1473 - acc: 0.9554\n",
      "30000/30000 [==============================] - 12s 385us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.6885 - acc: 0.7706\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 770us/step - loss: 0.1862 - acc: 0.9436\n",
      "30000/30000 [==============================] - 9s 300us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 0.6520 - acc: 0.7923\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1546 - acc: 0.9554\n",
      "30000/30000 [==============================] - 10s 324us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 962us/step - loss: 0.6232 - acc: 0.8083\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 781us/step - loss: 0.1532 - acc: 0.9573\n",
      "30000/30000 [==============================] - 10s 323us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 934us/step - loss: 0.5838 - acc: 0.8115\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 764us/step - loss: 0.1321 - acc: 0.9585\n",
      "30000/30000 [==============================] - 14s 457us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.4659 - acc: 0.8559\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1324 - acc: 0.9594\n",
      "30000/30000 [==============================] - 13s 434us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.3595 - acc: 0.111 - 29s 961us/step - loss: 2.3592 - acc: 0.1114\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 958us/step - loss: 1.2928 - acc: 0.5558\n",
      "30000/30000 [==============================] - 9s 305us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3863 - acc: 0.1135\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 897us/step - loss: 2.3011 - acc: 0.1141\n",
      "30000/30000 [==============================] - 12s 402us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 2.3786 - acc: 0.1018\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 800us/step - loss: 2.3239 - acc: 0.10422\n",
      "30000/30000 [==============================] - 11s 350us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 970us/step - loss: 2.3869 - acc: 0.1020\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 2.3317 - acc: 0.1023\n",
      "30000/30000 [==============================] - 10s 333us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.5996 - acc: 0.0998\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 734us/step - loss: 2.3917 - acc: 0.1028\n",
      "30000/30000 [==============================] - 10s 339us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.6082 - acc: 0.0994\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.3949 - acc: 0.099 - 24s 791us/step - loss: 2.3947 - acc: 0.0996\n",
      "30000/30000 [==============================] - 9s 315us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.7952 - acc: 0.734 - 29s 982us/step - loss: 0.7936 - acc: 0.7348\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 781us/step - loss: 0.2785 - acc: 0.9166\n",
      "30000/30000 [==============================] - 10s 330us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.6540 - acc: 0.7857\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.2552 - acc: 0.9227\n",
      "30000/30000 [==============================] - 10s 318us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 973us/step - loss: 0.6443 - acc: 0.8049\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 754us/step - loss: 0.2827 - acc: 0.9188\n",
      "30000/30000 [==============================] - 10s 322us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 993us/step - loss: 1.0580 - acc: 0.6501\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 772us/step - loss: 0.3137 - acc: 0.9113\n",
      "30000/30000 [==============================] - 10s 324us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 999us/step - loss: 0.5935 - acc: 0.8164\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 791us/step - loss: 0.2421 - acc: 0.9275\n",
      "30000/30000 [==============================] - 10s 328us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 997us/step - loss: 0.6823 - acc: 0.7985\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 780us/step - loss: 0.2696 - acc: 0.9193\n",
      "30000/30000 [==============================] - 10s 330us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3099 - acc: 0.1072\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 833us/step - loss: 2.3016 - acc: 0.1106\n",
      "30000/30000 [==============================] - 11s 359us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3062 - acc: 0.1122\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 11s 360us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3126 - acc: 0.1081\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 860us/step - loss: 2.3049 - acc: 0.1071\n",
      "30000/30000 [==============================] - 11s 378us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3152 - acc: 0.1122: 1s - loss: 2.3161\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 912us/step - loss: 2.3037 - acc: 0.1102\n",
      "30000/30000 [==============================] - 12s 385us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.3176 - acc: 0.1072\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 2.3020 - acc: 0.1100\n",
      "30000/30000 [==============================] - 12s 393us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.3209 - acc: 0.1125\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 918us/step - loss: 2.3016 - acc: 0.1134\n",
      "30000/30000 [==============================] - 12s 403us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3416 - acc: 0.1088\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 892us/step - loss: 2.3015 - acc: 0.1106\n",
      "30000/30000 [==============================] - 12s 388us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 2.3696 - acc: 0.1097\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 893us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 11s 379us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.4168 - acc: 0.1016\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 863us/step - loss: 2.3386 - acc: 0.1009\n",
      "30000/30000 [==============================] - 12s 394us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 2.3345 - acc: 0.1078\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 851us/step - loss: 2.3013 - acc: 0.1140\n",
      "30000/30000 [==============================] - 11s 369us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.6424 - acc: 0.1013: 8s - los\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 843us/step - loss: 2.4050 - acc: 0.1005\n",
      "30000/30000 [==============================] - 11s 373us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 2.6207 - acc: 0.1045\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 844us/step - loss: 2.3943 - acc: 0.0982\n",
      "30000/30000 [==============================] - 12s 416us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.4100 - acc: 0.1076\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 833us/step - loss: 2.3016 - acc: 0.1106\n",
      "30000/30000 [==============================] - 11s 376us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3954 - acc: 0.1107\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 847us/step - loss: 2.3012 - acc: 0.1141\n",
      "30000/30000 [==============================] - 12s 384us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 1.1090 - acc: 0.6230\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 944us/step - loss: 0.3247 - acc: 0.9056\n",
      "30000/30000 [==============================] - 14s 457us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 2.3719 - acc: 0.0991\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 894us/step - loss: 2.3205 - acc: 0.1046\n",
      "30000/30000 [==============================] - 12s 407us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 2.5792 - acc: 0.102 - 38s 1ms/step - loss: 2.5783 - acc: 0.1027\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 875us/step - loss: 2.3947 - acc: 0.1008\n",
      "30000/30000 [==============================] - 12s 406us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 2.5431 - acc: 0.1009: 6s - loss: - ETA: 3s - loss\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 903us/step - loss: 2.3918 - acc: 0.1057\n",
      "30000/30000 [==============================] - 13s 425us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.4916 - acc: 0.8377\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 892us/step - loss: 0.1318 - acc: 0.9603\n",
      "30000/30000 [==============================] - 12s 402us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.8665 - acc: 0.7036\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.1594 - acc: 0.9527\n",
      "30000/30000 [==============================] - 18s 583us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.4519 - acc: 0.8635\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.1269 - acc: 0.9646\n",
      "30000/30000 [==============================] - 18s 615us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 0.5286 - acc: 0.8363\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.1307 - acc: 0.9639\n",
      "30000/30000 [==============================] - 19s 633us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 66s 2ms/step - loss: 0.6131 - acc: 0.8036\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 46s 2ms/step - loss: 0.1305 - acc: 0.9594\n",
      "30000/30000 [==============================] - 33s 1ms/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 80s 3ms/step - loss: 0.5222 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 45s 2ms/step - loss: 0.1120 - acc: 0.9653\n",
      "30000/30000 [==============================] - 14s 475us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 2.3959 - acc: 0.1079\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 950us/step - loss: 2.3009 - acc: 0.1100\n",
      "30000/30000 [==============================] - 13s 429us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 2.3674 - acc: 0.1131\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.1624 - acc: 0.1770\n",
      "30000/30000 [==============================] - 14s 474us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 2.4001 - acc: 0.0987\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 930us/step - loss: 2.3328 - acc: 0.1014\n",
      "30000/30000 [==============================] - 13s 445us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 1.0532 - acc: 0.6432\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 942us/step - loss: 0.1748 - acc: 0.9517\n",
      "30000/30000 [==============================] - 14s 458us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 2.6046 - acc: 0.1039\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 928us/step - loss: 2.3978 - acc: 0.1015\n",
      "30000/30000 [==============================] - 16s 519us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 2.6197 - acc: 0.1016\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 2.4023 - acc: 0.1013\n",
      "30000/30000 [==============================] - 16s 524us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 2.3936 - acc: 0.1184\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 926us/step - loss: 2.3016 - acc: 0.1106\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.5717 - acc: 0.8132\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 930us/step - loss: 0.2347 - acc: 0.9277\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.6377 - acc: 0.8112\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 912us/step - loss: 0.2786 - acc: 0.9213\n",
      "30000/30000 [==============================] - 14s 476us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.6327 - acc: 0.8137\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.2914 - acc: 0.9180\n",
      "30000/30000 [==============================] - 14s 471us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 45s 1ms/step - loss: 2.6483 - acc: 0.0980\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 952us/step - loss: 2.4084 - acc: 0.1017\n",
      "30000/30000 [==============================] - 14s 478us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 0.5954 - acc: 0.8302\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 970us/step - loss: 0.2757 - acc: 0.9182\n",
      "30000/30000 [==============================] - 14s 470us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.2676 - acc: 0.917 - 38s 1ms/step - loss: 0.2672 - acc: 0.9174\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 932us/step - loss: 0.0741 - acc: 0.9769\n",
      "30000/30000 [==============================] - 14s 466us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 45s 2ms/step - loss: 0.2616 - acc: 0.9210: 5s -\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 898us/step - loss: 0.0724 - acc: 0.9777\n",
      "30000/30000 [==============================] - 14s 464us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 42s 1ms/step - loss: 0.3030 - acc: 0.9176\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 851us/step - loss: 0.0847 - acc: 0.97700s - loss: 0.0851 - acc: \n",
      "30000/30000 [==============================] - 14s 454us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 39s 1ms/step - loss: 0.3291 - acc: 0.9057: 11s - l - ETA: 7s - loss: 0.3778 - acc:\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 767us/step - loss: 0.0930 - acc: 0.9751\n",
      "30000/30000 [==============================] - 13s 418us/step\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.2296 - acc: 0.9289\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 882us/step - loss: 0.0676 - acc: 0.9795\n",
      "30000/30000 [==============================] - 14s 480us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 42s 1ms/step - loss: 0.2045 - acc: 0.9361\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 848us/step - loss: 0.0626 - acc: 0.9813\n",
      "30000/30000 [==============================] - 14s 479us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 45s 1ms/step - loss: 1.1618 - acc: 0.6427\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 0.3634 - acc: 0.8830\n",
      "30000/30000 [==============================] - 14s 475us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 0.9788 - acc: 0.6917: 3s - loss: \n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 904us/step - loss: 0.3287 - acc: 0.8964\n",
      "30000/30000 [==============================] - 16s 546us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.5789 - acc: 0.8237\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 943us/step - loss: 0.1272 - acc: 0.9649\n",
      "30000/30000 [==============================] - 15s 496us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.6186 - acc: 0.8108\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 950us/step - loss: 0.1254 - acc: 0.9652\n",
      "30000/30000 [==============================] - 16s 543us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 2.5931 - acc: 0.1000: \n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 923us/step - loss: 2.3818 - acc: 0.1002\n",
      "30000/30000 [==============================] - 17s 583us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.6142 - acc: 0.1030\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.4059 - acc: 0.0988\n",
      "30000/30000 [==============================] - 18s 596us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.2559 - acc: 0.9217\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.0914 - acc: 0.9732\n",
      "30000/30000 [==============================] - 17s 562us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.2401 - acc: 0.9252: 3s - loss: 0.24 - ETA: 0s - loss: 0.2412 - acc: 0.92\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 985us/step - loss: 0.0855 - acc: 0.9750\n",
      "30000/30000 [==============================] - 18s 606us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.3212 - acc: 0.9124\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 895us/step - loss: 0.1136 - acc: 0.9684\n",
      "30000/30000 [==============================] - 15s 494us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.3279 - acc: 0.9125\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 895us/step - loss: 0.1091 - acc: 0.9707\n",
      "30000/30000 [==============================] - 15s 505us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.2371 - acc: 0.9278\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 925us/step - loss: 0.0840 - acc: 0.9757\n",
      "30000/30000 [==============================] - 15s 493us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 44s 1ms/step - loss: 0.2213 - acc: 0.9332\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 896us/step - loss: 0.0838 - acc: 0.9746\n",
      "30000/30000 [==============================] - 16s 526us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.7564 - acc: 0.7460\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 945us/step - loss: 0.1891 - acc: 0.9413\n",
      "30000/30000 [==============================] - 16s 542us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.8830 - acc: 0.6932\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1683 - acc: 0.9497\n",
      "30000/30000 [==============================] - 17s 557us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.7694 - acc: 0.7549\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 975us/step - loss: 0.1865 - acc: 0.9479\n",
      "30000/30000 [==============================] - 17s 573us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.7521 - acc: 0.7620\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 956us/step - loss: 0.2027 - acc: 0.9416\n",
      "30000/30000 [==============================] - 19s 619us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 2.3178 - acc: 0.1081\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 971us/step - loss: 2.3020 - acc: 0.1094\n",
      "30000/30000 [==============================] - 17s 569us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 1.3112 - acc: 0.5234\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 979us/step - loss: 0.1522 - acc: 0.9542\n",
      "30000/30000 [==============================] - 17s 577us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 1.8433 - acc: 0.3294\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.6902 - acc: 0.7578\n",
      "30000/30000 [==============================] - 21s 707us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 65s 2ms/step - loss: 2.2924 - acc: 0.1381\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 1.7268 - acc: 0.3586\n",
      "30000/30000 [==============================] - 17s 559us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 1.1062 - acc: 0.6376\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1898 - acc: 0.9473\n",
      "30000/30000 [==============================] - 18s 596us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.8587 - acc: 0.7286\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 0.1830 - acc: 0.9501\n",
      "30000/30000 [==============================] - 18s 616us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.6756 - acc: 0.1037\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.4071 - acc: 0.1007\n",
      "30000/30000 [==============================] - 19s 647us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.5617 - acc: 0.1005\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3888 - acc: 0.0996\n",
      "30000/30000 [==============================] - 17s 552us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 2.3584 - acc: 0.1084\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 907us/step - loss: 2.3016 - acc: 0.1103\n",
      "30000/30000 [==============================] - 16s 542us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.3843 - acc: 0.1118\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 2.3011 - acc: 0.1142\n",
      "30000/30000 [==============================] - 19s 650us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.4940 - acc: 0.0998\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 987us/step - loss: 2.3498 - acc: 0.1028\n",
      "30000/30000 [==============================] - 18s 599us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 1.3521 - acc: 0.5263\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.2496 - acc: 0.9293\n",
      "30000/30000 [==============================] - 19s 627us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 59s 2ms/step - loss: 2.6631 - acc: 0.0990\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 2.3968 - acc: 0.0990\n",
      "30000/30000 [==============================] - 20s 651us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.6428 - acc: 0.1021\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3912 - acc: 0.0983\n",
      "30000/30000 [==============================] - 20s 677us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.2509 - acc: 0.9241\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 0.0941 - acc: 0.9718\n",
      "30000/30000 [==============================] - 19s 627us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.2474 - acc: 0.9243\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.0924 - acc: 0.9720\n",
      "30000/30000 [==============================] - 19s 645us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 58s 2ms/step - loss: 0.2918 - acc: 0.9190\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.0995 - acc: 0.9728\n",
      "30000/30000 [==============================] - 21s 687us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.3055 - acc: 0.9172\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.1005 - acc: 0.9729: 0s - loss: 0.1007 - acc: 0\n",
      "30000/30000 [==============================] - 17s 566us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 48s 2ms/step - loss: 0.2136 - acc: 0.9338\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 0.0840 - acc: 0.9738\n",
      "30000/30000 [==============================] - 17s 565us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.2215 - acc: 0.9335\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 946us/step - loss: 0.0801 - acc: 0.9754\n",
      "30000/30000 [==============================] - 20s 668us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 1.6021 - acc: 0.4322\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.7850 - acc: 0.6976\n",
      "30000/30000 [==============================] - 20s 656us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 60s 2ms/step - loss: 1.3191 - acc: 0.5560\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.5775 - acc: 0.7959\n",
      "30000/30000 [==============================] - 19s 641us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 61s 2ms/step - loss: 0.6512 - acc: 0.7991\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 43s 1ms/step - loss: 0.1207 - acc: 0.9667\n",
      "30000/30000 [==============================] - 24s 806us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 64s 2ms/step - loss: 1.8445 - acc: 0.3339\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.1730 - acc: 0.9535\n",
      "30000/30000 [==============================] - 20s 654us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 55s 2ms/step - loss: 2.6058 - acc: 0.0965\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 2.3906 - acc: 0.1032\n",
      "30000/30000 [==============================] - 20s 658us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 2.6059 - acc: 0.1038\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 2.3946 - acc: 0.1023\n",
      "30000/30000 [==============================] - 19s 630us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.3718 - acc: 0.8872\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 981us/step - loss: 0.2129 - acc: 0.9364\n",
      "30000/30000 [==============================] - 19s 622us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.3641 - acc: 0.8905\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 983us/step - loss: 0.2208 - acc: 0.9347\n",
      "30000/30000 [==============================] - 19s 632us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.4252 - acc: 0.8852\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 985us/step - loss: 0.1745 - acc: 0.9515\n",
      "30000/30000 [==============================] - 21s 688us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 67s 2ms/step - loss: 0.4293 - acc: 0.8825\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1979 - acc: 0.9449\n",
      "30000/30000 [==============================] - 18s 614us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 53s 2ms/step - loss: 0.3736 - acc: 0.8884\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 985us/step - loss: 0.2565 - acc: 0.9232\n",
      "30000/30000 [==============================] - 19s 621us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 60s 2ms/step - loss: 0.3912 - acc: 0.8807\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.2770 - acc: 0.9166\n",
      "30000/30000 [==============================] - 18s 614us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed: 222.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.1467 - acc: 0.9543\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 59s 984us/step - loss: 0.0474 - acc: 0.9856\n",
      "Best: 0.983333 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.983100 (0.001367) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981167 (0.000600) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.982650 (0.000217) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.958250 (0.005183) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.543033 (0.432400) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.103233 (0.007400) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981467 (0.000700) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.975683 (0.003283) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.979317 (0.002017) with: {'activation_1': 'relu', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.972117 (0.004217) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.976633 (0.000333) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.973900 (0.001367) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.544983 (0.259817) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.537467 (0.426833) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.533700 (0.430133) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.106533 (0.004100) with: {'activation_1': 'relu', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981617 (0.000717) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981117 (0.001017) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.979517 (0.003783) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.879150 (0.054083) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.537950 (0.437850) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.103233 (0.007400) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.976067 (0.001400) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.969067 (0.000200) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.969183 (0.003317) with: {'activation_1': 'relu', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.968950 (0.003183) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.970950 (0.000950) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.971183 (0.001783) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.494950 (0.384317) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.109683 (0.004417) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.949267 (0.001533) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.943850 (0.001083) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.943767 (0.006300) with: {'activation_1': 'sigmoid', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.100833 (0.002733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.106417 (0.007683) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.521483 (0.410850) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'sigmoid', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.972200 (0.001533) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.970467 (0.001767) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.972067 (0.003633) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.422233 (0.308133) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.536567 (0.433000) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.105367 (0.005267) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.533617 (0.419517) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.940833 (0.001767) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.516667 (0.417967) with: {'activation_1': 'sigmoid', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.981567 (0.001300) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.980467 (0.001100) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.983333 (0.001200) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.961700 (0.002567) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.974083 (0.000117) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.980867 (0.001000) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.977683 (0.000417) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.980650 (0.000550) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.971083 (0.000783) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.965633 (0.002733) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.541417 (0.427317) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.775783 (0.158417) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.965500 (0.000167) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.105650 (0.008450) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.112367 (0.001733) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.535217 (0.421117) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.104450 (0.006183) with: {'activation_1': 'tanh', 'activation_2': 'sigmoid', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.979050 (0.002183) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.977733 (0.000467) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.978100 (0.000333) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.947850 (0.008617) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.973317 (0.003050) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.108017 (0.006083) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'sigmoid', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.959717 (0.000150) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'relu', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.963767 (0.001600) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'sigmoid', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.936933 (0.005800) with: {'activation_1': 'tanh', 'activation_2': 'tanh', 'activation_3': 'tanh', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "Best: 0.983333 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 14s 1ms/step\n",
      "Test Accuracy 0.9882000062465668\n"
     ]
    }
   ],
   "source": [
    "#activations grid search over 4 activations using relu, sigmoid, and tanh\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [2],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation_2' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation_3' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'activation_4' : ['relu', 'sigmoid', 'tanh'],\n",
    "              'kernel_size' : [[5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam\n",
    "#BEST ACTIVATIONS tanh, relu, relu, tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.2527 - acc: 0.9246\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 0.0674 - acc: 0.9795\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 879us/step - loss: 0.0484 - acc: 0.9850\n",
      "30000/30000 [==============================] - 17s 577us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2119 - acc: 0.9360\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 861us/step - loss: 0.0561 - acc: 0.9829\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 0.0385 - acc: 0.9879\n",
      "30000/30000 [==============================] - 18s 589us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2103 - acc: 0.9345\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 867us/step - loss: 0.0648 - acc: 0.9806\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 855us/step - loss: 0.0441 - acc: 0.9865\n",
      "30000/30000 [==============================] - 18s 611us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 52s 2ms/step - loss: 0.2170 - acc: 0.9339: 3s - loss: 0.2258\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 881us/step - loss: 0.0624 - acc: 0.9808\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 884us/step - loss: 0.0393 - acc: 0.9875\n",
      "30000/30000 [==============================] - 18s 588us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 50s 2ms/step - loss: 0.2287 - acc: 0.9307\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 849us/step - loss: 0.0677 - acc: 0.9794\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 0.0435 - acc: 0.9867\n",
      "30000/30000 [==============================] - 18s 594us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.2214 - acc: 0.9315\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 28s 938us/step - loss: 0.0654 - acc: 0.9795\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 28s 937us/step - loss: 0.0435 - acc: 0.9864\n",
      "30000/30000 [==============================] - 18s 608us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 12.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.1395 - acc: 0.957 - 76s 1ms/step - loss: 0.1393 - acc: 0.9579\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 52s 866us/step - loss: 0.0487 - acc: 0.9848\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 52s 861us/step - loss: 0.0359 - acc: 0.9890\n",
      "Best: 0.986400 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.985950 (0.000683) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [3, 3], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.986400 (0.001067) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "0.984433 (0.000833) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [5, 5], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "Best: 0.986400 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "Test Accuracy 0.9908000066280365\n"
     ]
    }
   ],
   "source": [
    "#kernel size over (3,3), (4,4), (5,5)\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[3,3], [4,4], [5,5]],\n",
    "              'pool_size' : [[2,2]],\n",
    "              'dropout_1' : [0.25],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam\n",
    "#BEST ACTIVATIONS tanh, relu, relu, tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 54s 2ms/step - loss: 0.1788 - acc: 0.9440\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 882us/step - loss: 0.0474 - acc: 0.9849\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 0.0274 - acc: 0.9914\n",
      "30000/30000 [==============================] - 18s 601us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 0.1776 - acc: 0.9472\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 877us/step - loss: 0.0431 - acc: 0.9872\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 27s 888us/step - loss: 0.0231 - acc: 0.9936\n",
      "30000/30000 [==============================] - 18s 599us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 51s 2ms/step - loss: 0.1835 - acc: 0.9423\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 26s 872us/step - loss: 0.0474 - acc: 0.9860\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 26s 864us/step - loss: 0.0309 - acc: 0.9903\n",
      "30000/30000 [==============================] - 18s 604us/step\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.1943 - acc: 0.9389- ETA: 1s - loss: 0.1996 - ac\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 25s 818us/step - loss: 0.0466 - acc: 0.9865\n",
      "Epoch 3/3\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.0258 - acc: 0.9922\n",
      "30000/30000 [==============================] - 18s 597us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.1136 - acc: 0.9648\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 52s 862us/step - loss: 0.0338 - acc: 0.9893\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 52s 863us/step - loss: 0.0223 - acc: 0.9932\n",
      "Best: 0.985667 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985667 (0.000733) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.983400 (0.000033) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [2, 2]}\n",
      "Best: 0.985667 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 3, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "Test Accuracy 0.9916000044345856\n"
     ]
    }
   ],
   "source": [
    "#pool size grid search over (1,1), (2,2), (3,3)\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [3],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[4,4]],\n",
    "              'pool_size' : [[1,1], [2,2]],\n",
    "              'dropout_1' : [0.0],\n",
    "              'dropout_2' : [0.0]\n",
    "             }\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.2254 - acc: 0.9333\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 915us/step - loss: 0.0541 - acc: 0.9829\n",
      "30000/30000 [==============================] - 7s 222us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 21s 705us/step - loss: 0.1710 - acc: 0.9479\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 794us/step - loss: 0.0466 - acc: 0.9852\n",
      "30000/30000 [==============================] - 7s 246us/step\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.1990 - acc: 0.9375\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 47s 2ms/step - loss: 0.0554 - acc: 0.9834\n",
      "30000/30000 [==============================] - 10s 341us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.1895 - acc: 0.9402\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.0519 - acc: 0.9842\n",
      "30000/30000 [==============================] - 11s 354us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.2181 - acc: 0.9338\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.0641 - acc: 0.9804\n",
      "30000/30000 [==============================] - 11s 369us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.2110 - acc: 0.9349\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.0576 - acc: 0.9830\n",
      "30000/30000 [==============================] - 11s 354us/step\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 45s 1ms/step - loss: 0.3117 - acc: 0.9082\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.0981 - acc: 0.9732\n",
      "30000/30000 [==============================] - 8s 258us/step\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 23s 758us/step - loss: 0.2925 - acc: 0.9127\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 807us/step - loss: 0.0965 - acc: 0.9734\n",
      "30000/30000 [==============================] - 7s 246us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 949us/step - loss: 0.1823 - acc: 0.9427\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 835us/step - loss: 0.0507 - acc: 0.9841\n",
      "30000/30000 [==============================] - 8s 259us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 898us/step - loss: 0.1892 - acc: 0.9421\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 845us/step - loss: 0.0491 - acc: 0.9850\n",
      "30000/30000 [==============================] - 7s 243us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 24s 786us/step - loss: 0.2086 - acc: 0.9356\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 777us/step - loss: 0.0610 - acc: 0.9813\n",
      "30000/30000 [==============================] - 7s 240us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 862us/step - loss: 0.2078 - acc: 0.9355\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 762us/step - loss: 0.0563 - acc: 0.9830\n",
      "30000/30000 [==============================] - 7s 224us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 819us/step - loss: 0.2440 - acc: 0.9255\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 786us/step - loss: 0.0756 - acc: 0.9783\n",
      "30000/30000 [==============================] - 7s 237us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 817us/step - loss: 0.2177 - acc: 0.9338\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 821us/step - loss: 0.0698 - acc: 0.9800\n",
      "30000/30000 [==============================] - 7s 234us/step\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 900us/step - loss: 0.2956 - acc: 0.9117\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 770us/step - loss: 0.0995 - acc: 0.9725\n",
      "30000/30000 [==============================] - 8s 274us/step\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 909us/step - loss: 0.3305 - acc: 0.9017\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 881us/step - loss: 0.1064 - acc: 0.9712\n",
      "30000/30000 [==============================] - 7s 242us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 864us/step - loss: 0.1957 - acc: 0.94111s - loss: 0.2\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 772us/step - loss: 0.0570 - acc: 0.9823\n",
      "30000/30000 [==============================] - 7s 238us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 829us/step - loss: 0.2055 - acc: 0.9360\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 743us/step - loss: 0.0561 - acc: 0.9830\n",
      "30000/30000 [==============================] - 7s 241us/step\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 817us/step - loss: 0.2119 - acc: 0.9338\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 753us/step - loss: 0.0671 - acc: 0.9791\n",
      "30000/30000 [==============================] - 7s 242us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 829us/step - loss: 0.2182 - acc: 0.9330\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 782us/step - loss: 0.0668 - acc: 0.9799\n",
      "30000/30000 [==============================] - 7s 249us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 0.2382 - acc: 0.9275\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 772us/step - loss: 0.0831 - acc: 0.9751\n",
      "30000/30000 [==============================] - 7s 246us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 843us/step - loss: 0.2396 - acc: 0.9297\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 799us/step - loss: 0.0812 - acc: 0.9760\n",
      "30000/30000 [==============================] - 8s 279us/step\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 928us/step - loss: 0.3317 - acc: 0.9002\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 767us/step - loss: 0.1201 - acc: 0.96711s - loss:\n",
      "30000/30000 [==============================] - 7s 245us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 904us/step - loss: 0.3276 - acc: 0.9017\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 806us/step - loss: 0.1208 - acc: 0.9663\n",
      "30000/30000 [==============================] - 8s 276us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 925us/step - loss: 0.2279 - acc: 0.9289\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 852us/step - loss: 0.0826 - acc: 0.9738\n",
      "30000/30000 [==============================] - 7s 244us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 965us/step - loss: 0.2299 - acc: 0.9285\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 771us/step - loss: 0.0791 - acc: 0.9755\n",
      "30000/30000 [==============================] - 7s 249us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 919us/step - loss: 0.2577 - acc: 0.9195\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 0.0915 - acc: 0.97140s - loss: 0.0914 - acc: \n",
      "30000/30000 [==============================] - 8s 281us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 851us/step - loss: 0.2524 - acc: 0.9218\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 747us/step - loss: 0.0971 - acc: 0.9700\n",
      "30000/30000 [==============================] - 7s 245us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 827us/step - loss: 0.3097 - acc: 0.9048\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 24s 789us/step - loss: 0.1170 - acc: 0.96561s - loss: 0.117\n",
      "30000/30000 [==============================] - 8s 253us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 26s 862us/step - loss: 0.3155 - acc: 0.9031\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 782us/step - loss: 0.1153 - acc: 0.96492s \n",
      "30000/30000 [==============================] - 8s 269us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 27s 901us/step - loss: 0.4011 - acc: 0.87693s - los - ETA: 0s - loss: 0.4051 - acc: 0\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 22s 745us/step - loss: 0.1549 - acc: 0.9577\n",
      "30000/30000 [==============================] - 8s 265us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 25s 846us/step - loss: 0.3987 - acc: 0.8790\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 23s 763us/step - loss: 0.1548 - acc: 0.9557\n",
      "30000/30000 [==============================] - 7s 247us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 33.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 47s 779us/step - loss: 0.1350 - acc: 0.9592\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 42s 694us/step - loss: 0.0395 - acc: 0.9878\n",
      "Best: 0.985283 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.983767 (0.000233) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.0, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985283 (0.000250) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.982283 (0.001450) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.5, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985183 (0.000817) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.75, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.984367 (0.002500) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.0, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985033 (0.000533) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.984033 (0.001633) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.5, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985050 (0.000083) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.25, 'dropout_2': 0.75, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.982967 (0.000033) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.5, 'dropout_2': 0.0, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.985183 (0.000550) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.5, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.984367 (0.000233) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.5, 'dropout_2': 0.5, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.983200 (0.001233) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.5, 'dropout_2': 0.75, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.982933 (0.000033) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.75, 'dropout_2': 0.0, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.983250 (0.000783) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.75, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.981450 (0.000050) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.75, 'dropout_2': 0.5, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.981983 (0.000150) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.75, 'dropout_2': 0.75, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "Best: 0.985283 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "10000/10000 [==============================] - 3s 308us/step\n",
      "Test Accuracy 0.9899000067710877\n"
     ]
    }
   ],
   "source": [
    "#dropouts grid search over 0.0, 0.25, 0.50, 0.75\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [2],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[4,4]],\n",
    "              'pool_size' : [[1,1]],\n",
    "              'dropout_1' : [0.0],\n",
    "              'dropout_2' : [0.25]\n",
    "             }\n",
    "\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Print Test Accuracy\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignement says to use some kind of regularizer to limit overfitting, so I've chosen keras bias and kernel regularizers. I have never worked with regularizers before so my choice of regularizers might be somewhat arbitrary. \n",
    "\n",
    "The grid search is over 0.0001, 0.001, and 0.01 for all 4 regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 971us/step - loss: 0.3488 - acc: 0.9380\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 841us/step - loss: 0.1913 - acc: 0.9741\n",
      "30000/30000 [==============================] - 9s 287us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.3720 - acc: 0.9336\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 891us/step - loss: 0.1884 - acc: 0.9744\n",
      "30000/30000 [==============================] - 9s 298us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 960us/step - loss: 0.5543 - acc: 0.9188\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 841us/step - loss: 0.2882 - acc: 0.96081s - loss: 0.2874 -\n",
      "30000/30000 [==============================] - 9s 300us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 0.5545 - acc: 0.9187\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 877us/step - loss: 0.2782 - acc: 0.9619\n",
      "30000/30000 [==============================] - 8s 276us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 921us/step - loss: 1.0115 - acc: 0.8761\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 848us/step - loss: 0.4879 - acc: 0.9362\n",
      "30000/30000 [==============================] - 8s 281us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 1.0355 - acc: 0.8635\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 0.4474 - acc: 0.93941s - loss: 0.447\n",
      "30000/30000 [==============================] - 8s 283us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 945us/step - loss: 0.4508 - acc: 0.9266\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 837us/step - loss: 0.2188 - acc: 0.9662\n",
      "30000/30000 [==============================] - 9s 284us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 936us/step - loss: 0.4335 - acc: 0.9310\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 832us/step - loss: 0.2078 - acc: 0.9700\n",
      "30000/30000 [==============================] - 9s 313us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.6107 - acc: 0.9115\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 0.2988 - acc: 0.9561\n",
      "30000/30000 [==============================] - 9s 284us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.6171 - acc: 0.9136\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 884us/step - loss: 0.2899 - acc: 0.9589\n",
      "30000/30000 [==============================] - 9s 299us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 1.0813 - acc: 0.8619\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 932us/step - loss: 0.4444 - acc: 0.93413s -\n",
      "30000/30000 [==============================] - 10s 326us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 1.1465 - acc: 0.8590\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 965us/step - loss: 0.4773 - acc: 0.9315\n",
      "30000/30000 [==============================] - 10s 318us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.6535 - acc: 0.9099\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 847us/step - loss: 0.2495 - acc: 0.9603\n",
      "30000/30000 [==============================] - 9s 287us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 28s 950us/step - loss: 0.6096 - acc: 0.9188\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 25s 832us/step - loss: 0.2356 - acc: 0.9643\n",
      "30000/30000 [==============================] - 9s 288us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.8045 - acc: 0.8865\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 874us/step - loss: 0.4734 - acc: 0.9340\n",
      "30000/30000 [==============================] - 10s 322us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.7980 - acc: 0.8891\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 875us/step - loss: 0.3490 - acc: 0.9477\n",
      "30000/30000 [==============================] - 9s 303us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 1.2692 - acc: 0.8437\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 965us/step - loss: 0.6132 - acc: 0.9142\n",
      "30000/30000 [==============================] - 9s 298us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 1.2328 - acc: 0.8412\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 916us/step - loss: 0.7773 - acc: 0.9044\n",
      "30000/30000 [==============================] - 11s 351us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 19.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.2774 - acc: 0.9550\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 55s 922us/step - loss: 0.1662 - acc: 0.9775\n",
      "Best: 0.978967 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.978967 (0.000267) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.971250 (0.000283) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.01, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.947100 (0.002467) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.1, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.974967 (0.000700) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.01, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.969217 (0.002150) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.01, 'kreg2': 0.01, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.953667 (0.003400) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.01, 'kreg2': 0.1, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.971200 (0.000233) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.1, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.959817 (0.000350) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.1, 'kreg2': 0.01, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.936567 (0.000133) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.1, 'kreg2': 0.1, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "Best: 0.978967 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.0, 'breg2': 0.0, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "10000/10000 [==============================] - 4s 410us/step\n",
      "Test Accuracy 0.981000004529953\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "def create_model(optimizer, activation_1, activation_2, activation_3, activation_4, kernel_size, pool_size, dropout_1, dropout_2, kreg1, kreg2, breg1, breg2):\n",
    "    model = Sequential()\n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(6, kernel_size=kernel_size, strides=(1, 1), activation=activation_1, input_shape=(28,28,1), padding=\"same\"))\n",
    "\n",
    "    # First pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(1, 1), padding='valid'))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(16, kernel_size=kernel_size, strides=(1, 1), activation=activation_2, padding='valid'))\n",
    "    \n",
    "    # Second pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(2, 2), padding='valid'))\n",
    "    \n",
    "    # Connected convolutional layer\n",
    "    model.add(layers.Conv2D(120, kernel_regularizer=regularizers.l2(kreg1), bias_regularizer=regularizers.l2(breg1), kernel_size=kernel_size, strides=(1, 1), activation=activation_3, padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dropout(dropout_1)) \n",
    "    # Connected layer\n",
    "    model.add(layers.Dense(84, kernel_regularizer=regularizers.l2(kreg2), bias_regularizer=regularizers.l2(breg2), activation=activation_4))\n",
    "    model.add(Dropout(dropout_2)) \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # build/compile\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [2],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[4,4]],\n",
    "              'pool_size' : [[1,1]],\n",
    "              'dropout_1' : [0.0],\n",
    "              'dropout_2' : [0.25],\n",
    "              'kreg1' : [0.001 ,0.01, 0.1],\n",
    "              'kreg2' : [0.001, 0.01, 0.1],\n",
    "              'breg1' : [0.0],\n",
    "              'breg2' : [0.0]\n",
    "             }\n",
    "\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3487 - acc: 0.9374\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 926us/step - loss: 0.1897 - acc: 0.9741\n",
      "30000/30000 [==============================] - 10s 325us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3710 - acc: 0.9340\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 889us/step - loss: 0.1875 - acc: 0.9744\n",
      "30000/30000 [==============================] - 10s 324us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.3526 - acc: 0.9377\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 862us/step - loss: 0.1909 - acc: 0.97250s - loss: 0.1899 - acc:\n",
      "30000/30000 [==============================] - 9s 314us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.3535 - acc: 0.9383\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 29s 960us/step - loss: 0.1925 - acc: 0.9737\n",
      "30000/30000 [==============================] - 10s 331us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.3527 - acc: 0.9393\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 0.1968 - acc: 0.9730\n",
      "30000/30000 [==============================] - 9s 314us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.3715 - acc: 0.9313: 0s - loss: 0.3733 - acc: 0.9\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 862us/step - loss: 0.1945 - acc: 0.9736\n",
      "30000/30000 [==============================] - 10s 317us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3750 - acc: 0.9328\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 865us/step - loss: 0.2002 - acc: 0.9714\n",
      "30000/30000 [==============================] - 10s 331us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3638 - acc: 0.9367\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 889us/step - loss: 0.1844 - acc: 0.9749\n",
      "30000/30000 [==============================] - 12s 396us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 46s 2ms/step - loss: 0.3557 - acc: 0.9375\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 0.1952 - acc: 0.9734\n",
      "30000/30000 [==============================] - 10s 336us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3554 - acc: 0.9382\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 914us/step - loss: 0.1903 - acc: 0.9741\n",
      "30000/30000 [==============================] - 11s 352us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3734 - acc: 0.9332\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 899us/step - loss: 0.1969 - acc: 0.9722\n",
      "30000/30000 [==============================] - 10s 331us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3769 - acc: 0.9313\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 890us/step - loss: 0.2045 - acc: 0.9715\n",
      "30000/30000 [==============================] - 10s 337us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.3700 - acc: 0.9326\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1966 - acc: 0.9726\n",
      "30000/30000 [==============================] - 11s 361us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3454 - acc: 0.9414\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 26s 879us/step - loss: 0.1871 - acc: 0.9760\n",
      "30000/30000 [==============================] - 10s 349us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3751 - acc: 0.9306\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 920us/step - loss: 0.1970 - acc: 0.9727\n",
      "30000/30000 [==============================] - 11s 359us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3727 - acc: 0.9318\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 28s 919us/step - loss: 0.1942 - acc: 0.9733\n",
      "30000/30000 [==============================] - 10s 349us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3568 - acc: 0.9361\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1942 - acc: 0.9734\n",
      "30000/30000 [==============================] - 11s 379us/step\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 39s 1ms/step - loss: 0.3751 - acc: 0.9325\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 27s 914us/step - loss: 0.1886 - acc: 0.9746\n",
      "30000/30000 [==============================] - 11s 359us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 21.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.2774 - acc: 0.9550\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 56s 925us/step - loss: 0.1667 - acc: 0.9769\n",
      "Best: 0.979900 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.001, 'breg2': 0.001, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.979900 (0.000033) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.001, 'breg2': 0.001, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.977150 (0.001183) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.001, 'breg2': 0.01, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.968983 (0.003717) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.001, 'breg2': 0.1, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.978783 (0.002050) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.01, 'breg2': 0.001, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.979017 (0.000150) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.01, 'breg2': 0.01, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.977850 (0.003017) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.01, 'breg2': 0.1, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.979450 (0.000917) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.1, 'breg2': 0.001, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.978400 (0.000667) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.1, 'breg2': 0.01, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "0.973867 (0.002500) with: {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.1, 'breg2': 0.1, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "Best: 0.979900 using {'activation_1': 'tanh', 'activation_2': 'relu', 'activation_3': 'relu', 'activation_4': 'tanh', 'batch_size': 120, 'breg1': 0.001, 'breg2': 0.001, 'dropout_1': 0.0, 'dropout_2': 0.25, 'epochs': 2, 'kernel_size': [4, 4], 'kreg1': 0.001, 'kreg2': 0.001, 'optimizer': 'Nadam', 'pool_size': [1, 1]}\n",
      "10000/10000 [==============================] - 6s 617us/step\n",
      "Test Accuracy 0.9805000035762786\n"
     ]
    }
   ],
   "source": [
    "def create_model(optimizer, activation_1, activation_2, activation_3, activation_4, kernel_size, pool_size, dropout_1, dropout_2, kreg1, kreg2, breg1, breg2):\n",
    "    model = Sequential()\n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(6, kernel_size=kernel_size, strides=(1, 1), activation=activation_1, input_shape=(28,28,1), padding=\"same\"))\n",
    "\n",
    "    # First pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(1, 1), padding='valid'))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(16, kernel_size=kernel_size, strides=(1, 1), activation=activation_2, padding='valid'))\n",
    "    \n",
    "    # Second pooling layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=pool_size, strides=(2, 2), padding='valid'))\n",
    "    \n",
    "    # Connected convolutional layer\n",
    "    model.add(layers.Conv2D(120, kernel_regularizer=regularizers.l2(kreg1), bias_regularizer=regularizers.l2(breg1), kernel_size=kernel_size, strides=(1, 1), activation=activation_3, padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dropout(dropout_1)) \n",
    "    # Connected layer\n",
    "    model.add(layers.Dense(84, kernel_regularizer=regularizers.l2(kreg2), bias_regularizer=regularizers.l2(breg2), activation=activation_4))\n",
    "    model.add(Dropout(dropout_2)) \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # build/compile\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "param_grid = {'epochs': [2],\n",
    "              'batch_size': [120],\n",
    "              'optimizer': ['Nadam'],\n",
    "              'activation_1' : ['tanh'],\n",
    "              'activation_2' : ['relu'],\n",
    "              'activation_3' : ['relu'],\n",
    "              'activation_4' : ['tanh'],\n",
    "              'kernel_size' : [[4,4]],\n",
    "              'pool_size' : [[1,1]],\n",
    "              'dropout_1' : [0.0],\n",
    "              'dropout_2' : [0.25],\n",
    "              'kreg1' : [0.001],\n",
    "              'kreg2' : [0.001],\n",
    "              'breg1' : [0.001, 0.01, 0.1],\n",
    "              'breg2' : [0.001, 0.01, 0.1]\n",
    "             }\n",
    "\n",
    "\n",
    "my_classifier = KerasClassifier(create_model)\n",
    "\n",
    "grid = GridSearchCV(my_classifier, param_grid, cv=2, n_jobs=1, verbose=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Test Accuracy\", grid_result.score(x_test, y_test))\n",
    "\n",
    "#BEST BATCH SIZE 120\n",
    "#BEST OPTIMIZER Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.2679 - acc: 0.9199 - val_loss: 0.2019 - val_acc: 0.9372\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 52s 871us/step - loss: 0.1646 - acc: 0.9503 - val_loss: 0.1232 - val_acc: 0.9611\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.1215 - acc: 0.9637 - val_loss: 0.1015 - val_acc: 0.9686\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 53s 877us/step - loss: 0.1011 - acc: 0.9693 - val_loss: 0.0963 - val_acc: 0.9691\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 53s 891us/step - loss: 0.0907 - acc: 0.9722 - val_loss: 0.0758 - val_acc: 0.9795\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 55s 916us/step - loss: 0.0842 - acc: 0.9740 - val_loss: 0.0744 - val_acc: 0.9782\n",
      "10000/10000 [==============================] - 4s 430us/step\n",
      "Test loss 0.0744, accuracy 97.82%\n"
     ]
    }
   ],
   "source": [
    "# ORIGINAL MODEL ARCHITECTURE\n",
    "model = Sequential()\n",
    "#First convolutional layer\n",
    "model.add(layers.Conv2D(6, kernel_size=(5,5), strides=(1, 1), activation='tanh', input_shape=(28,28,1), padding=\"same\"))\n",
    "# First pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2,2), strides=(1, 1), padding='valid'))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(layers.Conv2D(16, kernel_size=(5,5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    " \n",
    "# Second pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2,2), strides=(2, 2), padding='valid'))\n",
    "   \n",
    "# Connected convolutional layer\n",
    "model.add(layers.Conv2D(120, kernel_size=(5,5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "model.add(layers.Flatten())\n",
    "# Connected layer\n",
    "model.add(layers.Dense(84, activation='tanh'))\n",
    "# Output layer\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "  \n",
    "# build/compile\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    \n",
    "hist = model.fit(x=x_train,y=y_train, epochs=6, batch_size=120, validation_data=(x_test, y_test), verbose=1)\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'acc')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['acc'], 'o-')\n",
    "ax.plot([None] + hist.history['val_acc'], 'x-')\n",
    "ax.legend(['Train acc', 'Validation acc'], loc = 0)\n",
    "ax.set_title('Training/Validation acc per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['loss'], 'o-')\n",
    "ax.plot([None] + hist.history['val_loss'], 'x-')\n",
    "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
    "ax.set_title('Training/Validation Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sindr\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 41s 678us/step - loss: 0.2824 - acc: 0.9543 - val_loss: 0.1561 - val_acc: 0.9820\n",
      "Epoch 2/20\n",
      " 1800/60000 [..............................] - ETA: 35s - loss: 0.1753 - acc: 0.9761"
     ]
    }
   ],
   "source": [
    "# FREEHAND TUNING\n",
    "model = Sequential()\n",
    "# First convolutional layer\n",
    "model.add(layers.Conv2D(6, kernel_size=(4,4), strides=(1, 1), activation='tanh', input_shape=(28,28,1), padding=\"same\"))\n",
    "# First pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(1,1), strides=(1, 1), padding='valid'))\n",
    " \n",
    "# Second convolutional layer\n",
    "model.add(layers.Conv2D(16, kernel_size=(4,4), strides=(1, 1), activation='relu', padding='valid'))\n",
    " \n",
    "# Second pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(1,1), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# Connected convolutional layer\n",
    "model.add(layers.Conv2D(120, kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001), kernel_size=(4,4), strides=(1, 1), activation='relu', padding='valid'))\n",
    "model.add(layers.Flatten())\n",
    "# Connected layer\n",
    "model.add(layers.Dense(84, kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001), activation='tanh'))\n",
    "model.add(Dropout(0.25)) \n",
    "# Output layer\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "# build/compile\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "    \n",
    "hist = model.fit(x=x_train,y=y_train, epochs=20, batch_size=120, validation_data=(x_test, y_test), verbose=1)\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "# After all tuning, 98.65% acc\n",
    "# Freehand tuning 1, val_acc 99.02%, val_loss 0.0851, regs 0.0001, dropout 0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'acc')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['acc'], 'o-')\n",
    "ax.plot([None] + hist.history['val_acc'], 'x-')\n",
    "ax.legend(['Train acc', 'Validation acc'], loc = 0)\n",
    "ax.set_title('Training/Validation acc per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['loss'], 'o-')\n",
    "ax.plot([None] + hist.history['val_loss'], 'x-')\n",
    "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
    "ax.set_title('Training/Validation Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.compat.v2.keras.utils.Sequence):\n",
    " \n",
    "    def __init__(self, X_data , y_data, batch_size, dim, n_classes,\n",
    "                 to_fit, shuffle = True):\n",
    "        self.batch_size = batch_size\n",
    "        self.X_data = X_data\n",
    "        self.labels = y_data\n",
    "        self.y_data = y_data\n",
    "        self.to_fit = to_fit\n",
    "        self.n_classes = n_classes\n",
    "        self.dim = dim\n",
    "        self.shuffle = shuffle\n",
    "        self.n = 0\n",
    "        self.list_IDs = np.arange(len(self.X_data))\n",
    "        self.on_epoch_end()\n",
    "    def __next__(self):\n",
    "        # Get one batch of data\n",
    "        data = self.__getitem__(self.n)\n",
    "        # Batch index\n",
    "        self.n += 1\n",
    "        \n",
    "        # If we have processed the entire dataset then\n",
    "        if self.n >= self.__len__():\n",
    "            self.on_epoch_end\n",
    "            self.n = 0\n",
    "        \n",
    "        return data\n",
    "    def __len__(self):\n",
    "        # Return the number of batches of the dataset\n",
    "        return math.ceil(len(self.indexes)/self.batch_size)\n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:\n",
    "            (index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        X = self._generate_x(list_IDs_temp)\n",
    "        \n",
    "        if self.to_fit:\n",
    "            y = self._generate_y(list_IDs_temp)\n",
    "            return X, y\n",
    "        else:\n",
    "            return X\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        self.indexes = np.arange(len(self.X_data))\n",
    "        \n",
    "        if self.shuffle: \n",
    "            np.random.shuffle(self.indexes)\n",
    "    def _generate_x(self, list_IDs_temp):\n",
    "               \n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "            X[i,] = self.X_data[ID]\n",
    "            \n",
    "            # Normalize data\n",
    "            X = (X/255).astype('float32')\n",
    "            \n",
    "        return X[:,:,:, np.newaxis]\n",
    "    def _generate_y(self, list_IDs_temp):\n",
    "        \n",
    "        y = np.empty(self.batch_size)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "            y[i] = self.y_data[ID]\n",
    "            \n",
    "        return keras.utils.to_categorical(\n",
    "                y,num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 154s 164ms/step - loss: 2.2914 - acc: 0.1191 - val_loss: 2.3132 - val_acc: 0.1133\n",
      "Epoch 2/10\n",
      "296/938 [========>.....................] - ETA: 1:25 - loss: 2.3097 - acc: 0.1089"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "train_generator = DataGenerator(x_train, y_train, batch_size = 64,\n",
    "                                dim = (28,28),\n",
    "                                n_classes=10, \n",
    "                                to_fit=True, shuffle=True)\n",
    "val_generator =  DataGenerator(x_test, y_test, batch_size=64, \n",
    "                               dim = (28,28), \n",
    "                               n_classes= 10, \n",
    "                               to_fit=True, shuffle=True)\n",
    "steps_per_epoch = len(train_generator)\n",
    "validation_steps = len(val_generator)\n",
    "#FINAL\n",
    "model = Sequential()\n",
    "# First convolutional layer\n",
    "model.add(layers.Conv2D(6, kernel_size=(4,4), strides=(1, 1), activation='tanh', input_shape=(28,28,1), padding=\"same\"))\n",
    " # First pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(1,1), strides=(1, 1), padding='valid'))\n",
    " \n",
    "# Second convolutional layer\n",
    "model.add(layers.Conv2D(16, kernel_size=(4,4), strides=(1, 1), activation='relu', padding='valid'))\n",
    "    \n",
    "   # Second pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(1,1), strides=(2, 2), padding='valid'))\n",
    "  \n",
    "    # Connected convolutional layer\n",
    "model.add(layers.Conv2D(120, kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001), kernel_size=(4,4), strides=(1, 1), activation='relu', padding='valid'))\n",
    "model.add(layers.Flatten())\n",
    "    # Connected layer\n",
    "model.add(layers.Dense(84, kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001), activation='tanh'))\n",
    "model.add(Dropout(0.25)) \n",
    "   # Output layer\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # build/compile\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Nadam', metrics=[\"accuracy\"])\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=10,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=validation_steps)    \n",
    "#hist = model.fit(x=x_train,y=y_train, epochs=6, batch_size=120, validation_data=(x_test, y_test), verbose=1)\n",
    "#test_score = model.evaluate(x_test, y_test)\n",
    "#print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'acc')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['acc'], 'o-')\n",
    "ax.plot([None] + hist.history['val_acc'], 'x-')\n",
    "ax.legend(['Train acc', 'Validation acc'], loc = 0)\n",
    "ax.set_title('Training/Validation acc per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + hist.history['loss'], 'o-')\n",
    "ax.plot([None] + hist.history['val_loss'], 'x-')\n",
    "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
    "ax.set_title('Training/Validation Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
